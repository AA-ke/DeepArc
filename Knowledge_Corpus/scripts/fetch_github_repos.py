import requests
import json
import time
import os
import sys
from datetime import datetime

# âš ï¸ å¯é€‰ï¼šæ·»åŠ GitHub Tokenä»¥æé«˜é€Ÿç‡é™åˆ¶ï¼ˆä»5æ¬¡/åˆ†é’Ÿåˆ°30æ¬¡/åˆ†é’Ÿï¼‰
# è·å–token: https://github.com/settings/tokens
GITHUB_TOKEN = None  # è®¾ç½®ä¸º "ghp_your_token_here" æˆ–ä¿æŒNone

def search_github_repos(query, language=None, min_stars=50, max_results=100):
    """æœç´¢GitHubä»“åº“"""
    
    url = "https://api.github.com/search/repositories"
    
    headers = {
        "Accept": "application/vnd.github.v3+json",
    }
    
    if GITHUB_TOKEN:
        headers["Authorization"] = f"token {GITHUB_TOKEN}"
    
    # æ„å»ºæŸ¥è¯¢
    q = query
    if language:
        q += f" language:{language}"
    if min_stars:
        q += f" stars:>={min_stars}"
    
    params = {
        "q": q,
        "sort": "stars",
        "order": "desc",
        "per_page": min(100, max_results)  # GitHub APIæœ€å¤š100/é¡µ
    }
    
    print(f"ğŸ” æœç´¢: {q}", flush=True)
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        # æ£€æŸ¥é€Ÿç‡é™åˆ¶
        if response.status_code == 403:
            rate_limit_reset = response.headers.get('X-RateLimit-Reset')
            if rate_limit_reset:
                wait_time = int(rate_limit_reset) - int(time.time()) + 5
                if wait_time > 0:
                    print(f"  âš ï¸ APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...", flush=True)
                    time.sleep(wait_time)
                else:
                    print(f"  âš ï¸ APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…60ç§’...", flush=True)
                    time.sleep(60)
            else:
                print(f"  âš ï¸ APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…60ç§’...", flush=True)
                time.sleep(60)
            return []
        
        if response.status_code != 200:
            error_msg = f"HTTP {response.status_code}"
            try:
                error_data = response.json()
                if "message" in error_data:
                    error_msg += f": {error_data['message']}"
            except:
                pass
            print(f"  âŒ {error_msg}", file=sys.stderr, flush=True)
            return []
        
        data = response.json()
        repos = data.get("items", [])
        total_count = data.get("total_count", 0)
        
        print(f"  âœ… æ‰¾åˆ° {len(repos)} ä¸ªä»“åº“ï¼ˆæ€»å…± {total_count} ä¸ªï¼‰", flush=True)
        return repos
        
    except requests.exceptions.RequestException as e:
        print(f"  âŒ ç½‘ç»œé”™è¯¯: {e}", file=sys.stderr, flush=True)
        return []
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}", file=sys.stderr, flush=True)
        return []


def fetch_readme(repo_full_name):
    """è·å–ä»“åº“READMEå†…å®¹"""
    
    # å°è¯•å¸¸è§çš„READMEæ–‡ä»¶å
    readme_names = ["README.md", "README.MD", "readme.md", "Readme.md"]
    
    # å°è¯•çš„åˆ†æ”¯åˆ—è¡¨
    branches = ["main", "master", "develop"]
    
    for branch in branches:
        for readme_name in readme_names:
            url = f"https://raw.githubusercontent.com/{repo_full_name}/{branch}/{readme_name}"
            
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    return response.text
            except requests.exceptions.RequestException:
                continue
    
    return None


def process_repo(repo):
    """å¤„ç†å•ä¸ªä»“åº“ï¼Œæå–å…³é”®ä¿¡æ¯"""
    
    full_name = repo["full_name"]
    print(f"  ğŸ“¦ å¤„ç†: {full_name}", flush=True)
    
    try:
        # åŸºæœ¬ä¿¡æ¯
        repo_data = {
            "name": repo.get("name", ""),
            "full_name": full_name,
            "description": repo.get("description", ""),
            "stars": repo.get("stargazers_count", 0),
            "forks": repo.get("forks_count", 0),
            "language": repo.get("language", "N/A"),
            "url": repo.get("html_url", ""),
            "topics": repo.get("topics", []),
            "created_at": repo.get("created_at", ""),
            "updated_at": repo.get("updated_at", ""),
            "homepage": repo.get("homepage", ""),
            "license": repo.get("license", {}).get("name", "N/A") if repo.get("license") else "N/A",
            "readme": None,
            "readme_length": 0
        }
        
        # è·å–README
        readme = fetch_readme(full_name)
        if readme:
            repo_data["readme"] = readme
            repo_data["readme_length"] = len(readme)
            print(f"    âœ… README: {len(readme)} å­—ç¬¦", flush=True)
        else:
            print(f"    âš ï¸ æœªæ‰¾åˆ°README", flush=True)
        
        time.sleep(0.5)  # é¿å…è¢«é™é€Ÿ
        
        return repo_data
    except Exception as e:
        print(f"    âŒ å¤„ç†ä»“åº“æ—¶å‡ºé”™: {e}", file=sys.stderr, flush=True)
        return None


def save_repos(repos, filename):
    """ä¿å­˜ä»“åº“æ•°æ®"""
    os.makedirs("Knowledge_Corpus/data/raw", exist_ok=True)
    
    # JSONï¼ˆå®Œæ•´æ•°æ®ï¼ŒåŒ…æ‹¬READMEï¼‰
    json_path = f"Knowledge_Corpus/data/raw/{filename}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(repos, f, indent=2, ensure_ascii=False)
    
    # TXTï¼ˆåªä¿å­˜READMEå†…å®¹ï¼‰
    txt_path = f"Knowledge_Corpus/data/raw/{filename}_readmes.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        for i, repo in enumerate(repos, 1):
            f.write(f"{'='*100}\n")
            f.write(f"Repository {i}/{len(repos)}\n")
            f.write(f"{'='*100}\n")
            f.write(f"Name: {repo['full_name']}\n")
            f.write(f"Description: {repo['description']}\n")
            f.write(f"â­ Stars: {repo['stars']} | Forks: {repo['forks']}\n")
            f.write(f"Language: {repo['language']}\n")
            f.write(f"Topics: {', '.join(repo['topics'])}\n")
            f.write(f"URL: {repo['url']}\n")
            f.write(f"\n{'â”€'*100}\n")
            f.write(f"README:\n")
            f.write(f"{'â”€'*100}\n")
            if repo['readme']:
                f.write(repo['readme'])
            else:
                f.write("No README file found")
            f.write(f"\n\n")
    
    print(f"ğŸ’¾ å·²ä¿å­˜: {json_path}", flush=True)
    print(f"ğŸ’¾ å·²ä¿å­˜: {txt_path}", flush=True)


if __name__ == "__main__":
    
    print("="*60, flush=True)
    print("å¼€å§‹ä» GitHub è·å–ç”Ÿç‰©ä¿¡æ¯å­¦ä»“åº“", flush=True)
    print("="*60 + "\n", flush=True)
    
    # å®šä¹‰æœç´¢ä¸»é¢˜
    search_topics = [
         # é€šç”¨ï¼ˆæœ€é‡è¦ï¼‰
    {"query": "gene regulatory element", "language": "python", "min_stars": 10, "category": "general"},
    {"query": "cis-regulatory element", "language": None, "min_stars": 10, "category": "general"},
    {"query": "regulatory element design", "language": None, "min_stars": 10, "category": "general"},
    
    # æ ¸å¿ƒè°ƒæ§å…ƒä»¶ç±»å‹
    {"query": "promoter prediction", "language": "python", "min_stars": 20, "category": "regulatory_elements"},
    {"query": "enhancer prediction", "language": "python", "min_stars": 20, "category": "regulatory_elements"},
    {"query": "synthetic promoter", "language": None, "min_stars": 20, "category": "regulatory_elements"},
    {"query": "synthetic enhancer", "language": None, "min_stars": 20, "category": "regulatory_elements"},
    
    # è®¡ç®—æ–¹æ³•
    {"query": "MPRA", "language": None, "min_stars": 20, "category": "methods"},
    {"query": "STARR-seq", "language": None, "min_stars": 20, "category": "methods"},
    {"query": "regulatory sequence design", "language": "python", "min_stars": 20, "category": "methods"},
    {"query": "sequence-to-function", "language": "python", "min_stars": 20, "category": "methods"},
    
    # æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ 
    {"query": "deep learning gene regulation", "language": "python", "min_stars": 30, "category": "ml"},
    {"query": "neural network enhancer", "language": "python", "min_stars": 20, "category": "ml"},
    {"query": "transformer gene regulation", "language": "python", "min_stars": 20, "category": "ml"},
    {"query": "CNN promoter enhancer", "language": "python", "min_stars": 20, "category": "ml"},
    
    # è½¬å½•å› å­ä¸motif
    {"query": "transcription factor binding", "language": "python", "min_stars": 30, "category": "tf_motif"},
    {"query": "motif discovery", "language": "python", "min_stars": 25, "category": "tf_motif"},
    {"query": "PWM", "language": None, "min_stars": 15, "category": "tf_motif"},
    {"query": "ChIP-seq analysis", "language": "python", "min_stars": 30, "category": "tf_motif"},
    
    # è¡¨è§‚é—ä¼ ä¸æŸ“è‰²è´¨
    {"query": "ATAC-seq", "language": "python", "min_stars": 30, "category": "epigenomics"},
    {"query": "chromatin accessibility", "language": "python", "min_stars": 25, "category": "epigenomics"},
    {"query": "3D genome", "language": None, "min_stars": 20, "category": "epigenomics"},
    {"query": "chromatin interaction", "language": None, "min_stars": 20, "category": "epigenomics"},
    
    # åŸºå› è°ƒæ§ç½‘ç»œ
    {"query": "gene regulatory network", "language": "python", "min_stars": 20, "category": "networks"},
    {"query": "GRN inference", "language": "python", "min_stars": 20, "category": "networks"},
    ]
    
    all_repos = []
    seen_repos = set()  # å»é‡
    
    for i, topic in enumerate(search_topics, 1):
        print(f"\n[{i}/{len(search_topics)}] ä¸»é¢˜: {topic['query']}", flush=True)
        
        try:
            # æœç´¢
            repos = search_github_repos(
                query=topic["query"],
                language=topic.get("language"),
                min_stars=topic["min_stars"],
                max_results=50
            )
            
            if not repos:
                print(f"  è·³è¿‡ï¼šæœªæ‰¾åˆ°ä»“åº“", flush=True)
                time.sleep(1)
                continue
            
            # å¤„ç†æ¯ä¸ªä»“åº“
            processed_count = 0
            for repo in repos:
                full_name = repo.get("full_name")
                if not full_name:
                    continue
                
                # å»é‡
                if full_name in seen_repos:
                    continue
                seen_repos.add(full_name)
                
                # è·å–è¯¦ç»†ä¿¡æ¯
                repo_data = process_repo(repo)
                if repo_data:
                    all_repos.append(repo_data)
                    processed_count += 1
            
            print(f"  æœ¬ä¸»é¢˜æ–°å¢: {processed_count} ä¸ªï¼Œç´¯è®¡: {len(all_repos)} ä¸ªç‹¬ç‰¹ä»“åº“", flush=True)
            
            # ç¤¼è²Œå»¶è¿Ÿ
            time.sleep(2)
        except Exception as e:
            print(f"  âŒ å¤„ç†ä¸»é¢˜æ—¶å‡ºé”™: {e}", file=sys.stderr, flush=True)
            continue
    
    # ä¿å­˜
    if all_repos:
        print(f"\n{'='*60}", flush=True)
        print(f"âœ… æ€»å…±è·å– {len(all_repos)} ä¸ª GitHub ä»“åº“", flush=True)
        print(f"{'='*60}", flush=True)
        
        save_repos(all_repos, "github_repos_all")
        
        # ç»Ÿè®¡
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:", flush=True)
        
        # æŒ‰è¯­è¨€
        languages = {}
        for repo in all_repos:
            lang = repo.get('language', 'N/A')
            languages[lang] = languages.get(lang, 0) + 1
        
        print(f"\nç¼–ç¨‹è¯­è¨€:", flush=True)
        for lang, count in sorted(languages.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  {lang}: {count} ä¸ª", flush=True)
        
        # æŒ‰æ˜Ÿæ ‡
        total_stars = sum(repo.get('stars', 0) for repo in all_repos)
        avg_stars = total_stars / len(all_repos) if all_repos else 0
        print(f"\nâ­ æ€»æ˜Ÿæ ‡æ•°: {total_stars:,}", flush=True)
        print(f"â­ å¹³å‡æ˜Ÿæ ‡: {avg_stars:.1f}", flush=True)
        
        # æœ‰READMEçš„æ¯”ä¾‹
        with_readme = sum(1 for repo in all_repos if repo.get('readme'))
        readme_percent = (with_readme / len(all_repos) * 100) if all_repos else 0
        print(f"\nğŸ“„ åŒ…å«README: {with_readme}/{len(all_repos)} ({readme_percent:.1f}%)", flush=True)
    else:
        print(f"\nâš ï¸  æœªè·å–åˆ°ä»»ä½•ä»“åº“", flush=True)