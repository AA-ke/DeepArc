"""
Markdownè¯»å–è„šæœ¬
ä»core_papers_mdç›®å½•è¯»å–Markdownæ–‡ä»¶ï¼Œæå–æ ‡é¢˜å’ŒMethodséƒ¨åˆ†ï¼Œç»„ç»‡æˆé€‚åˆRAGçš„æ ¼å¼
"""

import os
import sys
import json
import re
from pathlib import Path
from typing import Dict, List, Optional
import hashlib


def generate_doc_id(source: str, identifier: str) -> str:
    """ç”Ÿæˆå”¯ä¸€æ–‡æ¡£ID"""
    unique_string = f"{source}_{identifier}"
    return hashlib.md5(unique_string.encode()).hexdigest()[:16]


def extract_title_from_markdown(content: str) -> str:
    """ä»Markdownæ–‡ä»¶ä¸­æå–ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼ˆ# å¼€å¤´çš„ï¼‰"""
    lines = content.split('\n')
    
    for line in lines:
        line_stripped = line.strip()
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼ˆ# å¼€å¤´ï¼Œåé¢è·Ÿç©ºæ ¼ï¼‰
        if re.match(r'^#\s+', line_stripped):
            # ç§»é™¤ # å’Œç©ºæ ¼ï¼Œè¿”å›æ ‡é¢˜æ–‡æœ¬
            title = re.sub(r'^#\s+', '', line_stripped).strip()
            if title:
                return title
    
    return ""


def find_methods_section_in_markdown(content: str) -> Optional[str]:
    """ä»Markdownæ–‡ä»¶ä¸­æŸ¥æ‰¾å¹¶æå–Methodséƒ¨åˆ†"""
    lines = content.split('\n')
    
    # Methodséƒ¨åˆ†çš„å¯èƒ½æ ‡é¢˜å˜ä½“ï¼ˆMarkdownæ ¼å¼ï¼Œä»¥ # å¼€å¤´ï¼Œå¯èƒ½å¸¦ç¼–å·/ç½—é©¬æ•°å­—å‰ç¼€å’Œå†’å·ï¼‰
    # æ”¯æŒç¤ºä¾‹ï¼š
    #   # Methods
    #   # 2. Methods
    #   # III. METHODS
    #   # 3 METHOD
    #   # 3 Design and implementations
    #   # 2. Approach
    #   # 3 HyenaDNA Long-Range Genomic Foundation Models
    method_patterns = [
        r'^#\s+(?:[0-9IVXLCDM]+\.?\s+)?'
        r'(?:Methods?|METHODS?|Methodology|METHODOLOGY|Experimental\s+Methods?|EXPERIMENTAL\s+METHODS?'
        r'|Materials\s+and\s+Methods?|MATERIALS\s+AND\s+METHODS?|Methods\s+and\s+Materials|METHODS\s+AND\s+MATERIALS'
        r'|Design\s+and\s+implementations?|DESIGN\s+AND\s+IMPLEMENTATIONS?'
        r'|Approach|APPROACH'
        r'|HyenaDNA\s+Long-Range\s+Genomic\s+Foundation\s+Models)'
        r'\s*:?\s*$',
    ]
    
    # æŸ¥æ‰¾Methodséƒ¨åˆ†çš„å¼€å§‹ä½ç½®
    method_start = None
    
    for i, line in enumerate(lines):
        line_stripped = line.strip()
        # æ£€æŸ¥æ˜¯å¦æ˜¯Methodsæ ‡é¢˜ï¼ˆ# Methods æˆ– # METHODS ç­‰ï¼Œæ”¯æŒå†’å·ï¼‰
        for pattern in method_patterns:
            if re.match(pattern, line_stripped, re.IGNORECASE):
                method_start = i
                break
        if method_start is not None:
            break
    
    if method_start is None:
        return None
    
    # æŸ¥æ‰¾Methodséƒ¨åˆ†çš„ç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªä¸€çº§æ ‡é¢˜ # å¼€å¤´ï¼‰
    method_end = len(lines)
    
    # ä»Methodséƒ¨åˆ†å¼€å§‹åæŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸€çº§æ ‡é¢˜
    for i in range(method_start + 1, len(lines)):
        line_stripped = lines[i].strip()
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸‹ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼ˆ# å¼€å¤´ï¼Œä½†ä¸æ˜¯ Methods çš„å˜ä½“ï¼‰
        if re.match(r'^#\s+', line_stripped):
            # æ£€æŸ¥æ˜¯å¦æ˜¯å…¶ä»–ä¸»è¦ç« èŠ‚ï¼ˆä¸æ˜¯ Methods çš„å­æ ‡é¢˜ï¼‰
            next_title = re.sub(r'^#\s+', '', line_stripped).strip()
            # ç§»é™¤å¯èƒ½çš„å†’å·
            next_title = re.sub(r':\s*$', '', next_title).strip()
            # æ’é™¤ Methods çš„å˜ä½“ï¼ˆå¯èƒ½æ˜¯å­æ ‡é¢˜ï¼‰
            if not re.match(r'(?i)^(?:Methods?|METHODS?|Methodology|METHODOLOGY)', next_title):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸»è¦ç« èŠ‚ï¼ˆDiscussion, References, Data availabilityç­‰ï¼‰
                if re.match(r'(?i)^(?:Discussion|References?|Data\s+availability|Code\s+availability|Acknowledgments?|Author\s+contributions|Competing\s+interests|Additional\s+information|Reporting\s+Summary|Statistics|Software\s+and\s+code|Field-specific\s+reporting)', next_title):
                    method_end = i
                    break
    
    # æå–Methodséƒ¨åˆ†å†…å®¹ï¼ˆåŒ…å«æ ‡é¢˜è¡Œï¼‰
    methods_lines = lines[method_start:method_end]
    methods_text = '\n'.join(methods_lines).strip()
    
    # ç§»é™¤Methodsæ ‡é¢˜è¡Œï¼ˆä¿ç•™å†…å®¹ï¼Œæ”¯æŒæ•°å­—/ç½—é©¬æ•°å­—å‰ç¼€å’Œå†’å·ï¼‰
    methods_text = re.sub(
        r'^#\s+(?:[0-9IVXLCDM]+\.?\s+)?'
        r'(?:Methods?|METHODS?|Methodology|METHODOLOGY|Experimental\s+Methods?|EXPERIMENTAL\s+METHODS?'
        r'|Materials\s+and\s+Methods?|MATERIALS\s+AND\s+METHODS?|Methods\s+and\s+Materials|METHODS\s+AND\s+MATERIALS'
        r'|Design\s+and\s+implementations?|DESIGN\s+AND\s+IMPLEMENTATIONS?'
        r'|Approach|APPROACH'
        r'|HyenaDNA\s+Long-Range\s+Genomic\s+Foundation\s+Models)'
        r'\s*:?\s*$',
        '',
        methods_text,
        flags=re.IGNORECASE | re.MULTILINE
    ).strip()
    
    # æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤è¿‡å¤šçš„ç©ºç™½è¡Œï¼Œä¿ç•™æ®µè½ç»“æ„
    methods_text = re.sub(r'\n{3,}', '\n\n', methods_text)
    
    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å®¹ï¼ˆè‡³å°‘100ä¸ªå­—ç¬¦ï¼‰
    if len(methods_text.strip()) < 100:
        return None
    
    return methods_text if methods_text else None


def preserve_paragraphs(text: str) -> str:
    """ä¿ç•™æ®µè½ç»“æ„ï¼Œç¡®ä¿æ®µè½ä¹‹é—´ç”¨åŒæ¢è¡Œç¬¦åˆ†éš”"""
    # æ¸…ç†æ–‡æœ¬
    text = text.strip()
    
    # å°†å¤šä¸ªè¿ç»­æ¢è¡Œç¬¦ç»Ÿä¸€ä¸ºåŒæ¢è¡Œç¬¦ï¼ˆæ®µè½åˆ†éš”ï¼‰
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # ç¡®ä¿æ®µè½ä¹‹é—´æ˜¯åŒæ¢è¡Œç¬¦
    # å•æ¢è¡Œç¬¦é€šå¸¸è¡¨ç¤ºåŒä¸€æ®µè½å†…çš„æ¢è¡Œï¼ŒåŒæ¢è¡Œç¬¦è¡¨ç¤ºæ®µè½åˆ†éš”
    lines = text.split('\n')
    paragraphs = []
    current_para = []
    
    for line in lines:
        line = line.strip()
        if not line:
            # ç©ºè¡Œè¡¨ç¤ºæ®µè½ç»“æŸ
            if current_para:
                paragraphs.append(' '.join(current_para))
                current_para = []
        else:
            current_para.append(line)
    
    # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
    if current_para:
        paragraphs.append(' '.join(current_para))
    
    # ç”¨åŒæ¢è¡Œç¬¦è¿æ¥æ®µè½
    return '\n\n'.join(paragraphs)


def process_markdown(md_path: Path) -> Optional[Dict]:
    """å¤„ç†å•ä¸ªMarkdownæ–‡ä»¶ï¼Œæå–æ ‡é¢˜å’ŒMethodséƒ¨åˆ†"""
    print(f"  å¤„ç†: {md_path.name}", flush=True)
    
    # è¯»å–Markdownæ–‡ä»¶
    try:
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"  âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {md_path.name}, é”™è¯¯: {e}", flush=True)
        return None
    
    if not content.strip():
        print(f"  âš ï¸ æ–‡ä»¶ä¸ºç©º: {md_path.name}", flush=True)
        return None
    
    # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª # æ ‡é¢˜ï¼‰
    title = extract_title_from_markdown(content)
    if not title:
        # å¦‚æœæ— æ³•æå–æ ‡é¢˜ï¼Œä½¿ç”¨æ–‡ä»¶åï¼ˆå»é™¤æ‰©å±•åå’Œå‰ç¼€ï¼‰
        title = md_path.stem
        # ç§»é™¤å¯èƒ½çš„æ–‡ä»¶åå‰ç¼€ï¼ˆå¦‚ MinerU_markdown_ï¼‰
        title = re.sub(r'^MinerU_markdown_', '', title)
        title = title.replace('_', ' ').replace('-', ' ')
        print(f"  âš ï¸ æ— æ³•æå–æ ‡é¢˜ï¼Œä½¿ç”¨æ–‡ä»¶å: {title}", flush=True)
    
    # æå–Methodséƒ¨åˆ†
    methods_text = find_methods_section_in_markdown(content)
    has_methods = False
    
    if methods_text:
        # ä¿ç•™æ®µè½ç»“æ„ï¼ˆä½†ä¿ç•™Markdownæ ¼å¼ï¼Œä¸è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼‰
        # åªæ¸…ç†å¤šä½™çš„ç©ºç™½è¡Œ
        methods_text = re.sub(r'\n{3,}', '\n\n', methods_text.strip())
        has_methods = True
    else:
        print(f"  âš ï¸ æœªæ‰¾åˆ°Methodséƒ¨åˆ†: {md_path.name}ï¼Œmethodså­—æ®µç•™ç©ºä¾›æ‰‹åŠ¨å¡«å†™", flush=True)
        methods_text = ""  # ç•™ç©ºï¼Œä¾›ç”¨æˆ·æ‰‹åŠ¨å¡«å†™
    
    # ç”Ÿæˆæ–‡æ¡£IDï¼ˆä½¿ç”¨æ–‡ä»¶åï¼Œå»é™¤æ‰©å±•åï¼‰
    source_id = md_path.stem
    doc_id = generate_doc_id("core_papers_md", source_id)
    
    # ç»„ç»‡æˆç»Ÿä¸€æ ¼å¼
    doc = {
        "doc_id": doc_id,
        "source": "Core Papers MD",
        "source_id": source_id,
        "title": title,
        "abstract": "",  # ä¸æå–abstract
        "authors": "",
        "journal": "",
        "date": "",
        "doi": "",
        "url": "",
        "keywords": [],
        "full_text": "",  # ä¸å­˜å‚¨å…¨æ–‡ï¼Œåªå­˜å‚¨Methodséƒ¨åˆ†
        "methods": methods_text,  # Methodséƒ¨åˆ†ï¼Œä¿ç•™Markdownæ ¼å¼å’Œæ®µè½ç»“æ„ï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
        "metadata": {
            "md_filename": md_path.name,
            "md_path": str(md_path),
            "has_methods": has_methods  # æ ‡è®°æ˜¯å¦æ‰¾åˆ°Methodséƒ¨åˆ†
        }
    }
    
    if has_methods:
        print(f"  âœ“ æå–æˆåŠŸ: {title[:50]}...", flush=True)
    else:
        print(f"  âš ï¸ å·²ä¿å­˜ï¼ˆMethodså¾…å¡«å†™ï¼‰: {title[:50]}...", flush=True)
    
    return doc


def main():
    """ä¸»å‡½æ•°ï¼šå¤„ç†core_papers_mdç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶"""
    print("="*80)
    print("ğŸ“„ Markdownè¯»å–è„šæœ¬ - æå–æ ‡é¢˜å’ŒMethodséƒ¨åˆ†")
    print("="*80)
    
    # è®¾ç½®è·¯å¾„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    core_papers_md_dir = project_root / "Knowledge_Corpus" / "core_papers_md"
    output_dir = project_root / "Knowledge_Corpus" / "data" / "raw"
    
    if not core_papers_md_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {core_papers_md_dir}", flush=True)
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(core_papers_md_dir.glob("*.md"))
    if not md_files:
        print(f"âŒ æœªæ‰¾åˆ°Markdownæ–‡ä»¶: {core_papers_md_dir}", flush=True)
        sys.exit(1)
    
    print(f"\nğŸ“š æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶", flush=True)
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}\n", flush=True)
    
    # å¤„ç†æ¯ä¸ªMarkdownæ–‡ä»¶
    all_docs = []
    success_count = 0
    with_methods_count = 0
    without_methods_count = 0
    failed_count = 0
    
    for md_path in sorted(md_files):
        try:
            doc = process_markdown(md_path)
            if doc:
                all_docs.append(doc)
                success_count += 1
                # ç»Ÿè®¡æœ‰Methodså’Œæ²¡æœ‰Methodsçš„æ•°é‡
                if doc.get("metadata", {}).get("has_methods", False):
                    with_methods_count += 1
                else:
                    without_methods_count += 1
            else:
                failed_count += 1
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥ {md_path.name}: {e}", flush=True)
            failed_count += 1
    
    # ä¿å­˜ç»“æœ
    if all_docs:
        output_file = output_dir / "core_papers_md_methods.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_docs, f, ensure_ascii=False, indent=2)
        
        print(f"\n{'='*80}")
        print(f"âœ… å¤„ç†å®Œæˆ!")
        print(f"  æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
        print(f"    - åŒ…å«Methods: {with_methods_count} ä¸ª")
        print(f"    - Methodså¾…å¡«å†™: {without_methods_count} ä¸ª")
        print(f"  å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
        print(f"  è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"\nğŸ’¡ æç¤º: Methodså­—æ®µä¸ºç©ºçš„æ–‡æ¡£å¯ä»¥æ‰‹åŠ¨å¡«å†™Methodså†…å®¹", flush=True)
        print(f"{'='*80}", flush=True)
    else:
        print(f"\nâŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•æ–‡æ¡£", flush=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
