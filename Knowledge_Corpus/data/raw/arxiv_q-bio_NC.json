[
  {
    "arxiv_id": "2512.01962v1",
    "title": "A framework for disentangling spatial and visual neural representations",
    "abstract": "Neurons in cortical areas often integrate signals from different origins. In the primary visual cortex (V1), neural responses are modulated by non-visual context such as the animal's position. However, the spatial profile of these position signals across the environment remains unknown. Here, we propose a new framework to disentangle visual and spatial contributions in virtual reality. This method relies on two principles: 1) a virtual corridor design that decorrelates vision and space through targeted cue repetitions and manipulations and 2) a Generalized Linear Model (GLM) that explicitly estimates visual contributions in retinotopic rather than environmental coordinates. In simulations, we demonstrate that this framework is highly specific (recovering spatial modulation only when present) and effectively captures the profile and weight of spatial gain fields across the environment. When applied to V1 recordings from mice navigating the virtual corridor, the model isolated significant spatial components in a substantial fraction of V1 neurons. The recovered spatial components exhibited heterogeneous, often multi-peaked, profiles. Application of this framework to large-scale recordings may provide a robust approach to characterize the nature of spatial signals modulating sensory processing across brain areas.",
    "authors": [
      "Mai M. Morimoto",
      "Julien Fournier",
      "Aman B. Saleem"
    ],
    "published": "2025-12-01",
    "updated": "2025-12-01",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.01962v1",
    "doi": null,
    "journal_ref": null,
    "comment": "14 pages, 5 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01591v1",
    "title": "Scaling and context steer LLMs along the same computational path as the human brain",
    "abstract": "Recent studies suggest that the representations learned by large language models (LLMs) are partially aligned to those of the human brain. However, whether and why this alignment score arises from a similar sequence of computations remains elusive. In this study, we explore this question by examining temporally-resolved brain signals of participants listening to 10 hours of an audiobook. We study these neural dynamics jointly with a benchmark encompassing 22 LLMs varying in size and architecture type. Our analyses confirm that LLMs and the brain generate representations in a similar order: specifically, activations in the initial layers of LLMs tend to best align with early brain responses, while the deeper layers of LLMs tend to best align with later brain responses. This brain-LLM alignment is consistent across transformers and recurrent architectures. However, its emergence depends on both model size and context length. Overall, this study sheds light on the sequential nature of computations and the factors underlying the partial convergence between biological and artificial neural networks.",
    "authors": [
      "Joséphine Raugel",
      "Stéphane d'Ascoli",
      "Jérémy Rapin",
      "Valentin Wyart",
      "Jean-Rémi King"
    ],
    "published": "2025-12-01",
    "updated": "2025-12-01",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.01591v1",
    "doi": null,
    "journal_ref": "Neurips Proceedings 2025 - Spotlight",
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01406v1",
    "title": "Personalized optimization of pediatric HD-tDCS for dose consistency and target engagement",
    "abstract": "High-definition transcranial direct current stimulation (HD-tDCS) dosing in children remains largely empirical, relying on one-size-fits-all protocols despite rapid developmental changes in head anatomy and tissue properties that strongly modulate how currents reach the developing brain. Using 70 pediatric head models and commonly used cortical targets, our forward simulations find that standard montages produce marked age-dependent reductions in target electric-field intensity and systematic sex differences linked to tissue-volume covariation, underscoring the profound limitations of conventional uniform montages. To overcome these limitations, we introduce a developmentally informed, dual-objective optimization framework designed to generate personalized Pareto fronts summarizing the trade-off between electric-field intensity and focality. From these optimized solutions, we derive two practical dosing prescriptions: a dose-consistency strategy that, for the first time, enforces fixed target intensity across individuals to implicitly mitigate demographic effects, and a target-engagement strategy that maximizes target intensity under safety limits. Both strategies remain robust to large conductivity variations, and we further show that dense HD-tDCS solutions admit sparse equivalents without performance loss under the target-engagement strategy. We also find that tissue conductivity sensitivity is depth-dependent, with Pareto-front distributions for superficial cortical targets most influenced by gray matter, scalp, and bone conductivities, and those for a deep target predominantly shaped by gray and white matter conductivities. Together, these results establish a principled framework for pediatric HD-tDCS planning that explicitly accounts for developmental anatomy and physiological uncertainty, enabling reliable and individualized neuromodulation dosing in pediatric populations.",
    "authors": [
      "Zeming Liu",
      "Mo Wang",
      "Xuanye Pan",
      "Yuan Yang",
      "Wilson Truccolo",
      "Quanying Liu"
    ],
    "published": "2025-12-01",
    "updated": "2025-12-01",
    "categories": [
      "q-bio.QM",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.QM",
    "pdf_url": "https://arxiv.org/pdf/2512.01406v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Zeming Liu and Mo Wang contributed equally to this work. Correspondence to Wilson Truccolo (wilson_truccolo@brown.edu) and Quanying Liu (liuqy@sustech.edu.cn)",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01199v1",
    "title": "Know Thyself by Knowing Others: Learning Neuron Identity from Population Context",
    "abstract": "Neurons process information in ways that depend on their cell type, connectivity, and the brain region in which they are embedded. However, inferring these factors from neural activity remains a significant challenge. To build general-purpose representations that allow for resolving information about a neuron's identity, we introduce NuCLR, a self-supervised framework that aims to learn representations of neural activity that allow for differentiating one neuron from the rest. NuCLR brings together views of the same neuron observed at different times and across different stimuli and uses a contrastive objective to pull these representations together. To capture population context without assuming any fixed neuron ordering, we build a spatiotemporal transformer that integrates activity in a permutation-equivariant manner. Across multiple electrophysiology and calcium imaging datasets, a linear decoding evaluation on top of NuCLR representations achieves a new state-of-the-art for both cell type and brain region decoding tasks, and demonstrates strong zero-shot generalization to unseen animals. We present the first systematic scaling analysis for neuron-level representation learning, showing that increasing the number of animals used during pretraining consistently improves downstream performance. The learned representations are also label-efficient, requiring only a small fraction of labeled samples to achieve competitive performance. These results highlight how large, diverse neural datasets enable models to recover information about neuron identity that generalize across animals. Code is available at https://github.com/nerdslab/nuclr.",
    "authors": [
      "Vinam Arora",
      "Divyansha Lachi",
      "Ian J. Knight",
      "Mehdi Azabou",
      "Blake Richards",
      "Cole L. Hurwitz",
      "Josh Siegle",
      "Eva L. Dyer"
    ],
    "published": "2025-12-01",
    "updated": "2025-12-01",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.01199v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Accepted at Neurips 2025",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01081v1",
    "title": "Testing the Machine Consciousness Hypothesis",
    "abstract": "The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.",
    "authors": [
      "Stephen Fitz"
    ],
    "published": "2025-11-30",
    "updated": "2025-11-30",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA",
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2512.01081v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01073v1",
    "title": "The Modeler Schema Theory of Consciousness, with a Falsifiable Experiment",
    "abstract": "We propose that consciousness arises from a single control agent, the Modeler-schema. It monitors the brain's Modeler as that system constructs and updates the internal World Model. As part of that monitoring, the Modeler-schema generates experience by applying a qualia-based consistency check to the Modeler's output. The Human Agent comprises three cooperating agents: Modeler, Controller, and Targeter, each paired with an associated regulatory \"schema\" agent. We also describe fast-Modelers and fast-Controllers; evolutionary shortcuts whose rapid actions will precede awareness. Our core prediction is that the Modeler-schema performs a qualia-based consistency check during saccades and issues a bottom-up target when a discrepancy is found. To test this prediction, we propose a saccadic change-detection experiment that distinguishes Modeler-generated from Modeler-schema-generated targets. Locating qualia in the Modeler-schema ties experience to the regulation and refinement of internal representations, clarifies how awareness arises from model control, and suggests a path toward empirical falsification, thereby offering a concrete, testable proposal toward solving the Hard Problem of consciousness.",
    "authors": [
      "Frank Heile"
    ],
    "published": "2025-11-30",
    "updated": "2025-11-30",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.01073v1",
    "doi": null,
    "journal_ref": null,
    "comment": "36 pages, 5 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01058v1",
    "title": "Stability analysis of action potential generation using Markov models of voltage-gated sodium channel isoforms",
    "abstract": "We investigate a conductance-based neuron model to explore how voltage-gated ion channel isoforms influence action-potential generation. The model combines a six-state Markov representation of NaV channels with a first-order KV3.1 model, allowing us to vary maximal sodium and potassium conductances and compare nine NaV isoforms. Using bifurcation theory and local stability analysis, we map regions of stable limit cycles and visualize excitability landscapes via heatmap-based diagrams. These analyses show that isoforms NaV1.3, NaV1.4 and NaV1.6 support broad excitable regimes, while isoforms NaV1.7 and NaV1.9 exhibit minimal oscillatory behavior. Our findings provide insights into the role of channel heterogeneity in neuronal dynamics and may help to guide the design of synthetic excitable systems by narrowing the parameter space needed for robust action-potential trains.",
    "authors": [
      "Youssof Abdullah",
      "Violet Hart",
      "Moumita Das"
    ],
    "published": "2025-11-30",
    "updated": "2025-11-30",
    "categories": [
      "q-bio.NC",
      "nlin.CD"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.01058v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.01006v1",
    "title": "The Coupling Strength Is a Scale Parameter in Threshold Power-Law Reservoirs and Does Not Influence Training Accuracy",
    "abstract": "In reservoir computing, the coupling strength of the initial untrained recurrent neural network (the reservoir) is an important hyperparameter that can be varied for accurate training. A common heuristic is to set this parameter near the ``edge of chaos\", where the untrained reservoir is near the transition to chaotic dynamics, and the chaos can be ``tamed\". Here, we investigate how the overall connectivity strength should be varied in threshold power-law recurrent neural networks, where the firing rate is 0 below some threshold of the current and is a power function of the current above this threshold. These networks have been previously shown to exhibit chaotic solutions for very small coupling strengths, which may imply that the chaos cannot be tamed at all. We show that for reservoirs constructed with threshold power-law transfer functions, if the reservoir can be trained for one single positive value of the initial reservoir coupling strength, then there exist networks with identical accuracy for all positive coupling strengths, implying that the chaotic dynamics can always be tamed or never be tamed. This is a direct consequence of the coupling strength of threshold power-law RNNs acting as a scale parameter that does not qualitatively influence the dynamics of the system, but only scales all system solutions in magnitude. This is independent of the power of the transfer function, with the exception of Rectified Linear Unit (ReLU) networks. This is in contrast with conventional RNNs/reservoirs employing sigmoidal firing rates, where the strength of the recurrent coupling in the initial reservoir determines the performance on different tasks during training and also influences the network dynamics explicitly.",
    "authors": [
      "Wilten Nicola"
    ],
    "published": "2025-11-30",
    "updated": "2025-11-30",
    "categories": [
      "math.DS",
      "q-bio.NC"
    ],
    "primary_category": "math.DS",
    "pdf_url": "https://arxiv.org/pdf/2512.01006v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00984v1",
    "title": "Symmetries at the origin of hierarchical emergence",
    "abstract": "Many systems of interest exhibit nested emergent layers with their own rules and regularities, and our knowledge about them seems naturally organised around these levels. This paper proposes that this type of hierarchical emergence arises as a result of underlying symmetries. By combining principles from information theory, group theory, and statistical mechanics, one finds that dynamical processes that are equivariant with respect to a symmetry group give rise to emergent macroscopic levels organised into a hierarchy determined by the subgroups of the symmetry. The same symmetries happen to also shape Bayesian beliefs, yielding hierarchies of abstract belief states that can be updated autonomously at different levels of resolution. These results are illustrated in Hopfield networks and Ehrenfest diffusion, showing that familiar macroscopic quantities emerge naturally from their symmetries. Together, these results suggest that symmetries provide a fundamental mechanism for emergence and support a structural correspondence between objective and epistemic processes, making feasible inferential problems that would otherwise be computationally intractable.",
    "authors": [
      "Fernando E. Rosas"
    ],
    "published": "2025-11-30",
    "updated": "2025-11-30",
    "categories": [
      "q-bio.NC",
      "cond-mat.dis-nn"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00984v1",
    "doi": null,
    "journal_ref": null,
    "comment": "12 pages, 4 figures plus one diagram",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00281v1",
    "title": "Rethinking Lung Cancer Screening: AI Nodule Detection and Diagnosis Outperforms Radiologists, Leading Models, and Standards Beyond Size and Growth",
    "abstract": "Early detection of malignant lung nodules is critical, but its dependence on size and growth in screening inherently delays diagnosis. We present an AI system that redefines lung cancer screening by performing both detection and malignancy diagnosis directly at the nodule level on low-dose CT scans. To address limitations in dataset scale and explainability, we designed an ensemble of shallow deep learning and feature-based specialized models. Trained and evaluated on 25,709 scans with 69,449 annotated nodules, the system outperforms radiologists, Lung-RADS, and leading AI models (Sybil, Brock, Google, Kaggle). It achieves an area under the receiver operating characteristic curve (AUC) of 0.98 internally and 0.945 on an independent cohort. With 0.5 false positives per scan at 99.3\\% sensitivity, it addresses key barriers to AI adoption. Critically, it outperforms radiologists across all nodule sizes and stages, excelling in stage 1 cancers, and all growth-based metrics, including the least accurate: Volume-Doubling Time. It also surpasses radiologists by up to one year in diagnosing indeterminate and slow-growing nodules.",
    "authors": [
      "Sylvain Bodard",
      "Pierre Baudot",
      "Benjamin Renoust",
      "Charles Voyton",
      "Gwendoline De Bie",
      "Ezequiel Geremia",
      "Van-Khoa Le",
      "Danny Francis",
      "Pierre-Henri Siot",
      "Yousra Haddou",
      "Vincent Bobin",
      "Jean-Christophe Brisset",
      "Carey C. Thomson",
      "Valerie Bourdes",
      "Benoit Huet"
    ],
    "published": "2025-11-29",
    "updated": "2025-11-29",
    "categories": [
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2512.00281v1",
    "doi": null,
    "journal_ref": null,
    "comment": "25 pages, 8 figures, with supplementary information containing 11 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00196v1",
    "title": "Emergent Riemannian geometry over learning discrete computations on continuous manifolds",
    "abstract": "Many tasks require mapping continuous input data (e.g. images) to discrete task outputs (e.g. class labels). Yet, how neural networks learn to perform such discrete computations on continuous data manifolds remains poorly understood. Here, we show that signatures of such computations emerge in the representational geometry of neural networks as they learn. By analysing the Riemannian pullback metric across layers of a neural network, we find that network computation can be decomposed into two functions: discretising continuous input features and performing logical operations on these discretised variables. Furthermore, we demonstrate how different learning regimes (rich vs. lazy) have contrasting metric and curvature structures, affecting the ability of the networks to generalise to unseen inputs. Overall, our work provides a geometric framework for understanding how neural networks learn to perform discrete computations on continuous manifolds.",
    "authors": [
      "Julian Brandon",
      "Angus Chadwick",
      "Arthur Pellegrino"
    ],
    "published": "2025-11-28",
    "updated": "2025-11-28",
    "categories": [
      "cs.LG",
      "cs.NE",
      "math.DG",
      "q-bio.NC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2512.00196v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00140v1",
    "title": "The Geometry of Certainty: Recursive Topological Condensation and the Limits of Inference",
    "abstract": "Computation fundamentally separates time from space: nondeterministic search is exponential in time but polynomially simulable in space (Savitch's Theorem). We propose that the brain physically instantiates a biological variant of this theorem through Memory-Amortized Inference (MAI), creating a geometry of certainty from the chaos of exploration. We formalize the cortical algorithm as a recursive topological transformation of flow into scaffold:$H_{odd}^{(k)} \\xrightarrow{\\text{Condense}} H_{even}^{(k+1)}$, where a stable, high-frequency cycle ($β_1$) at level $k$ is collapsed into a static atomic unit ($β_0$) at level $k+1$. Through this Topological Trinity (Search $\\to$ Closure $\\to$ Condensation), the system amortizes the thermodynamic cost of inference. By reducing complex homological loops into zero-dimensional defects (memory granules), the cortex converts high-entropy parallel search into low-entropy serial navigation. This mechanism builds a ``Tower of Scaffolds'' that achieves structural parity with the environment, allowing linear cortical growth to yield exponential representational reach. However, this efficiency imposes a strict limit: the same metric contraction that enables \\emph{generalization} (valid manifold folding) inevitably risks \\emph{hallucination} (homological collapse). We conclude that intelligence is the art of navigating this trade-off, where the ``Geometry of Certainty'' is defined by the precise threshold between necessary abstraction and topological error.",
    "authors": [
      "Xin Li"
    ],
    "published": "2025-11-28",
    "updated": "2025-11-28",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00140v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00132v1",
    "title": "An Operational Quantum Information Framework for Experimental Studies on Color Perception",
    "abstract": "Starting from the foundational axiomatization of the perceptual color space initiated by Schrödinger in 1920 and eventually refined by Resnikoff in 1974, Berthier, Provenzi and their collaborators have recently proposed a reformulation of perceptual color attributes within the framework of quantum information. Their work is based on the Jordan algebra formalism of quantum theories and, more specifically, on a quantum system described by a spin factor over the field of real numbers. This theoretical framework is not that of ordinary quantum mechanics, mainly because it requires dealing with rebits, whereas the latter uses qubits. The aim of this paper is to show that this difference in no way hinders the implementation of experimental protocols for testing the validity of the predictions of the color perception model. In particular, we show how to compute the quantum information based perceptual attributes of perceived colors in terms of qubit density matrices.",
    "authors": [
      "Roberto Leporini",
      "Edoardo Provenzi",
      "Michel Berthier"
    ],
    "published": "2025-11-28",
    "updated": "2025-11-28",
    "categories": [
      "q-bio.NC",
      "math-ph",
      "physics.soc-ph",
      "quant-ph"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00132v1",
    "doi": null,
    "journal_ref": "Theoretical Computer Science 1061, 115650, 2026",
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.22870v1",
    "title": "Scalable Diffusion Transformer for Conditional 4D fMRI Synthesis",
    "abstract": "Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models.",
    "authors": [
      "Jungwoo Seo",
      "David Keetae Park",
      "Shinjae Yoo",
      "Jiook Cha"
    ],
    "published": "2025-11-28",
    "updated": "2025-11-28",
    "categories": [
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.22870v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Accepted at NeurIPS 2025 Workshop: Foundation Models for the Brain and Body. 13 pages, 6 figures, 4 tables",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.22848v1",
    "title": "Short-term plasticity recalls forgotten memories through a trampoline mechanism",
    "abstract": "We analyze continuous Hopfield associative memories augmented by additional, rapid short-term associative synaptic plasticity. Through the cavity method, we determine the boundary between the retrieval and forgetting, or spin-glass phase, of the network as a function of the fraction of stored memories and the neuronal gain. We find that short-term synaptic plasticity yields marginal improvements in critical memory capacity. However, through dynamical mean field theory, backed by extensive numerical simulations, we find that short-term synaptic plasticity has a dramatic impact on memory retrieval above the critical capacity. When short-term synaptic plasticity is turned on, the combined neuronal and synaptic dynamics descends a high-dimensional energy landscape over both neurons and synapses. The energy landscape over neurons alone is thus dynamic, and is lowered in the vicinity of recent neuronal patterns visited by the network, just like the surface of a trampoline is lowered in the vicinity of regions recently visited by a heavy ball. This trampoline-like reactivity of the neuronal energy landscape to short-term plasticity in synapses can lead to the recall of stored memories that would otherwise have been forgotten. This occurs because the dynamics without short-term plasticity transiently moves towards a stored memory before departing away from it. Thus short-term plasticity, operating during the transient, lowers the energy in the vicinity of the stored memory, eventually trapping the combined neuronal and synaptic dynamics at a fixed point close to the stored memory. In this manner, short-term plasticity enables the recall of memories that would otherwise be forgotten, by trapping transients that would otherwise escape. We furthermore find an optimal time constant for short-term synaptic plasticity, matched to the transient dynamics, to empower recall of forgotten memories.",
    "authors": [
      "Martina Del Gaudio",
      "Federico Ghimenti",
      "Surya Ganguli"
    ],
    "published": "2025-11-28",
    "updated": "2025-11-28",
    "categories": [
      "q-bio.NC",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.22848v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.22828v1",
    "title": "Fast dynamical similarity analysis",
    "abstract": "To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis.",
    "authors": [
      "Arman Behrad",
      "Mitchell Ostrow",
      "Mohammad Taha Fakharian",
      "Ila Fiete",
      "Christian Beste",
      "Shervin Safavi"
    ],
    "published": "2025-11-28",
    "updated": "2025-11-28",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.22828v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00109v1",
    "title": "The Dual-Loop Model of Psychophysiological Regulation: A Framework for Psychological Breakthrough and State Transition",
    "abstract": "In real life, psychological and physiological states rarely change along a single dimension. Through self-tracking and discussions with clinicians, I have come to recognise with increasing clarity that sleep patterns, autonomic arousal, bodily sensations, and cognitive load are in constant interaction. Existing models often fail to capture this complexity. Many theoretical frameworks continue to analyse these elements in isolation, making it difficult to explain sudden changes reported by individuals,such as abrupt spikes in anxiety, sudden drops in dissociation, or even moments of heightened alertness. The mathematical modelling employed herein does not replace clinical or subjective narratives, but rather provides a structural framework for these rapid transitions and elucidates why bodily-driven and cognitively-driven changes manifest differently. The objective is to build a conceptual bridge between physiological signals and lived experience, laying the groundwork for dynamic modelling and future case analyses.",
    "authors": [
      "Xueqing Deng"
    ],
    "published": "2025-11-27",
    "updated": "2025-11-27",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00109v1",
    "doi": "10.5281/zenodo.17723615",
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.22050v1",
    "title": "Integrative characterization of the topography of V4 neural codes using deep learning approaches",
    "abstract": "Area V4 is a mid-level stage of the macaque ventral visual stream, known to encode intermediate visual features such as color, curvature, corners, texture, three-dimensional (3D) solids, and local form. Classical neurophysiological studies have typically examined these dimensions in isolation, contrasting V4 selectivity for shape versus texture, 3D solid surfaces versus two-dimensional (2D) flat patterns, or object form versus texture. Yet how these tunings relate to one another within individual neurons, and how they are jointly organized across the cortical surface, remain unknown. For instance, does a neuron selective for 2D contour-defined shape prefer 3D solid surfaces or 2D flat surfaces? How are preferences for such heterogeneous attributes arranged in a common topographic map? To address these questions, we leverage V4 \"digital twins\" -- deep neural network models fitted to large-scale, wide-field calcium imaging data comprising tens of thousands of natural images. These digital twins allow us to systematically probe not only the stimulus dimensions explored in earlier studies, but also new, multidimensional stimulus sets that reveal additional aspects of the V4 code. In this study, we find that neural pixels preferring 2D contour-defined shapes also tend to prefer 3D surface shape defined by shading or texture gradients and by object form. In contrast, pixels preferring 2D texture tend to prefer flat surfaces defined by uniform texture or reflectance. We propose that this division of labor suggests that V4 may decompose the encoding of geometrical shape and surface appearance of visual stimuli into distinct populations of neurons, organized as interleaved clusters in the V4 topographic map.",
    "authors": [
      "Yingjue Bian",
      "Tianye Wang",
      "Shiming Tang",
      "Tai Sing Lee"
    ],
    "published": "2025-11-27",
    "updated": "2025-11-27",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.22050v1",
    "doi": null,
    "journal_ref": null,
    "comment": "21 pages,11 figures,4 tables.Preprint",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.21940v1",
    "title": "Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection",
    "abstract": "Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.",
    "authors": [
      "Kiran Nair",
      "Hubert Cecotti"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "cs.LG",
      "eess.SP",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.21940v1",
    "doi": null,
    "journal_ref": null,
    "comment": "20 Pages, prepared for a Journal",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.21848v1",
    "title": "Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics",
    "abstract": "The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control.",
    "authors": [
      "Eric Leonardis",
      "Akira Nagamori",
      "Ayesha Thanawalla",
      "Yuanjia Yang",
      "Joshua Park",
      "Hutton Saunders",
      "Eiman Azim",
      "Talmo Pereira"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "cs.LG",
      "cs.RO",
      "q-bio.NC",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.21848v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Accepted at NeurIPS 2025 Workshop Data on the Brain & Mind: Concrete Applications of AI to Neuroscience and Cognitive Science. 12 pages, 4 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.21677v1",
    "title": "Lesion-Independent Thalamic Degeneration Identifies Intrinsically Vulnerable Nuclei Associated with Cognitive Impairment in Multiple Sclerosis",
    "abstract": "Cognitive impairment in multiple sclerosis (MS) is driven by both focal inflammation and compartmentalized neurodegeneration, yet the relative effect of lesion-independent thalamic atrophy on information processing speed (IPS) remains unclear. This retrospective cohort study included 100 participants with MS. Automatic segmentation techniques quantified lesion load and delineated 26 thalamic regions of interest (ROIs). Linear models compared associations between ROI volumes and Symbol Digit Modalities Test (SDMT) performance in lesion-adjusted and unadjusted models. Twenty-one of 26 ROIs showed significant SDMT associations before lesion adjustment; twelve remained significant after adjustment. Lesion-independent associations were observed in the global thalamus, sensory relay nuclei (ventral posterolateral, medial and lateral geniculate), and associative hubs (pulvinar and mediodorsal-parafascicular complex). These intrinsically vulnerable nuclei exhibited significantly lower lesion-mediated effects (13.4%) than those losing significance after adjustment (34.2%, p < 0.001). Our findings suggest that IPS impairment reflects heterogenous contributions from both primary and secondary degeneration, with nucleus-specific phenotyping potentially informing identification of higher risk individuals.",
    "authors": [
      "Arshya Pooladi-Darvish",
      "Heather Rosehart",
      "Marina R. Everest",
      "Ali R. Khan",
      "Sarah A. Morrow"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.21677v1",
    "doi": null,
    "journal_ref": null,
    "comment": "13 pages, 3 figures, 1 table",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.21674v1",
    "title": "Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism",
    "abstract": "Despite remarkable technological advances, AI systems may still benefit from biological principles, such as recurrent connectivity and energy-efficient mechanisms. Drawing inspiration from the brain, we present a biologically plausible extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. By translating the time-driven update scheme into an event-driven one, we integrate the learning rule into a simulation platform for large-scale spiking neural networks and demonstrate its applicability to tasks such as neuromorphic MNIST. We extend the model with prominent biological features such as continuous dynamics and weight updates, strict locality, and sparse connectivity. Our results show that biologically grounded constraints can inform the design of computationally efficient AI algorithms, offering scalability to millions of neurons without compromising learning performance. This work bridges machine learning and computational neuroscience, paving the way for sustainable, biologically inspired AI systems while advancing our understanding of brain-like learning.",
    "authors": [
      "Agnes Korcsak-Gorzo",
      "Jesús A. Espinoza Valverde",
      "Jonas Stapmanns",
      "Hans Ekkehard Plesser",
      "David Dahmen",
      "Matthias Bolten",
      "Sacha J. van Albada",
      "Markus Diesmann"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "pdf_url": "https://arxiv.org/pdf/2511.21674v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.21605v1",
    "title": "Detecting absence: A dedicated prediction-error signal emerging in the auditory thalamus",
    "abstract": "How does the brain know what is out there and what is not? Living organisms cannot rely solely on sensory signals for perception because they are noisy and ambiguous. To transform sensory signals into stable percepts, the brain uses its prior knowledge or beliefs. Current theories describe perceptual beliefs as probability distributions over the features of the stimuli, summarised by their mean and variance. Beliefs are updated by feature prediction errors: the mismatch between expected and observed feature values. This framework explains how the brain encodes unexpected changes in stimulus features (e.g., higher or lower pitch, stronger or weaker motion). How the brain updates beliefs about a stimulus' presence or absence is, however, unclear.   We propose that the detection of absence relies on a distinct form of prediction error dedicated to reducing the beliefs on stimulus occurrence. We call this signal absence prediction error. Using the human auditory system as a model for sensory processing, we developed a paradigm designed to test this hypothesis. fMRI results showed that absence prediction error is encoded in the auditory thalamus and cortex, indicating that absence is explicitly represented in subcortical sensory pathways. Moreover, while feature prediction error is already encoded in the auditory midbrain, absence prediction error was not, implying that absence-related error signals are supported by a different circuit.   These results identify a neural mechanism for the detection of sensory absence. Such mechanisms may be disrupted in conditions such as psychosis, where predictions about absence and presence are impaired.",
    "authors": [
      "Alejandro Tabas",
      "Heike Sönnichsen",
      "Sandeep Kaur",
      "Marco Meixner",
      "Katharina von Kriegstein"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.21605v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00090v1",
    "title": "Biomimetic Metamaterial-based Interface for Decoding Heterogeneous Mechanodermal Activity",
    "abstract": "Human skin acts as a dynamic biomechanical interface that conveys critical physiological and behavioural information through spatiotemporally distributed deformations. Due to the limited capabilities of current sensing technologies, the spatiotemporal diversity of its mechanical cues has remained underutilised to date, preventing these mechanisms from being used to capture and decode the full spectrum of underlying physiological states. In this work, we define this heterogeneous set of mechanical signals as mechanodermal activity (MDA) and introduce the biomimetic metamaterial-based interface (BMMI), an engineered auxetic metamaterial substrate that reproduces the microrelief and mechanoreceptor architecture of natural skin. The BMMI allows selective capture of diverse MDA signals from adjacent skin regions with simultaneous signal amplification and noise suppression, and permits straightforward modulation to accommodate various scenarios. Combined with bespoke algorithms, the wireless BMMI device decodes MDA accurately and robustly for multimodal communication interfaces, unleashing applications in healthcare monitoring and human-machine interaction.",
    "authors": [
      "Muzi Xu",
      "Jiaqi Zhang",
      "Chaoqun Dong",
      "Zibo Zhang",
      "Duanyang Li",
      "Wentian Yi",
      "Miaomiao Zou",
      "Chenyu Tang",
      "George G. Malliaras",
      "Luigi G. Occhipinti"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00090v1",
    "doi": null,
    "journal_ref": null,
    "comment": "26 pages, 5 figures, 55 references",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20990v1",
    "title": "Meditative absorption shifts brain dynamics toward criticality",
    "abstract": "Criticality describes a regime between order and chaos that supports flexible yet stable information processing. Here we examine whether neural dynamics can be volitionally shifted toward criticality through the self-regulation of attention. We examined ten experienced practitioners of meditation during a 10-day retreat, comparing refined states of meditative absorption, called the jhanas, to regular mindfulness of breathing. We collected electroencephalography (EEG) and physiological data during these practices and quantified the signal's dynamical properties using Lempel-Ziv complexity, signal entropy, chaoticity and long-range temporal correlations. In addition, we estimated perturbational sensitivity using a global auditory oddball mismatch negativity (MMN) during meditation. Relative to mindfulness, jhana was associated with pronounced self-reported sensory fading, slower respiration, higher neural signal diversity across multiple measures, reduced chaoticity, and enhanced MMN amplitude over frontocentral sites. Spectral analyses showed a flatter aperiodic one over f component and a frequency-specific reorganization of long-range temporal correlations. Together, increased diversity with reduced chaoticity and heightened deviance detection indicate a shift toward a metastable, near-critical regime during jhana. We propose an overlap of the phenomenology of jhana with minimal phenomenal experiences in terms of progressive attenuation of sensory content with preserved tonic alertness. Accordingly, our findings suggest that criticality is a candidate neurophysiological marker of the absorptive, minimal-content dimension of the minimal phenomenal experience.",
    "authors": [
      "Jonas Mago",
      "Joshua Brahinsky",
      "Mark Miller",
      "Charlotte Maschke",
      "Heleen A. Slagter",
      "Shaila Catherine",
      "Ruben E. Laukkonen",
      "B. Rael Cahn",
      "Matthew D. Sacchet",
      "Wangmo Dixey",
      "Richard Dixey",
      "Soham Rej",
      "Michael Lifshitz"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20990v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20950v1",
    "title": "Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures",
    "abstract": "Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity.",
    "authors": [
      "Yaoyue Wang",
      "Arian Ashourvan",
      "Guilherme Ramos",
      "Paul Bogdan",
      "Emily Pereira"
    ],
    "published": "2025-11-26",
    "updated": "2025-11-26",
    "categories": [
      "q-bio.QM",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.QM",
    "pdf_url": "https://arxiv.org/pdf/2511.20950v1",
    "doi": null,
    "journal_ref": null,
    "comment": "29 pages, 15 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20835v1",
    "title": "Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces",
    "abstract": "Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI.",
    "authors": [
      "Gao Wang",
      "Yingying Huang",
      "Lars Muckli",
      "Daniele Faccio"
    ],
    "published": "2025-11-25",
    "updated": "2025-11-25",
    "categories": [
      "q-bio.NC",
      "cs.HC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20835v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20532v1",
    "title": "MIMIC-MJX: Neuromechanical Emulation of Animal Behavior",
    "abstract": "The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.",
    "authors": [
      "Charles Y. Zhang",
      "Yuanjia Yang",
      "Aidan Sirbu",
      "Elliott T. T. Abe",
      "Emil Wärnberg",
      "Eric J. Leonardis",
      "Diego E. Aldarondo",
      "Adam Lee",
      "Aaditya Prasad",
      "Jason Foat",
      "Kaiwen Bian",
      "Joshua Park",
      "Rusham Bhatt",
      "Hutton Saunders",
      "Akira Nagamori",
      "Ayesha R. Thanawalla",
      "Kee Wui Huang",
      "Fabian Plum",
      "Hendrik K. Beck",
      "Steven W. Flavell",
      "David Labonte",
      "Blake A. Richards",
      "Bingni W. Brunton",
      "Eiman Azim",
      "Bence P. Ölveczky",
      "Talmo D. Pereira"
    ],
    "published": "2025-11-25",
    "updated": "2025-11-25",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20532v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20392v1",
    "title": "Mechano-chemical modeling of glia initiated secondary injury of neurons under mechanical load",
    "abstract": "Traumatic Brain Injury (TBI) results from an impact or concussion to the head with the injury being specifically characterized through pathological degradation at various biological length scales. Following injury, various mechanical modeling techniques have been proposed in the literature that seek to quantify neuronal-scale to tissue-scale metrics of brain damage. Broadly, the two categories of degradation encompass physiological deterioration of neurons and upregulation of chemical entities such as neurotransmitters which causes initiation of downstream pathophysiological effects. Despite the many contributing pathways, in this work, we delineate and model a potential glia-initiated injury pathway that leads to secondary injury. The goal of this work is to demonstrate a continuum framework which models the multiphysics of mechano-chemical interactions underlying TBI. Using a coupled PDE (partial differential equation) formulation and FEM (finite element method) discretization, the framework highlights evolution of field variables which spatio-temporally resolve mechanical metrics and chemical species across neuronal clusters. The modeling domain encompasses microglia, neurons and the extracellular matrix. The continuum framework used to model the mechano-chemical interactions assumes a three dimensional viscoelastic network to capture the mechanical response underlying proteins constituting the neuron microstructure and advection-diffusion equations modeling spatio-temporal evolution of chemical species. We use this framework to numerically estimate key concentrations of chemical species produced by the strain field. In this work, we identify key biomarkers within the labyrinth of molecular pathways and build a framework that captures the core mechano-chemical interactions. This framework is an attempt to quantify secondary injury and thus assist in developing targeted TBI treatments.",
    "authors": [
      "Debabrata Auddya",
      "Shiva Rudraraju"
    ],
    "published": "2025-11-25",
    "updated": "2025-11-25",
    "categories": [
      "q-bio.QM",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.QM",
    "pdf_url": "https://arxiv.org/pdf/2511.20392v1",
    "doi": null,
    "journal_ref": null,
    "comment": "26 pages, 10 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20179v1",
    "title": "Human-computer interactions predict mental health",
    "abstract": "Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.   We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.   Our results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online.",
    "authors": [
      "Veith Weilnhammer",
      "Jefferson Ortega",
      "David Whitney"
    ],
    "published": "2025-11-25",
    "updated": "2025-11-25",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20179v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20162v1",
    "title": "While recognizing actions, LMMs struggle to detect core interaction events",
    "abstract": "Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.",
    "authors": [
      "Daniel Harari",
      "Michael Sidorov",
      "Liel David",
      "Chen Shterental",
      "Abrham Kahsay Gebreselasie",
      "Muhammad Haris Khan"
    ],
    "published": "2025-11-25",
    "updated": "2025-11-25",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.20162v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.19548v1",
    "title": "When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics",
    "abstract": "Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, \"brain-based\" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies \"true\" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.",
    "authors": [
      "Yiven",
      "Zhu"
    ],
    "published": "2025-11-24",
    "updated": "2025-11-24",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "econ.GN",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.19548v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Durham Economic Journal 2025",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.18853v1",
    "title": "Decoding the science behind antioxidant -antiinflammatory nutraceuticals in stroke",
    "abstract": "Stroke is a leading cause of disability and death worldwide, with ischemic strokes accounting for nearly 80% of cases. Fewer than 5% of patients receive the sole validated pharmacotherapy, intravenous thrombolysis, highlighting the urgent need for novel therapies. Within this landscape, the exploration of natural molecules emerges as a promising avenue, particularly as a means to address limitations associated with conventional drugs. Nutraceuticals, bioactive compounds derived from food sources, offer a compelling prospect for health and wellness. The term nutraceutical reflects their dual potential in nutrition and pharmacotherapy, emphasizing their relevance to both disease prevention and treatment. Interestingly, many were initially recognized as ''natural preconditioners'', substances that prime the body for protection against stress or damage. In fact, numerous nutraceuticals have been shown to activate protective pathways similar to those triggered by preconditioning across various organs. Among nutraceuticals, omega-3 polyunsaturated fatty acids sourced from plants or fish, along with polyphenols, have emerged as particularly promising. Their consumption has been associated with a reduced risk of ischemic stroke, supported by numerous preclinical studies demonstrating their beneficial effects on cellular components within the neurovascular unit. This review explores the shared protective mechanisms of various nutraceuticals against key drivers of ischemic injury, including excitotoxicity, oxidative stress, apoptosis, and inflammation. By delineating these actions, the review highlights the potential of nutraceuticals as brain preconditioners that enhance neuroprotection, thereby mitigating the impact of cerebral ischemia in both preventive and therapeutic contexts.",
    "authors": [
      "Sophie Béraud-Dufour",
      "Ilona Legroux",
      "Thierry Coppola",
      "Patricia Lebrun",
      "Nicolas Blondeau"
    ],
    "published": "2025-11-24",
    "updated": "2025-11-24",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.18853v1",
    "doi": null,
    "journal_ref": "Conditioning Medicine, 2024, 7",
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00063v1",
    "title": "Exploring the changes in brain network SC-FC coupling patterns of partial sleep deprivation based on DTI-fMRI fusion analysis",
    "abstract": "Sleep disorder is a serious global public health issue, with cognitive-emotional dysfunction being a core symptom. The analysis of multimodal MRI data provides an effective method for detecting sleep deprivation-induced neural network abnormalities. The structure-function coupling (SC-FC) integrates functional connectivity with white matter structural information, which can enable comprehensive detection of brain network abnormalities and offer quantitative measures of sleep deprivation-induced neural damage. This study integrates diffusion tensor imaging (DTI) and resting-state fMRI (rs-fMRI) to systematically investigate brain network reorganization and their relationship with emotional functions in partial sleep deprivation (PSD). Our methodology employed DTI to construct structural connectivity (SC) networks and rs-fMRI to establish functional connectivity (FC) networks, then construct SC-FC coupling model . The experiment included 16 healthy controls (HC) and 20 PSD patients, with comprehensive whole-brain and nodal-level SC-FC analyses performed. The results show that (1) severe FC disruptions in PSD patients involving the limbic system, default mode network, sensorimotor network, and visual networks; (2) altered SC in default mode, sensorimotor, visual, language, and auditory networks; (3) significant SC-FC decoupling in these networks; and (4) strong correlations between these neural changes and clinical measures (KSQ and HADS scores). The SC-FC coupling approach achieved comprehensive detection of PSD-related network abnormalities. Compared to single-modal approaches, this integrated SC-FC analysis provides more comprehensive biomarkers for sleep-related emotional dysregulation. This innovative multimodal neuroimaging approach elucidates the neural mechanisms of SC-FC imbalance induced by PSD, establishing novel biomarkers for sleep-mediated emotional dysregulation.",
    "authors": [
      "Mengyuan Liu",
      "Jing Hu",
      "Zhenzhen Ru",
      "Ruomeng Quan",
      "Xu Zhang",
      "Ning Qiang",
      "Jin Li"
    ],
    "published": "2025-11-24",
    "updated": "2025-11-24",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00063v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.19520v1",
    "title": "Modeling Bioelectric State Transitions in Glial Cells: An ASAL-Inspired Computational Approach to Glioblastoma Initiation",
    "abstract": "Understanding how glioblastoma (GBM) emerges from initially healthy glial tissue requires models that integrate bioelectrical, metabolic, and multicellular dynamics. This work introduces an ASAL-inspired agent-based framework that simulates bioelectric state transitions in glial cells as a function of mitochondrial efficiency (Meff), ion-channel conductances, gap-junction coupling, and ROS dynamics. Using a 64x64 multicellular grid over 60,000 simulation steps, we show that reducing Meff below a critical threshold (~0.6) drives sustained depolarization, ATP collapse, and elevated ROS, reproducing key electrophysiological signatures associated with GBM. We further apply evolutionary optimization (genetic algorithms and MAP-Elites) to explore resilience, parameter sensitivity, and the emergence of tumor-like attractors. Early evolutionary runs converge toward depolarized, ROS-dominated regimes characterized by weakened electrical coupling and altered ionic transport. These results highlight mitochondrial dysfunction and disrupted bioelectric signaling as sufficient drivers of malignant-like transitions and provide a computational basis for probing the bioelectrical origins of oncogenesis.",
    "authors": [
      "Wiktoria Agata Pawlak"
    ],
    "published": "2025-11-24",
    "updated": "2025-11-24",
    "categories": [
      "physics.bio-ph",
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "physics.bio-ph",
    "pdf_url": "https://arxiv.org/pdf/2511.19520v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Thesis preprint. arXiv category: cs.NE",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.18325v1",
    "title": "Brain-MGF: Multimodal Graph Fusion Network for EEG-fMRI Brain Connectivity Analysis Under Psilocybin",
    "abstract": "Psychedelics, such as psilocybin, reorganise large-scale brain connectivity, yet how these changes are reflected across electrophysiological (electroencephalogram, EEG) and haemodynamic (functional magnetic resonance imaging, fMRI) networks remains unclear. We present Brain-MGF, a multimodal graph fusion network for joint EEG-fMRI connectivity analysis. For each modality, we construct graphs with partial-correlation edges and Pearson-profile node features, and learn subject-level embeddings via graph convolution. An adaptive softmax gate then fuses modalities with sample-specific weights to capture context-dependent contributions. Using the world's largest single-site psilocybin dataset, PsiConnect, Brain-MGF distinguishes psilocybin from no-psilocybin conditions in meditation and rest. Fusion improves over unimodal and non-adaptive variants, achieving 74.0% accuracy and 76.5% F1 score on meditation, and 76.0% accuracy with 85.8% ROC-AUC on rest. UMAP visualisations reveal clearer class separation for fused embeddings. These results indicate that adaptive graph fusion effectively integrates complementary EEG-fMRI information, providing an interpretable framework for characterising psilocybin-induced alterations in large-scale neural organisation.",
    "authors": [
      "Sin-Yee Yap",
      "Fuad Noman",
      "Junn Yong Loo",
      "Devon Stoliker",
      "Moein Khajehnejad",
      "Raphaël C. -W. Phan",
      "David L. Dowe",
      "Adeel Razi",
      "Chee-Ming Ting"
    ],
    "published": "2025-11-23",
    "updated": "2025-11-23",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.18325v1",
    "doi": null,
    "journal_ref": null,
    "comment": "5 pages",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.18294v1",
    "title": "MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding",
    "abstract": "Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \\textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.",
    "authors": [
      "Mengchun Zhang",
      "Kateryna Shapovalenko",
      "Yucheng Shao",
      "Eddie Guo",
      "Parusha Pradhan"
    ],
    "published": "2025-11-23",
    "updated": "2025-11-23",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.18294v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20692v1",
    "title": "The Human Brain as a Combinatorial Complex",
    "abstract": "We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data.",
    "authors": [
      "Valentina Sánchez",
      "Çiçek Güven",
      "Koen Haak",
      "Theodore Papamarkou",
      "Gonzalo Nápoles",
      "Marie Šafář Postma"
    ],
    "published": "2025-11-22",
    "updated": "2025-11-22",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20692v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Accepted as an Extended Abstract at the NeurReps Workshop, NeurIPS 2025",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2512.00058v1",
    "title": "Sight, smell and more: What cues do free-ranging dogs use for decision-making while scavenging?",
    "abstract": "Finding food is a fundamental activity for survival of all living organisms. Free-ranging dogs have been known to use their olfaction to assess the quality and type of available food but their use of visual ability in foraging is not well-documented. In the current study, we seek to remedy that by testing free-ranging dogs in a food-based choice test. We tested whether the dogs implemented hierarchical or synergistic usage of cues while finding food. We found limited prioritization of olfactory cues over visual cues in dichromatic choice tests but in phases with similar perceptual elements, the sensory choice was not clear. Furthermore, free-ranging dogs display a dynamic decision-making in unpredictable urban environments adopting a good-enough strategy during foraging. They prefer speed over accuracy, settling for intermediate quality food if their preferred food item is not available. These dogs also displayed left-bias during food choice. In multi-sensorial, natural setting multiple modulators like environmental noise, risk, and internal perceptual elements apart from food cues seem to be affecting the decision-making in dogs.",
    "authors": [
      "Rohan Sarkar",
      "Tuhin Subhra Pal",
      "Sharmistha Maji",
      "Srijaya Nandi",
      "Aesha Lahiri",
      "Ashim Kumar Basumatary",
      "Arpitha GP",
      "Nakul Wehare",
      "Nudrat Jahan",
      "Sharayu Jakhete",
      "Srinwanti Bandyopadhyay",
      "Rajdip Adhikary",
      "Tithi Paul",
      "Shreya Majumdar",
      "Anindita Bhadra"
    ],
    "published": "2025-11-22",
    "updated": "2025-11-22",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2512.00058v1",
    "doi": null,
    "journal_ref": null,
    "comment": "5 figures, original research",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.18057v1",
    "title": "The Hydraulic Brain: Understanding as Constraint-Release Phase Transition in Whole-Body Resonance",
    "abstract": "Current models treat physiological signals as noise corrupting neural computation. Previously, we showed that removing these \"artifacts\" eliminates 70% of predictive correlation, suggesting body signals functionally drive cognition. Here, we investigate the mechanism using high-density EEG (64 channels, 10 subjects, 500+ trials) during P300 target recognition.   Phase Slope Index revealed zero-lag synchrony (PSI=0.000044, p=0.061) with high coherence (0.316, p<0.0001). Ridge-regularized Granger causality showed massive bidirectional coupling (F=100.53 brain-to-body, F=62.76 body-to-brain) peaking simultaneously at 78.1ms, consistent with mutually coupled resonance pairs.   Time-resolved entropy analysis (200ms windows, 25ms steps) revealed triphasic dynamics: (1) constraint accumulation (0-78ms) building causal drive without entropy change (delta-S=-0.002 bits, p=0.75); (2) supercritical transition (100-600ms) triggering state expansion (58% directional increase, binomial p=0.002); (3) sustained metastability. Critically, transition magnitude was uncorrelated with resonance strength (r=-0.044, p=0.327), indicating binary threshold dynamics.   Understanding emerges through a thermodynamic sequence: brain-body resonance acts as a discrete gate triggering non-linear information integration. This architecture may fundamentally distinguish biological from artificial intelligence.   Keywords: embodied cognition, phase transitions, Granger causality, thermodynamics, neuromorphic computing, resonance dynamics, EEG artifacts",
    "authors": [
      "Ahmed Gamal Eldin"
    ],
    "published": "2025-11-22",
    "updated": "2025-11-22",
    "categories": [
      "q-bio.NC",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.18057v1",
    "doi": null,
    "journal_ref": null,
    "comment": "14 pages, 2 figures. Companion to arXiv:2511.10596",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20689v1",
    "title": "Morality in AI. A plea to embed morality in LLM architectures and frameworks",
    "abstract": "Large language models (LLMs) increasingly mediate human decision-making and behaviour. Ensuring LLM processing of moral meaning therefore has become a critical challenge. Current approaches rely predominantly on bottom-up methods such as fine-tuning and reinforcement learning from human feedback. We propose a fundamentally different approach: embedding moral meaning processing directly into the architectural mechanisms and frameworks of transformer-based models through top-down design principles. We first sketch a framework that conceptualizes attention as a dynamic interface mediating between structure and processing, contrasting with existing linear attention frameworks in psychology. We start from established biological-artificial attention analogies in neural architecture design to improve cognitive processing. We extend this analysis to moral processing, using Iris Murdoch's theory of loving attention (sustained, just observation that enables moral transformation by reseeing others with clarity and compassion) to philosophically discuss functional analogies between human and LLM moral processing. We formulate and evaluate potentially promising technical operationalizations to embed morality in LLM architectures and frameworks. We acknowledge the limitations of our exploration and give three key contributions. (1) We conceptualize attention as a dynamic system mechanism mediating between structure and processing. (2) Drawing on the Murdoch notion of loving attention, we outline technical pathways for embedding morality in LLMs, through modified training objectives, runtime weight adjustments, and architectural refinements to attention. (3) We argue that integrating morality into architectures and frameworks complements external, constraint-based methods. We conclude with a call for collaboration between transformer designers and philosophers engaged in AI ethics.",
    "authors": [
      "Gunter Bombaerts",
      "Bram Delisse",
      "Uzay Kaymak"
    ],
    "published": "2025-11-21",
    "updated": "2025-11-21",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20689v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.16465v2",
    "title": "Mesoscale tissue properties and electric fields in brain stimulation -- bridging the macroscopic and microscopic scales",
    "abstract": "Accurate simulations of electric fields (E-fields) in brain stimulation depend on tissue conductivity representations that link macroscopic assumptions with underlying microscopic tissue structure. Mesoscale conductivity variations can produce meaningful changes in E-fields and neural activation thresholds but remain largely absent from standard macroscopic models. Recent microscopic models have suggested substantial local E-field perturbations and could, in principle, inform mesoscale conductivity. However, the quantitative validity of microscopic models is limited by fixation-related tissue distortion and incomplete extracellular-space reconstruction. We outline approaches that bridge macro- and microscales to derive consistent mesoscale conductivity distributions, providing a foundation for accurate multiscale models of E-fields and neural activation in brain stimulation.",
    "authors": [
      "Boshuo Wang",
      "Torge Worbs",
      "Minhaj A. Hussain",
      "Aman S. Aberra",
      "Axel Thielscher",
      "Warren M. Grill",
      "Angel V. Peterchev"
    ],
    "published": "2025-11-20",
    "updated": "2025-11-24",
    "categories": [
      "physics.bio-ph",
      "physics.app-ph",
      "physics.med-ph",
      "q-bio.NC"
    ],
    "primary_category": "physics.bio-ph",
    "pdf_url": "https://arxiv.org/pdf/2511.16465v2",
    "doi": null,
    "journal_ref": null,
    "comment": "16 pages, 1 main figure, 6 appendix figures and 4 appendix tables Minor text and format edits. Corrected reference numbers within figure",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.16432v1",
    "title": "From generative AI to the brain: five takeaways",
    "abstract": "The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.",
    "authors": [
      "Claudius Gros"
    ],
    "published": "2025-11-20",
    "updated": "2025-11-20",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "pdf_url": "https://arxiv.org/pdf/2511.16432v1",
    "doi": null,
    "journal_ref": null,
    "comment": "Frontiers in Computational Neuroscience, in press",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.15985v1",
    "title": "Beat Frequency Induced Transitions in Synchronization Dynamics",
    "abstract": "In neurosciences, the brain processes information via the firing patterns of connected neurons operating across a spectrum of frequencies. To better understand the effects of these frequencies in the neuron dynamics, we have simulated a neuronal network of Izhikevich neurons to examine the interaction between frequency allocation and intermittent phase synchronization dynamics. As the synchronized population of neurons passes through a bifurcation, an additional frequency mode emerges, enabling a match in the mean frequency while retaining distinct most probable frequencies among neurons. Subsequently, the network intermittently transits between two patterns, one partially synchronized and the other unsynchronized. Through our analysis, we demonstrate that the frequency changes on the network lead to characteristic transition times between synchronization states. Moreover, these transitions adhere to beat frequency statistics when the neurons' frequencies differ by multiples of a frequency gap. Finally, our results can improve the performance in predicting transitions on problems where the beat frequency strongly influences the dynamics.",
    "authors": [
      "Gabriel Marghoti",
      "Thiago L. Prado",
      "Miguel A. F. Sanjuán",
      "Sergio R. Lopes"
    ],
    "published": "2025-11-20",
    "updated": "2025-11-20",
    "categories": [
      "q-bio.NC",
      "nlin.PS"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.15985v1",
    "doi": "10.1016/j.cnsns.2024.108243",
    "journal_ref": "Communications in Nonlinear Science and Numerical Simulation (2024) 128, 108243",
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.15338v1",
    "title": "Does the Muller-Lyer illusion induced by a goalkeeper configuration influence soccer penalty kicks?",
    "abstract": "In soccer penalty kicks, goalkeepers that orient their arms upward compared to downward can be misperceived as being taller - effectively recreating the Muller-Lyer illusion. The present study elaborates on previous research surrounding a potential illusion-induced bias in penalty kicks. Participants were exposed to goalkeeper configurations within a virtual goal including arms-parallel, arms-down, arms-out and arms-up. They separately judged the perceived size of the goalkeeper, and executed penalty kicks. The perceived size was near fully consistent with the intended illusion. Meanwhile, the penalty kicks indicated wider a horizontal position following arms-out, and lower vertical position following arms-up. Likewise, there was no relation between the biases expressed in perception and action. While goalkeepers can elicit a perceptual illusion, this does not extend to influencing the penalty kick itself. Instead, other contextual cues appeared more relevant including the proximity between the goalkeeper and goalposts, and with it, the available space in the goal.",
    "authors": [
      "Sufiaan Ahmed",
      "Tyrese Lindsay",
      "James W. Roberts"
    ],
    "published": "2025-11-19",
    "updated": "2025-11-19",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.15338v1",
    "doi": null,
    "journal_ref": null,
    "comment": "22 pages, 4 figures, accepted for publication in Movement & Sport Sciences - Science & Motricite",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.15298v1",
    "title": "Modulating the tennis racket grip during motor imagery influences serve accuracy and performance: A pilot study",
    "abstract": "There is now ample evidence that Motor Imagery (MI) contributes to improve motor performance. Previous studies provided evidence that its effectiveness remains dependent upon specific guidelines and recommendations. The body posture, as well as the context in which MI is performed, are notably critical and should be carefully considered. The present study in young tennis players (n=18) was designed to compare the effectiveness of performing MI of the serve while adopting a loose grip (congruent MI) or holding tightly and squeezing hard the racket (incongruent MI). Data revealed that both MI conditions contributed to enhance the number of successful serves (p<0.001) and the technical quality of the serve (p<0.001). Interestingly, comparing mean serve accuracy scores showed that performance gains were significantly higher in the loose MI group than in the tight MI group (p<0.02). These findings confirm the critical importance of the congruence between the content of the mental representation and the features of the corresponding actual movement. Overall, the present study further highlights the effectiveness of the loose grip while mentally rehearsing the serve, and might thus contribute to update and adjust specific MI guidelines and recommendations.",
    "authors": [
      "Aymeric Guillot",
      "Julien Gauthier",
      "Jeanne Lejoncour",
      "Franck Di Rienzo"
    ],
    "published": "2025-11-19",
    "updated": "2025-11-19",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.15298v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.15296v1",
    "title": "Detection of spiking motifs of arbitrary length in neural activity using bounded synaptic delays",
    "abstract": "In the context of spiking neural networks, temporal coding of signals is increasingly preferred over the rate coding hypothesis due to its advantages in processing speed and energy efficiency. In temporal coding, synaptic delays are crucial for processing signals with precise spike timings, known as spiking motifs. Synaptic delays are however bounded in the brain and can thus be shorter than the duration of a motif. This prevents the use of motif recognition methods that consist of setting heterogeneous delays to synchronize the input spikes on a single output neuron acting as a coincidence detector. To address this issue, we developed a method to detect motifs of arbitrary length using a sequence of output neurons connected to input neurons by bounded synaptic delays. Each output neuron is associated with a sub-motif of bounded duration. A motif is recognized if all sub-motifs are sequentially detected by the output neurons. We simulated this network using leaky integrate-and-fire neurons and tested it on the Spiking Heidelberg Digits (SHD) database, that is, on audio data converted to spikes via a cochlear model, as well as on random simultaneous motifs. The results demonstrate that the network can effectively recognize motifs of arbitrary length extracted from the SHD database. Our method features a correct detection rate of about 60% in presence of ten simultaneous motifs from the SHD dataset and up to 80% for five motifs, showing the robustness of the network to noise. Results on random overlapping patterns show that the recognition of a single motif overlapping with other motifs is most effective for a large number of input neurons and sparser motifs. Our method provides a foundation for more general models for the storage and retrieval of neural information of arbitrary temporal lengths.",
    "authors": [
      "Thomas Kronland-Martinet",
      "Stéphane Viollet",
      "Laurent U Perrinet"
    ],
    "published": "2025-11-19",
    "updated": "2025-11-19",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.15296v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14917v1",
    "title": "Teaching signal synchronization in deep neural networks with prospective neurons",
    "abstract": "Working memory requires the brain to maintain information from the recent past to guide ongoing behavior. Neurons can contribute to this capacity by slowly integrating their inputs over time, creating persistent activity that outlasts the original stimulus. However, when these slowly integrating neurons are organized hierarchically, they introduce cumulative delays that create a fundamental challenge for learning: teaching signals that indicate whether behavior was correct or incorrect arrive out-of-sync with the neural activity they are meant to instruct. Here, we demonstrate that neurons enhanced with an adaptive current can compensate for these delays by responding to external stimuli prospectively -- effectively predicting future inputs to synchronize with them. First, we show that such prospective neurons enable teaching signal synchronization across a range of learning algorithms that propagate error signals through hierarchical networks. Second, we demonstrate that this successfully guides learning in slowly integrating neurons, enabling the formation and retrieval of memories over extended timescales. We support our findings with a mathematical analysis of the prospective coding mechanism and learning experiments on motor control tasks. Together, our results reveal how neural adaptation could solve a critical timing problem and enable efficient learning in dynamic environments.",
    "authors": [
      "Nicoas Zucchet",
      "Qianqian Feng",
      "Axel Laborieux",
      "Friedemann Zenke",
      "Walter Senn",
      "João Sacramento"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-18",
    "categories": [
      "q-bio.NC",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14917v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14872v2",
    "title": "Maximum entropy models of neuronal populations at and off criticality",
    "abstract": "Empirical evidence of scaling behaviors in neuronal avalanches suggests that neuronal populations in the brain operate near criticality. Departure from scaling in neuronal avalanches has been used as a measure of distance to criticality and linked to brain disorders. A distinct line of evidence for brain criticality has come from thermodynamic signatures in maximum entropy (ME) models. Both of these approaches have been widely applied to the analysis of neuronal data. However, the relationship between deviations from avalanche criticality and thermodynamics of ME models of neuronal populations remains poorly understood. To address this question, we study spontaneous activity of organotypic rat cortex slice cultures in physiological and drug-induced hypo- or hyper-excitable conditions, which are classified as critical, subcritical and supercritical based on avalanche dynamics. We find that ME models inferred from critical cultures show signatures of criticality in thermodynamic quantities, e.g. specific heat. However, such signatures are also present, and equally strong, in models inferred from supercritical cultures -- despite their altered dynamics and poor functional performance. On the contrary, ME models inferred from subcritical cultures do not show thermodynamic hints of criticality. Importantly, we confirm these results using an interpretable neural network model that can be tuned to and away from avalanche criticality. Our findings indicate that maximum entropy models correctly distinguish subcritical from critical/supercritical systems. However, they may not be able to discriminate between avalanche criticality and supercriticality, although they may still capture a number of important features from neuronal data.",
    "authors": [
      "T. S. A. N. Simões",
      "F. Lombardi",
      "D. Plenz",
      "H. J. Herrmann",
      "L. de Arcangelis"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-20",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14872v2",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14555v2",
    "title": "DecNefLab: A Modular and Interpretable Simulation Framework for Decoded Neurofeedback",
    "abstract": "Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.   We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.   We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.   In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation.",
    "authors": [
      "Alexander Olza",
      "Roberto Santana",
      "David Soto"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-25",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14555v2",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14466v2",
    "title": "Effect of Dopamine in Enhancement of SNR of Cortico-Striatal-Thalamo-Cortical Loop Spiking",
    "abstract": "In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop have been investigated. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop.",
    "authors": [
      "Hadi Barati",
      "Ali Nayerifar",
      "Mehdi Fardmanesh"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-25",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14466v2",
    "doi": null,
    "journal_ref": null,
    "comment": "9 pages",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14453v1",
    "title": "Multi-network Topology Underlying Individual Language Learning Success",
    "abstract": "Adult language learning varies greatly among individuals. Traditionally associated with frontotemporal language regions, this variability is increasingly seen as stemming from distributed brain networks. However, the role of these networks and their topological organization in explaining these differences remains unclear. We hypothesize that graph-theory-based network analysis of intrinsic multimodal connectivities across multiple networks explains overall and component-specific variations in language learning. We tested this in 101 healthy adults who underwent resting-state fMRI, structural MRI, and diffusion tensor imaging before seven days of six artificial language training tasks. We identified one dominant general learning component shared across tasks and five task-specific ones. Cross-validated predictive models used multimodal multi-network graph-theoretic metrics to predict final learning outcomes (LO) and rates (LR). We significantly predicted the LO and LR of the general component, which were primarily contributed by dorsal attention and frontoparietal networks. Nodal local efficiency was the most consistent predictor, with additional contributions from node clustering coefficient and network centrality for LR, highlighting local robustness, mesoscale network segregation, and global influence in explaining individual differences. Only task-specific word learning LO was predictable, relying on default mode and frontoparietal hubs with high betweenness centrality and efficiency. These findings demonstrate that intrinsic network topologies underlie differences in language learning success, supporting a multiple-systems hypothesis in which attentional-control networks interact with default and subcortical systems to shape learning trajectories. This advances mechanistic understanding and paves the way for personalized language education.",
    "authors": [
      "Peilun Song",
      "Shuguang Yang",
      "Xiujuan Geng",
      "Zhenzhong Gan",
      "Suiping Wang",
      "Gangyi Feng"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-18",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14453v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14188v3",
    "title": "A region-specific brain dysfunction underlies cognitive impairment in long COVID brain fog",
    "abstract": "Long COVID \"brain fog\" is a common and debilitating subjective syndrome often associated with persistent cognitive impairment after COVID-19 infection. Here we identify a specific regional brain dysfunction that mediates this cognitive impairment and provide evidence that targeted neuromodulation improves this deficit. In 120 patients with long COVID brain fog, we found an aberrant perceptual processing pattern. Patients with more severe brain fog committed significantly more false alarms (impulsive responses to non-signals) despite preserved overall accuracy. Both high-density (128-channel) EEG and structural MRI analyses provided converging evidence of a right inferior insula deficit, characterized by a blunted neural monitoring signal and cortical atrophy. We confirmed this deficit in a separate 796-participant UK Biobank longitudinal COVID re-imaging cohort, where COVID-19 survivors also showed selective impairment on a perceptual processing task and corresponding longitudinal atrophy of the right inferior insula compared with healthy controls. Finally, in a proof-of-principle randomized, sham-controlled trial (n = 40), a non-invasive, excitatory theta-burst ultrasound stimulation protocol targeting the right inferior insula rescued the perceptual deficit by reducing false alarms. These findings provide evidence of a causal role for right inferior insula dysfunction in long COVID-related perceptual impairment and show that modulation of this region can rescue the deficit, establishing it as a novel therapeutic target for long COVID cognitive impairment.",
    "authors": [
      "Jinhao Yang",
      "Shaojiong Zhou",
      "Zhibin Wang",
      "Jiahua Xu",
      "Jia Chen",
      "Zhouqian Yin",
      "Tao Wei",
      "Chaofan Geng",
      "Xiaoduo Liu",
      "Xiang Li",
      "Xiaoyu Zhou",
      "Kun Li",
      "Ruolei Gu",
      "Raymond Dolan",
      "Yi Tang",
      "Yunzhe Liu"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-30",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14188v3",
    "doi": null,
    "journal_ref": null,
    "comment": "58 pages, 6 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.14065v1",
    "title": "Intrinsic Resonance depends on Network Size of Coupled-Delayed Interacting Oscillators",
    "abstract": "The collective frequency that emerges from synchronized neuronal populations--the network resonance--shows a systematic relationship with brain size: whole-brain's large networks oscillate slowly, whereas finer parcellations of fixed volume exhibit faster rhythms. This resonance-size scaling has been reported in delayed neural mass models and human neuroimaging, yet the physical mechanism remained unresolved. Here we show that size-dependent resonance follows directly from propagation delays in delay-coupled phase oscillators. Starting from a Kuramoto model with heterogeneous delays, we linearize around the near-synchronous solution and obtain a closed-form approximation linking the resonance $Ω$ to the mean delay and the effective coupling field. The analysis predicts a generic scaling law: $Ω\\approx (\\sum_j c_{ij} τ)^{-1}$, so resonance is delay-limited and therefore depends systematically on geometric size or parcellation density. We evaluate four growth scenarios--expanding geometry, fixed-volume parcellation, constant geometry, and an unphysical reference case--and show that only geometry-consistent scaling satisfies the analytical prediction. Numerical simulations with heterogeneous delays validate the law and quantify its error as a function of delay dispersion. These results identify a minimal physical mechanism for size-dependent cortical resonance and provide an analytical framework that unifies numeric simulation outputs.",
    "authors": [
      "Felipe A. Torres",
      "Alejandro Weinstein",
      "Jesus M. Cortes",
      "Wael El-Deredy"
    ],
    "published": "2025-11-18",
    "updated": "2025-11-18",
    "categories": [
      "q-bio.NC",
      "eess.SY"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.14065v1",
    "doi": null,
    "journal_ref": null,
    "comment": "16 pages, 3 figures: 2 figures in the main text and 1 figure in the appendix",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.13954v1",
    "title": "A Brain Wave Encodes a Thousand Tokens: Modeling Inter-Cortical Neural Interactions for Effective EEG-based Emotion Recognition",
    "abstract": "Human emotions are difficult to convey through words and are often abstracted in the process; however, electroencephalogram (EEG) signals can offer a more direct lens into emotional brain activity. Recent studies show that deep learning models can process these signals to perform emotion recognition with high accuracy. However, many existing approaches overlook the dynamic interplay between distinct brain regions, which can be crucial to understanding how emotions unfold and evolve over time, potentially aiding in more accurate emotion recognition. To address this, we propose RBTransformer, a Transformer-based neural network architecture that models inter-cortical neural dynamics of the brain in latent space to better capture structured neural interactions for effective EEG-based emotion recognition. First, the EEG signals are converted into Band Differential Entropy (BDE) tokens, which are then passed through Electrode Identity embeddings to retain spatial provenance. These tokens are processed through successive inter-cortical multi-head attention blocks that construct an electrode x electrode attention matrix, allowing the model to learn the inter-cortical neural dependencies. The resulting features are then passed through a classification head to obtain the final prediction. We conducted extensive experiments, specifically under subject-dependent settings, on the SEED, DEAP, and DREAMER datasets, over all three dimensions, Valence, Arousal, and Dominance (for DEAP and DREAMER), under both binary and multi-class classification settings. The results demonstrate that the proposed RBTransformer outperforms all previous state-of-the-art methods across all three datasets, over all three dimensions under both classification settings. The source code is available at: https://github.com/nnilayy/RBTransformer.",
    "authors": [
      "Nilay Kumar",
      "Priyansh Bhandari",
      "G. Maragatham"
    ],
    "published": "2025-11-17",
    "updated": "2025-11-17",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.13954v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.13899v1",
    "title": "A Disentangled Low-Rank RNN Framework for Uncovering Neural Connectivity and Dynamics",
    "abstract": "Low-rank recurrent neural networks (lrRNNs) are a class of models that uncover low-dimensional latent dynamics underlying neural population activity. Although their functional connectivity is low-rank, it lacks disentanglement interpretations, making it difficult to assign distinct computational roles to different latent dimensions. To address this, we propose the Disentangled Recurrent Neural Network (DisRNN), a generative lrRNN framework that assumes group-wise independence among latent dynamics while allowing flexible within-group entanglement. These independent latent groups allow latent dynamics to evolve separately, but are internally rich for complex computation. We reformulate the lrRNN under a variational autoencoder (VAE) framework, enabling us to introduce a partial correlation penalty that encourages disentanglement between groups of latent dimensions. Experiments on synthetic, monkey M1, and mouse voltage imaging data show that DisRNN consistently improves the disentanglement and interpretability of learned neural latent trajectories in low-dimensional space and low-rank connectivity over baseline lrRNNs that do not encourage partial disentanglement.",
    "authors": [
      "Chengrui Li",
      "Yunmiao Wang",
      "Yule Wang",
      "Weihan Li",
      "Dieter Jaeger",
      "Anqi Wu"
    ],
    "published": "2025-11-17",
    "updated": "2025-11-17",
    "categories": [
      "q-bio.NC",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.13899v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.13668v1",
    "title": "Integrative Model for Interoception and Exteroception: predictive coding, points of modulation, and testable predictions",
    "abstract": "Interoception and exteroception provide continuous feedback about the body and the environment, yet how they are dynamically integrated within a unified predictive coding framework has remained under-specified. This paper develops and empirically validates an integrative predictive coding model that treats interoceptive and exteroceptive inference as parallel hierarchical systems exchanging precision-weighted prediction errors. Within this framework, arbitration between the two streams is governed by relative precision weights (w) and integrated within the anterior insula (AIC) and anterior cingulate cortex (ACC). Computational simulations of the model reproduced biologically plausible dynamics: prediction errors decayed exponentially while arbitration weights self-normalized toward equilibrium (w = 0.5), demonstrating stable convergence and coherent integration. Simulated anxiety and PTSD profiles, characterized respectively by interoceptive and exteroceptive overweighting, yielded rigid, self-sustaining imbalances (w to 1 or w to 0) and slowed recalibration. Empirical application of the arbitration equation to published EEG-fMRI datasets further validated the model. The framework contributes a unifying account of how dysregulated precision weighting may underlie anxiety (overweighted interoception) and PTSD (underweighted interoception). Building on this validation, a proposed experimental paradigm is outlined to test the model's predictions in humans. It examines recalibration across anxiety, neutral, and PTSD groups following targeted interoceptive or exteroceptive therapies. Key predictions include identifiable neural markers of coherence, modulation of heartbeat-evoked potentials by vagal stimulation, and precision-sensitive behavioral signatures in interoceptive-exteroceptive congruency tasks.",
    "authors": [
      "Pranjal Balar",
      "Sundeep Kapila"
    ],
    "published": "2025-11-17",
    "updated": "2025-11-17",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.13668v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.12715v1",
    "title": "Predicting upcoming visual features during eye movements yields scene representations aligned with human visual cortex",
    "abstract": "Scenes are complex, yet structured collections of parts, including objects and surfaces, that exhibit spatial and semantic relations to one another. An effective visual system therefore needs unified scene representations that relate scene parts to their location and their co-occurrence. We hypothesize that this structure can be learned self-supervised from natural experience by exploiting the temporal regularities of active vision: each fixation reveals a locally-detailed glimpse that is statistically related to the previous one via co-occurrence and saccade-conditioned spatial regularities. We instantiate this idea with Glimpse Prediction Networks (GPNs) -- recurrent models trained to predict the feature embedding of the next glimpse along human-like scanpaths over natural scenes. GPNs successfully learn co-occurrence structure and, when given relative saccade location vectors, show sensitivity to spatial arrangement. Furthermore, recurrent variants of GPNs were able to integrate information across glimpses into a unified scene representation. Notably, these scene representations align strongly with human fMRI responses during natural-scene viewing across mid/high-level visual cortex. Critically, GPNs outperform architecture- and dataset-matched controls trained with explicit semantic objectives, and match or exceed strong modern vision baselines, leaving little unique variance for those alternatives. These results establish next-glimpse prediction during active vision as a biologically plausible, self-supervised route to brain-aligned scene representations learned from natural visual experience.",
    "authors": [
      "Sushrut Thorat",
      "Adrien Doerig",
      "Alexander Kroner",
      "Carmen Amme",
      "Tim C. Kietzmann"
    ],
    "published": "2025-11-16",
    "updated": "2025-11-16",
    "categories": [
      "q-bio.NC",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.12715v1",
    "doi": null,
    "journal_ref": null,
    "comment": "28 pages, 12 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.11480v2",
    "title": "Inferring response times of perceptual decisions with Poisson variational autoencoders",
    "abstract": "Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs.",
    "authors": [
      "Hayden R. Johnson",
      "Anastasia N. Krouglova",
      "Hadi Vafaii",
      "Jacob L. Yates",
      "Pedro J. Gonçalves"
    ],
    "published": "2025-11-14",
    "updated": "2025-11-24",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.11480v2",
    "doi": null,
    "journal_ref": null,
    "comment": "To appear at the NeurIPS 2025 Workshop on Data on the Brain \\& Mind",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.11463v1",
    "title": "A universal theorem of sensory information",
    "abstract": "A universal theorem of sensory information, analogous to the second law of thermodynamics, is derived. Beginning from a minimal description of a sensory neuron, a state-space representation of firing rate emerges naturally from Shannon's measure of information. A special case of this formulation predicts a previously unknown inequality governing sensory adaptation, which was confirmed across different modalities, species, and experimental conditions. Further analysis shows that the firing rate behaves like a state function in thermodynamics, leading to an entropy production equation from which a general law follows: any closed cycle of stimulation yields a non-negative net gain of sensory information.",
    "authors": [
      "Willy Wong"
    ],
    "published": "2025-11-14",
    "updated": "2025-11-14",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.11463v1",
    "doi": null,
    "journal_ref": null,
    "comment": "12 pages, 2 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.20670v1",
    "title": "Phase Plane Analysis of Firing Patterns in the Adaptive Exponential Integrate-and-Fire Model",
    "abstract": "The Adaptive Exponential Integrate-and-Fire (AdEx) model is a simplified framework that effectively characterizes neuronal electrical activity. The aim of this paper is to employ phase plane analysis to systematically investigate diverse firing patterns generated by the AdEx model under varying parametric conditions. We first introduce the fundamental equations and parameter configurations of the AdEx model to numerically simulate the six representative firing patterns in the AdEx model. And then we use phase plane analysis to explore the dynamic mechanism of these firing patterns under different input currents and parametric conditions. Our findings demonstrate that the AdEx model can simulate multiple firing patterns, including Tonic Spiking, Adapting, Initial Bursting, Busting, Transient Spiking and Delayed Spiking firing patterns. These results not only advance the understanding of complex electrophysiological phenomena in neurons but also provide theoretical foundations for applications in many fields like neuromorphic computing and brain-computer interfaces.",
    "authors": [
      "Wu-Fei Zhang"
    ],
    "published": "2025-11-14",
    "updated": "2025-11-14",
    "categories": [
      "q-bio.NC",
      "physics.bio-ph"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.20670v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.10935v1",
    "title": "CAT-Net: A Cross-Attention Tone Network for Cross-Subject EEG-EMG Fusion Tone Decoding",
    "abstract": "Brain-computer interface (BCI) speech decoding has emerged as a promising tool for assisting individuals with speech impairments. In this context, the integration of electroencephalography (EEG) and electromyography (EMG) signals offers strong potential for enhancing decoding performance. Mandarin tone classification presents particular challenges, as tonal variations convey distinct meanings even when phonemes remain identical. In this study, we propose a novel cross-subject multimodal BCI decoding framework that fuses EEG and EMG signals to classify four Mandarin tones under both audible and silent speech conditions. Inspired by the cooperative mechanisms of neural and muscular systems in speech production, our neural decoding architecture combines spatial-temporal feature extraction branches with a cross-attention fusion mechanism, enabling informative interaction between modalities. We further incorporate domain-adversarial training to improve cross-subject generalization. We collected 4,800 EEG trials and 4,800 EMG trials from 10 participants using only twenty EEG and five EMG channels, demonstrating the feasibility of minimal-channel decoding. Despite employing lightweight modules, our model outperforms state-of-the-art baselines across all conditions, achieving average classification accuracies of 87.83% for audible speech and 88.08% for silent speech. In cross-subject evaluations, it still maintains strong performance with accuracies of 83.27% and 85.10% for audible and silent speech, respectively. We further conduct ablation studies to validate the effectiveness of each component. Our findings suggest that tone-level decoding with minimal EEG-EMG channels is feasible and potentially generalizable across subjects, contributing to the development of practical BCI applications.",
    "authors": [
      "Yifan Zhuang",
      "Calvin Huang",
      "Zepeng Yu",
      "Yongjie Zou",
      "Jiawei Ju"
    ],
    "published": "2025-11-14",
    "updated": "2025-11-14",
    "categories": [
      "cs.SD",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.SD",
    "pdf_url": "https://arxiv.org/pdf/2511.10935v1",
    "doi": null,
    "journal_ref": null,
    "comment": "This is the extended version with technical appendices. The version of record appears in AAAI-26. Please cite the AAAI version",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.10835v1",
    "title": "What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference",
    "abstract": "Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency.",
    "authors": [
      "Domenico Maisto",
      "Davide Nuzzi",
      "Giovanni Pezzulo"
    ],
    "published": "2025-11-13",
    "updated": "2025-11-13",
    "categories": [
      "nlin.AO",
      "cs.MA",
      "math.OC",
      "q-bio.NC"
    ],
    "primary_category": "nlin.AO",
    "pdf_url": "https://arxiv.org/pdf/2511.10835v1",
    "doi": null,
    "journal_ref": null,
    "comment": "18 pages, 3 figures, appendix",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.10757v1",
    "title": "Habit learning is associated with efficiently controlled network dynamics in naive macaque monkeys",
    "abstract": "Primates utilize distributed neural circuits to learn habits in uncertain environments, but the underlying mechanisms remain poorly understood. We propose a formal theory of network energetics explaining how brain states influence sequential behavior. We test our theory on multi-unit recordings from the caudate nucleus and cortical regions of macaques performing a motor habit task. The theory predicts the energy required to transition between brain states represented by trial-specific firing rates across channels, assuming activity spreads through effective connections. We hypothesized that habit formation would correlate with lower control energy. Consistent with this, we observed smaller energy requirements for transitions between similar saccade patterns and those of intermediate complexity, and sessions exploiting fewer patterns. Simulations ruled out confounds from neurons' directional tuning. Finally, virtual lesioning demonstrated robustness of observed relationships between control energy and behavior. This work paves the way for examining how behavior arises from changing activity in distributed circuitry.",
    "authors": [
      "Julia K. Brynildsen",
      "Panagiotis Fotiadis",
      "Karol P. Szymula",
      "Jason Z. Kim",
      "Fabio Pasqualetti",
      "Ann M. Graybiel",
      "Theresa M. Desrochers",
      "Dani S. Bassett"
    ],
    "published": "2025-11-13",
    "updated": "2025-11-13",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.10757v1",
    "doi": null,
    "journal_ref": null,
    "comment": "This manuscript updates and substantially extends analyses originally presented in arXiv:2006.14565v1. Supplementary Material is provided as an ancillary file",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.10261v1",
    "title": "Representation learning in cerebellum-like structures",
    "abstract": "Animals use past experiences to adapt future behavior. To enable this rapid learning, vertebrates and invertebrates have evolved analogous neural structures like the vertebrate cerebellum or insect mushroom body. A defining feature of these circuits is a large expansion layer, which re-codes sensory inputs to improve pattern separation, a prerequisite to learn non-overlapping associations between relevant sensorimotor inputs and adaptive changes in behavior. However, classical models of associative learning treat expansion layers as static, assuming that associations are learned through plasticity at the output synapses. Here, we review emerging evidence that also highlights the importance of plasticity within the expansion layer for associative learning. Because the underlying plasticity mechanisms and principles of this representation learning are only emerging, we systematically compare experimental data from two well-studied circuits for expansion coding -- the cerebellum granule layer and the mushroom body calyx. The data indicate remarkably similar interneuron circuits, dendritic morphology and plasticity mechanisms between both systems that hint at more general principles for representation learning. Moreover, the data show strong overlap with recent theoretical advances that consider interneuron circuits and dendritic computations for representation learning. However, they also hint at an interesting interaction of stimulus-induced, non-associative and reinforced, associative mechanisms of plasticity that is not well understood in current theories of representation learning. Therefore, studying expansion layer plasticity will be important to elucidate the mechanisms and full potential of representation learning for behavioral adaptation.",
    "authors": [
      "Lucas Rudelt",
      "Fabian Mikulasch",
      "Viola Priesemann",
      "André Ferreira Castro"
    ],
    "published": "2025-11-13",
    "updated": "2025-11-13",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.10261v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.10184v1",
    "title": "Theoretical Analysis of Resource-Induced Phase Transitions in Estimation Strategies",
    "abstract": "Organisms adapt to volatile environments by integrating sensory information with internal memory, yet their information processing is constrained by resource limitations. Such limitations can fundamentally alter optimal estimation strategies in biological systems. For example, recent experiments suggest that organisms exhibit nonmonotonic phase transitions between memoryless and memory-based estimation strategies depending on sensory reliability. However, an analytical understanding of these resource-induced phase transitions is still missing. This Letter presents an analytical characterization of resource-induced phase transitions in optimal estimation strategies. Our result identifies the conditions under which resource limitations alter estimation strategies and analytically reveals the mechanism underlying the emergence of discontinuous, nonmonotonic, and scaling behaviors. These results provide a theoretical foundation for understanding how limited resources shape information processing in biological systems.",
    "authors": [
      "Takehiro Tottori",
      "Tetsuya J. Kobayashi"
    ],
    "published": "2025-11-13",
    "updated": "2025-11-13",
    "categories": [
      "physics.bio-ph",
      "math.OC",
      "q-bio.NC",
      "q-bio.SC"
    ],
    "primary_category": "physics.bio-ph",
    "pdf_url": "https://arxiv.org/pdf/2511.10184v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.09949v1",
    "title": "Imaging the Topology of Dynamic Brain Connectivity",
    "abstract": "Functional brain connectivity changes dynamically over time, making its representation challenging for learning on non-Euclidean data. We present a framework that encodes dynamic functional connectivity as an image representation of evolving network topology. Persistent graph homology summarizes global organization across scales, yielding Wasserstein distance-preserving embeddings stable under resolution changes. Stacking these embeddings forms a topological image that captures temporal reconfiguration of brain networks. This design enables convolutional architectures and transfer learning from pretrained foundational models to operate effectively under limited and imbalanced data. Applied to early Alzheimer's detection, the approach achieves clinically meaningful accuracy, establishing a principled foundation for imaging dynamic brain topology.",
    "authors": [
      "Peilin He",
      "Tananun Songdechakraiwut"
    ],
    "published": "2025-11-13",
    "updated": "2025-11-13",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.09949v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.09765v1",
    "title": "Brian Intensify: An Adaptive Machine Learning Framework for Auditory EEG Stimulation and Cognitive Enhancement in FXS",
    "abstract": "Neurodevelopmental disorders such as Fragile X Syndrome (FXS) and Autism Spectrum Disorder (ASD) are characterized by disrupted cortical oscillatory activity, particularly in the alpha and gamma frequency bands. These abnormalities are linked to deficits in attention, sensory processing, and cognitive function. In this work, we present an adaptive machine learning-based brain-computer interface (BCI) system designed to modulate neural oscillations through frequency-specific auditory stimulation to enhance cognitive readiness in individuals with FXS. EEG data were recorded from 38 participants using a 128-channel system under a stimulation paradigm consisting of a 30-second baseline (no stimulus) followed by 60-second auditory entrainment episodes at 7Hz, 9Hz, 11Hz, and 13Hz. A comprehensive analysis of power spectral features (Alpha, Gamma, Delta, Theta, Beta) and cross-frequency coupling metrics (Alpha-Gamma, Alpha-Beta, etc.) was conducted. The results identified Peak Alpha Power, Peak Gamma Power, and Alpha Power per second per channel as the most discriminative biomarkers. The 13Hz stimulation condition consistently elicited a significant increase in Alpha activity and suppression of Gamma activity, aligning with our optimization objective. A supervised machine learning framework was developed to predict EEG responses and dynamically adjust stimulation parameters, enabling real-time, subject-specific adaptation. This work establishes a novel EEG-driven optimization framework for cognitive neuromodulation, providing a foundational model for next-generation AI-integrated BCI systems aimed at personalized neurorehabilitation in FXS and related disorders.",
    "authors": [
      "Zag ElSayed",
      "Grace Westerkamp",
      "Jack Yanchen Liu",
      "Ernest Pedapati"
    ],
    "published": "2025-11-12",
    "updated": "2025-11-12",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.09765v1",
    "doi": null,
    "journal_ref": null,
    "comment": "7 pages, 4 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.09506v2",
    "title": "A thermoinformational formulation for the description of neuropsychological systems",
    "abstract": "Complex systems produce high-dimensional signals that lack macroscopic variables analogous to entropy, temperature, or free energy. This work introduces a thermoinformational formulation that derives entropy, internal energy, temperature, and Helmholtz free energy directly from empirical microstate distributions of arbitrary datasets. The approach provides a data-driven description of how a system reorganizes, exchanges information, and moves between stable and unstable states. Applied to dual-EEG recordings from mother-infant dyads performing the A-not-B task, the formulation captures increases in informational heat during switches and errors, and reveals that correct choices arise from more stable, low-temperature states. In an independent optogenetic dam-pup experiment, the same variables separate stimulation conditions and trace coherent trajectories in thermodynamic state space. Across both human and rodent systems, this thermoinformational formulation yields compact and physically interpretable macroscopic variables that generalize across species, modalities, and experimental paradigms.",
    "authors": [
      "George-Rafael Domenikos",
      "Victoria Leong"
    ],
    "published": "2025-11-12",
    "updated": "2025-11-28",
    "categories": [
      "q-bio.NC",
      "stat.AP"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.09506v2",
    "doi": null,
    "journal_ref": null,
    "comment": "Preprint. Submitted to PNAS on 30 Nov 2025 29 pages, 6 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.09290v1",
    "title": "Multi-step Predictive Coding Leads To Simplicity Bias",
    "abstract": "Predictive coding is a framework for understanding the formation of low-dimensional internal representations mirroring the environment's latent structure. The conditions under which such representations emerge remain unclear. In this work, we investigate how the prediction horizon and network depth shape the solutions of predictive coding tasks. Using a minimal abstract setting inspired by prior work, we show empirically and theoretically that sufficiently deep networks trained with multi-step prediction horizons consistently recover the underlying latent structure, a phenomenon explained through the Ordinary Least Squares estimator structure and biases in learning dynamics. We then extend these insights to nonlinear networks and complex datasets, including piecewise linear functions, MNIST, multiple latent states and higher dimensional state geometries. Our results provide a principled understanding of when and why predictive coding induces structured representations, bridging the gap between empirical observations and theoretical foundations.",
    "authors": [
      "Aviv Ratzon",
      "Omri Barak"
    ],
    "published": "2025-11-12",
    "updated": "2025-11-12",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.09290v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.09243v1",
    "title": "Characterizing sleep stages through the complexity-entropy plane in human intracranial data and in a whole-brain model",
    "abstract": "Characterizing the brain dynamics during different cortical states can reveal valuable information about its patterns across various cognitive processes. In particular, studying the differences between awake and sleep stages can shed light on the understanding of brain processes essential for physical and mental well-being, such as memory consolidation, information processing, and fatigue recovery. Alterations in these patterns may indicate disorders and pathologies such as obstructive sleep apnea, narcolepsy, as well as Alzheimer's and Parkinson's diseases. Here, we analyze time series obtained from intracranial recordings of 106 patients, covering four sleep stages: Wake, N2, N3, and REM. Intracranial electroencephalography (iEEG), which can include electrocorticography (ECoG) and depth recordings, represents the state-of-the-art measurements of brain activity, offering unparalleled spatial and temporal resolution for investigating neural dynamics. We characterize the signals using Bandt and Pompe symbolic methodology to calculate the Weighted Permutation Entropy (WPE) and the Statistical Complexity Measure (SCM) based on the Jensen and Shannon disequilibrium. By mapping the data onto the complexity-entropy plane, we observe that each stage occupies a distinct region, revealing its own dynamic signature. We show that our empirical results can be reproduced by a whole-brain computational model, in which each cortical region is described by a mean-field formulation based on networks of Adaptive Exponential Integrate-and-Fire (AdEx) neurons, adjusting the adaptation parameter to simulate the different sleep stages. Finally, we show that a classification approach using Support Vector Machine (SVM) provides high accuracy in distinguishing between cortical states.",
    "authors": [
      "Helena Bordini de Lucas",
      "Leonardo Dalla Porta",
      "Alain Destexhe",
      "Maria V. Sanchez-Vives",
      "Osvaldo A. Rosso",
      "Cláudio R. Mirasso",
      "Fernanda Selingardi Matias"
    ],
    "published": "2025-11-12",
    "updated": "2025-11-12",
    "categories": [
      "q-bio.NC",
      "physics.bio-ph"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.09243v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.08847v1",
    "title": "Data-driven spatiotemporal modeling reveals personalized trajectories of cortical atrophy in Alzheimer's disease",
    "abstract": "Alzheimer's disease (AD) is characterized by the progressive spread of pathology across brain networks, yet forecasting this cascade at the individual level remains challenging. We present a personalized graph-based dynamical model that captures the spatiotemporal evolution of cortical atrophy from longitudinal MRI and PET data. The approach constructs individualized brain graphs and learns the dynamics driving regional neurodegeneration. Applied to 1,891 participants from the Alzheimer's Disease Neuroimaging Initiative, the model accurately predicts key AD biomarkers -- including amyloid-beta, tau, neurodegeneration, and cognition -- outperforming clinical and neuroimaging benchmarks. Patient-specific parameters reveal distinct progression subtypes and anticipate future cognitive decline more effectively than standard biomarkers. Sensitivity analysis highlights regional drivers of disease spread, reproducing known temporolimbic and frontal vulnerability patterns. This network-based digital twin framework offers a quantitative, personalized paradigm for AD trajectory prediction, with implications for patient stratification, clinical trial design, and targeted therapeutic development.",
    "authors": [
      "Chunyan Li",
      "Yutong Mao",
      "Xiao Liu",
      "Wenrui Hao"
    ],
    "published": "2025-11-12",
    "updated": "2025-11-12",
    "categories": [
      "q-bio.NC",
      "math.DS"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.08847v1",
    "doi": null,
    "journal_ref": null,
    "comment": "23 pages, 7 figures and 3 tables",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.08531v1",
    "title": "Cognition as least action: the Physarum Lagrangian",
    "abstract": "The slime mould Physarum polycephalum displays adaptive transport dynamics and network formation that have inspired its use as a model of biological computation. We develop a Lagrangian formulation of Physarum's adaptive dynamics on predefined graphs, showing that steady states arise as extrema of a least-action functional balancing metabolic dissipation and transport efficiency. The organism's apparent ability to find optimal paths between nutrient sources and sinks emerges from minimizing global energy dissipation under predefined boundary conditions that specify the problem to be solved. Applied to ring, tree, and lattice geometries, the framework accurately reproduces the optimal conductance and flux configurations observed experimentally. These results show that Physarum's problem-solving on constrained topologies follows a physics-based variational principle, revealing least-action dynamics as the foundation of its adaptive organization.",
    "authors": [
      "Ricard Solé",
      "Jordi Pla-Mauri"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "q-bio.NC",
      "math.OC",
      "physics.bio-ph",
      "q-bio.CB"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.08531v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.08436v1",
    "title": "Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning",
    "abstract": "Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible.",
    "authors": [
      "Satpreet H. Singh",
      "Sonja Johnson-Yu",
      "Zhouyang Lu",
      "Aaron Walsman",
      "Federico Pedraja",
      "Denis Turcu",
      "Pratyusha Sharma",
      "Naomi Saphra",
      "Nathaniel B. Sawtell",
      "Kanaka Rajan"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.MA",
      "eess.SY",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "pdf_url": "https://arxiv.org/pdf/2511.08436v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.08292v1",
    "title": "Distance by de-correlation: Computing distance with heterogeneous grid cells",
    "abstract": "Encoding the distance between locations in space is essential for accurate navigation. Grid cells, a functional class of neurons in medial entorhinal cortex, are believed to support this computation. However, existing theories of how populations of grid cells code distance rely on complex coding schemes, with assumptions that may not be met by anatomical constraints. Inspired by recent work finding grid cells to have small, but robust heterogeneity in their grid properties, we hypothesize that distance coding can be achieved by a simple de-correlation of population activity. We develop a mathematical theory for describing this de-correlation in one-dimension, showing that its predictions are consistent with simulations of noisy grid cells. Our simulations highlight a non-intuitive prediction of such a distance by de-correlation framework. Namely, that some further distances are better encoded than some nearer distances. We find evidence of this \"sweet spot\" in previously published rodent behavioral experiments and demonstrate that a decoder which estimates distance from the de-correlation of populations of simulated noisy grid cells leads to a similar pattern of errors. Finally, by simulating noisy grid cells in two-dimensions, we find that there exists a trade-off between the range of distances that can be encoded by de-correlation of population activity and the distinguishability of different distances, which is controlled by the amount of variability in grid properties. We show that the previously observed average amount of grid property variability strikes a balance between the two, enabling the encoding of distances up to several meters. Our work provides new insight on how grid cells can underlie the coding of distance, without the assumptions previously needed, and why grid cells may have small amounts of heterogeneity in their grid properties.",
    "authors": [
      "Pritipriya Dasbehera",
      "Akshunna S. Dogra",
      "William T. Redman"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.08292v1",
    "doi": null,
    "journal_ref": null,
    "comment": "14 pages, 5 figures, comments welcome!",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.08101v1",
    "title": "Direction and speed selectivity properties for spatio-temporal receptive fields according to the generalized Gaussian derivative model for visual receptive fields",
    "abstract": "This paper gives an in-depth theoretical analysis of the direction and speed selectivity properties of idealized models of the spatio-temporal receptive fields of simple cells and complex cells, based on the generalized Gaussian derivative model for visual receptive fields. According to this theory, the receptive fields are modelled as velocity-adapted affine Gaussian derivatives for different image velocities and different degrees of elongation. By probing such idealized receptive field models of visual neurons to moving sine waves with different angular frequencies and image velocities, we characterize the computational models to a structurally similar probing method as is used for characterizing the direction and speed selective properties of biological neurons.   By comparison to results of neurophysiological measurements of direction and speed selectivity for biological neurons in the primary visual cortex, we find that our theoretical results are qualitatively consistent with (i) velocity-tuned visual neurons that are sensitive to particular motion directions and speeds, and (ii)~different visual neurons having broader {\\em vs.\\/}\\ sharper direction and speed selective properties. Our theoretical results in combination with results from neurophysiological characterizations of motion-sensitive visual neurons are also consistent with a previously formulated hypothesis that the simple cells in the primary visual cortex ought to be covariant under local Galilean transformations, so as to enable processing of visual stimuli with different motion directions and speeds.",
    "authors": [
      "Tony Lindeberg"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.08101v1",
    "doi": null,
    "journal_ref": null,
    "comment": "21 pages, 9 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.07960v1",
    "title": "Advancing credibility and transparency in brain-to-image reconstruction research: Reanalysis of Koide-Majima, Nishimoto, and Majima (Neural Networks, 2024)",
    "abstract": "A recent high-profile study by Koide-Majima et al. (2024) claimed a major advance in reconstructing visual imagery from brain activity using a novel variant of a generative AI-based method. However, our independent reanalysis reveals multiple methodological concerns that raise questions about the validity of their conclusions. Specifically, our evaluation demonstrates that: (1) the reconstruction results are biased by selective reporting of only the best-performing examples at multiple levels; (2) performance is artificially inflated by circular metrics that fail to reflect perceptual accuracy; (3) fair baseline comparisons reveal no discernible advantages of the study's key innovations over existing techniques; (4) the central \"Bayesian\" sampling component is functionally inert, producing outcomes identical to the standard optimization result; and (5) even if the component were successfully implemented, the claims of Bayesian novelty are unsubstantiated, as the proposed method does not leverage the principles of a proper Bayesian framework. These systemic issues necessitate a critical reassessment of the study's contributions. This commentary dissects these deficiencies to underscore the need for greater credibility and transparency in the rapidly advancing field of brain decoding.",
    "authors": [
      "Ken Shirakawa",
      "Yoshihiro Nagano",
      "Misato Tanaka",
      "Fan L. Cheng",
      "Yukiyasu Kamitani"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.07960v1",
    "doi": null,
    "journal_ref": null,
    "comment": "30 pages (21 pages in the main text), 10 figures (5 in the main text). Preprint, under preparation for journal submission",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.13739v1",
    "title": "Subject-Independent Imagined Speech Detection via Cross-Subject Generalization and Calibration",
    "abstract": "Achieving robust generalization across individuals remains a major challenge in electroencephalogram based imagined speech decoding due to substantial variability in neural activity patterns. This study examined how training dynamics and lightweight subject specific adaptation influence cross subject performance in a neural decoding framework. A cyclic inter subject training approach, involving shorter per subject training segments and frequent alternation among subjects, led to modest yet consistent improvements in decoding performance across unseen target data. Furthermore, under the subject calibrated leave one subject out scheme, incorporating only 10 % of the target subjects data for calibration achieved an accuracy of 0.781 and an AUC of 0.801, demonstrating the effectiveness of few shot adaptation. These findings suggest that integrating cyclic training with minimal calibration provides a simple and effective strategy for developing scalable, user adaptive brain computer interface systems that balance generalization and personalization.",
    "authors": [
      "Byung-Kwan Ko",
      "Soowon Kim",
      "Seo-Hyun Lee"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.13739v1",
    "doi": null,
    "journal_ref": null,
    "comment": "4 pages, 2 figures, Name of Conference: International Conference on Brain-Computer Interface",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.07825v1",
    "title": "Inferring Hidden Motives: Bayesian Models of Preference Learning in Repeated Dictator Games",
    "abstract": "Human cooperation depends on how accurately we infer others' motives--how much they value fairness, generosity, or self-interest from the choices they make. We model that process in binary dictator games, which isolate moral trade-offs between self and other stripped of strategic complexity. Participants observed others' allocation decisions and predicted their future behavior while playing through an exhaustive, randomized payoff space implemented on The Morality Game platform. We formalize social-preference learning as Bayesian belief updating over continuous parameters such as self-interest, altruism, envy, and guilt. The resulting Utility Bayesian Model (UBM) outperformed non-Bayesian alternatives and Bayesian models that categorize others into discrete social types. Because Bayesian updating requires a utility function in its likelihood term, we conducted the largest utility-function comparison to date--476 candidate forms differing in psychologically meaningful properties (e.g., payoff exponents, reference dependence, payoff ratios, and envy-guilt asymmetries). Exploring this joint space of payoffs and models allowed us to identify the function that unifies prior theories and generalizes across payoff conditions. Parameter estimation revealed moderate altruism, strong inequality aversion, and nonlinear payoff valuation (exponent > 1). Altruism and social-comparison motives were largely independent, revealing diverse moral phenotypes from cooperative to competitive or sadistic. Together, these findings provide a computational framework and a map of social motives, clarifying how humans learn whom to trust and offering quantitative foundations for promoting cooperation in social and artificial systems.",
    "authors": [
      "Gregory Stanley",
      "Jun Zhang",
      "Rick Lewis"
    ],
    "published": "2025-11-11",
    "updated": "2025-11-11",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.07825v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.07313v1",
    "title": "De-Individualizing fMRI Signals via Mahalanobis Whitening and Bures Geometry",
    "abstract": "Functional connectivity has been widely investigated to understand brain disease in clinical studies and imaging-based neuroscience, and analyzing changes in functional connectivity has proven to be valuable for understanding and computationally evaluating the effects on brain function caused by diseases or experimental stimuli. By using Mahalanobis data whitening prior to the use of dimensionality reduction algorithms, we are able to distill meaningful information from fMRI signals about subjects and the experimental stimuli used to prompt them. Furthermore, we offer an interpretation of Mahalanobis whitening as a two-stage de-individualization of data which is motivated by similarity as captured by the Bures distance, which is connected to quantum mechanics. These methods have potential to aid discoveries about the mechanisms that link brain function with cognition and behavior and may improve the accuracy and consistency of Alzheimer's diagnosis, especially in the preclinical stage of disease progression.",
    "authors": [
      "Aaron Jacobson",
      "Tingting Dan",
      "Martin Styner",
      "Guorong Wu",
      "Shahar Kovalsky",
      "Caroline Moosmueller"
    ],
    "published": "2025-11-10",
    "updated": "2025-11-10",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.07313v1",
    "doi": null,
    "journal_ref": null,
    "comment": "34 pages, 7 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.06602v1",
    "title": "A Causal Formulation of Spike-Wave Duality",
    "abstract": "Understanding the relationship between brain activity and behavior is a central goal of neuroscience. Despite significant advances, a fundamental dichotomy persists: neural activity manifests as both discrete spikes of individual neurons and collective waves of populations. Both neural codes correlate with behavior, yet correlation alone cannot determine whether waves exert a causal influence or merely reflect spiking dynamics without causal efficacy. According to the Causal Hierarchy Theorem, no amount of observational data--however extensive--can settle this question; causal conclusions require explicit structural assumptions or careful experiment designs that directly correspond to the causal effect of interest. We develop a formal framework that makes this limitation precise and constructive. Formalizing epiphenomenality via the invariance of interventional distributions in Structural Causal Models (SCMs), we derive a certificate of sufficiency from Pearl's do-calculus that specifies when variables can be removed from the model without loss of causal explainability and clarifies how interventions should be interpreted under different causal structures of spike-wave duality. The purpose of this work is not to resolve the spike-wave debate, but to reformulate it. We shift the problem from asking which signal matters most to asking under what conditions any signal can be shown to matter at all. This reframing distinguishes prediction from explanation and offers neuroscience a principled route for deciding when waves belong to mechanism and when they constitute a byproduct of underlying coordination",
    "authors": [
      "Kasra Jalaldoust",
      "Erfan Zabeh"
    ],
    "published": "2025-11-10",
    "updated": "2025-11-10",
    "categories": [
      "q-bio.NC",
      "stat.ME"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.06602v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.06519v1",
    "title": "On the Analogy between Human Brain and LLMs: Spotting Key Neurons in Grammar Perception",
    "abstract": "Artificial Neural Networks, the building blocks of AI, were inspired by the human brain's network of neurons. Over the years, these networks have evolved to replicate the complex capabilities of the brain, allowing them to handle tasks such as image and language processing. In the realm of Large Language Models, there has been a keen interest in making the language learning process more akin to that of humans. While neuroscientific research has shown that different grammatical categories are processed by different neurons in the brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we identify the most important neurons associated with the prediction of words belonging to different part-of-speech tags. Using the achieved knowledge, we train a classifier on a dataset, which shows that the activation patterns of these key neurons can reliably predict part-of-speech tags on fresh data. The results suggest the presence of a subspace in LLMs focused on capturing part-of-speech tag concepts, resembling patterns observed in lesion studies of the brain in neuroscience.",
    "authors": [
      "Sanaz Saki Norouzi",
      "Mohammad Masjedi",
      "Pascal Hitzler"
    ],
    "published": "2025-11-09",
    "updated": "2025-11-09",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.06519v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.06153v1",
    "title": "Topologically Invariant Permutation Test",
    "abstract": "Functional brain networks exhibit topological structures that reflect neural organization; however, statistical comparison of these networks is challenging for several reasons. This paper introduces a topologically invariant permutation test for detecting topological inequivalence. Under topological equivalence, topological features can be permuted separately between groups without distorting individual network structures. The test statistic uses $2$-Wasserstein distances on persistent diagrams, computed in closed form. To reduce variability in brain connectivities while preserving topology, heat kernel expansion on the Hodge Laplacian is applied with bandwidth $t$ controlling diffusion intensity. Theoretical results guarantee variance reduction through optimal Hilbert space projection. Simulations across diverse network topologies show superior performance compared to conventional two-sample tests and alternative metrics. Applied to resting-state fMRI data from the Multimodal Treatment of ADHD study, the method detects significant topological differences between cannabis users and non-users.",
    "authors": [
      "Sixtus Dakurah"
    ],
    "published": "2025-11-08",
    "updated": "2025-11-08",
    "categories": [
      "q-bio.NC",
      "math.AT",
      "stat.ME"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.06153v1",
    "doi": null,
    "journal_ref": null,
    "comment": "24 pages, 8 figures, 3 tables",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.05232v1",
    "title": "Travelling waves modulated by subthreshold oscillations in networks of integrate-and-fire neurons",
    "abstract": "Travelling waves of neural firing activity are observed in brain tissue as a part of various sensory, motor and cognitive processes. They represent an object of major interest in the study of excitable networks, with analysis conducted in both neural field models and spiking neuronal networks. The latter class exposes the single-neuron dynamics directly, allowing us to study the details of their influence upon network-scale behaviour. Here we present a study of a laterally-inhibited network of leaky integrate-and-fire neurons modulated by a slow voltage-gated ion channel that acts as a linear adaptation variable. As the strength of the ion channel increases, we find that its interaction with the lateral inhibition increases wave speeds. The ion channel can enable subthreshold oscillations, with the intervals between the firing events of loosely-coupled travelling wave solutions structured around the neuron's natural period. These subthreshold oscillations also enable the occurrence of codimension-2 grazing bifurcations; along with the emergence of fold bifurcations along wave solution branches, the slow ion channel introduces a variety of intermediate structures in the solution space. These point towards further investigation of the role neighbouring solution branches play in the behaviour of waves forced across bifurcations, which we illustrate with the aid of simulations using a novel root-finding algorithm designed to handle uncertainty over the existence of firing solutions.",
    "authors": [
      "Henry D. J. Kerr",
      "Peter Ashwin",
      "Kyle C. A. Wedgwood"
    ],
    "published": "2025-11-07",
    "updated": "2025-11-07",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.05232v1",
    "doi": null,
    "journal_ref": null,
    "comment": "37 pages, 11 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.05221v2",
    "title": "ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy",
    "abstract": "Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $α$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices.",
    "authors": [
      "David Bertram",
      "Anja Ophey",
      "Sinah Röttgen",
      "Konstantin Kufer",
      "Gereon R. Fink",
      "Elke Kalbe",
      "Clint Hansen",
      "Walter Maetzler",
      "Maximilian Kapsecker",
      "Lara M. Reimer",
      "Stephan Jonas",
      "Andreas T. Damgaard",
      "Natasha B. Bertelsen",
      "Casper Skjaerbaek",
      "Per Borghammer",
      "Karolien Groenewald",
      "Pietro-Luca Ratti",
      "Michele T. Hu",
      "Noémie Moreau",
      "Michael Sommerauer",
      "Katarzyna Bozek"
    ],
    "published": "2025-11-07",
    "updated": "2025-11-12",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "pdf_url": "https://arxiv.org/pdf/2511.05221v2",
    "doi": null,
    "journal_ref": null,
    "comment": "30 pages including Supplementary Information, 4 core figures, 1 supplementary figure. (v2: fixed a typo in Table 3 and made minor text edits.)",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04983v1",
    "title": "Predicting Cognitive Assessment Scores in Older Adults with Cognitive Impairment Using Wearable Sensors",
    "abstract": "Background and Objectives: This paper focuses on using AI to assess the cognitive function of older adults with mild cognitive impairment or mild dementia using physiological data provided by a wearable device. Cognitive screening tools are disruptive, time-consuming, and only capture brief snapshots of activity. Wearable sensors offer an attractive alternative by continuously monitoring physiological signals. This study investigated whether physiological data can accurately predict scores on established cognitive tests. Research Design and Methods: We recorded physiological signals from 23 older adults completing three NIH Toolbox Cognitive Battery tests, which assess working memory, processing speed, and attention. The Empatica EmbracePlus, a wearable device, measured blood volume pulse, skin conductance, temperature, and movement. Statistical features were extracted using wavelet-based and segmentation methods. We then applied supervised learning and validated predictions via cross-validation, hold-out testing, and bootstrapping. Results: Our models showed strong performance with Spearman's ρof 0.73-0.82 and mean absolute errors of 0.14-0.16, significantly outperforming a naive mean predictor. Sensor roles varied: heart-related signals combined with movement and temperature best predicted working memory, movement paired with skin conductance was most informative for processing speed, and heart in tandem with skin conductance worked best for attention. Discussion and Implications: These findings suggest that wearable sensors paired with AI tools such as supervised learning and feature engineering can noninvasively track specific cognitive functions in older adults, enabling continuous monitoring. Our study demonstrates how AI can be leveraged when the data sample is small. This approach may support remote assessments and facilitate clinical interventions.",
    "authors": [
      "Assma Habadi",
      "Milos Zefran",
      "Lijuan Yin",
      "Woojin Song",
      "Maria Caceres",
      "Elise Hu",
      "Naoko Muramatsu"
    ],
    "published": "2025-11-07",
    "updated": "2025-11-07",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.04983v1",
    "doi": null,
    "journal_ref": null,
    "comment": "40 pages, 2 figures, 3 tables; Supplementary Material: 3 tables (S1-S3). Presented as a poster at the Gerontological Society of America (GSA) Annual Scientific Meeting, November 2025",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.05630v1",
    "title": "BrainCSD: A Hierarchical Consistency-Driven MoE Foundation Model for Unified Connectome Synthesis and Multitask Brain Trait Prediction",
    "abstract": "Functional and structural connectivity (FC/SC) are key multimodal biomarkers for brain analysis, yet their clinical utility is hindered by costly acquisition, complex preprocessing, and frequent missing modalities. Existing foundation models either process single modalities or lack explicit mechanisms for cross-modal and cross-scale consistency. We propose BrainCSD, a hierarchical mixture-of-experts (MoE) foundation model that jointly synthesizes FC/SC biomarkers and supports downstream decoding tasks (diagnosis and prediction). BrainCSD features three neuroanatomically grounded components: (1) a ROI-specific MoE that aligns regional activations from canonical networks (e.g., DMN, FPN) with a global atlas via contrastive consistency; (2) a Encoding-Activation MOE that models dynamic cross-time/gradient dependencies in fMRI/dMRI; and (3) a network-aware refinement MoE that enforces structural priors and symmetry at individual and population levels. Evaluated on the datasets under complete and missing-modality settings, BrainCSD achieves SOTA results: 95.6\\% accuracy for MCI vs. CN classification without FC, low synthesis error (FC RMSE: 0.038; SC RMSE: 0.006), brain age prediction (MAE: 4.04 years), and MMSE score estimation (MAE: 1.72 points). Code is available in \\href{https://github.com/SXR3015/BrainCSD}{BrainCSD}",
    "authors": [
      "Xiongri Shen",
      "Jiaqi Wang",
      "Yi Zhong",
      "Zhenxi Song",
      "Leilei Zhao",
      "Liling Li",
      "Yichen Wei",
      "Lingyan Liang",
      "Shuqiang Wang",
      "Baiying Lei",
      "Demao Deng",
      "Zhiguo Zhang"
    ],
    "published": "2025-11-07",
    "updated": "2025-11-07",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.05630v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04887v1",
    "title": "Duration-modulated neural population dynamics in humans during BMI controls",
    "abstract": "The motor cortex (MC) is often described as an autonomous dynamical system during movement execution. In an autonomous dynamical system, flexible movement generation depends on reconfiguring the initial conditions, which then unwind along known dynamics. An open question is whether these dynamics govern MC activity during brain-machine interface (BMI) control. We investigated MC activity during BMI cursor movements of multiple durations, ranging from hundreds of milliseconds to sustained over seconds. These durations were chosen to cover the range of movement durations necessary to control modern BMIs under varying precision levels. Movements shared their MC initial condition with movements of different durations in the same direction. Long-duration movements sustained MC activity, effectively pausing the neural population dynamics until each movement goal was reached. The difference across durations in MC population dynamics may be attributed to external inputs. Our results highlight the role of sustained inputs to MC during movement.",
    "authors": [
      "Fei Yin",
      "Charles Guan",
      "Tyson Aflalo",
      "Jorge Gamez",
      "Kelsie Pejsa",
      "Emily Rosario",
      "Charles Liu",
      "Ausaf Bari",
      "Richard Andersen"
    ],
    "published": "2025-11-07",
    "updated": "2025-11-07",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.04887v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04802v2",
    "title": "Shaping manifolds in equivariant recurrent neural networks",
    "abstract": "Recordings of increasingly large neural populations have revealed that the firing of individual neurons is highly coordinated. When viewed in the space of all possible patterns, the collective activity forms non-linear structures called neural manifolds. Because such structures are observed even at rest or during sleep, an important hypothesis is that activity manifolds may correspond to continuous attractors shaped by recurrent connectivity between neurons. Classical models of recurrent networks have shown that continuous attractors can be generated by specific symmetries in the connectivity. Although a variety of attractor network models have been studied, general principles linking network connectivity and the geometry of attractors remain to be formulated. Here, we address this question by using group representation theory to formalize the relationship between the symmetries in recurrent connectivity and the resulting fixed-point manifolds. We start by revisiting the classical ring model, a continuous attractor network generating a circular manifold. Interpreting its connectivity as a circular convolution, we draw a parallel with feed-forward CNNs. Building on principles of geometric deep learning, we then generalize this architecture to a broad range of symmetries using group representation theory. Specifically, we introduce a new class of equivariant RNNs, where the connectivity is based on group convolution. Using the group Fourier transform, we reduce such networks to low-rank models, giving us a low-dimensional description that can be fully analyzed to determine the symmetry, dimensionality and stability of fixed-point manifolds. Our results underline the importance of stability considerations: for a connectivity with a given symmetry, depending on parameters, several manifolds with different symmetry subgroups can coexist, some stable and others consisting of saddle points.",
    "authors": [
      "Arianna Di Bernardo",
      "Adrian Valente",
      "Francesca Mastrogiuseppe",
      "Srdjan Ostojic"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-13",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.04802v2",
    "doi": null,
    "journal_ref": null,
    "comment": "46 pages; 7 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04593v1",
    "title": "Neural Computation Without Slots: Steps Towards Biologically Plausible Memory and Attention in Natural and Artificial Intelligence",
    "abstract": "Many models used in artificial intelligence and cognitive science rely on multi-element patterns stored in \"slots\" - dedicated storage locations - in a digital computer. As biological brains likely lack slots, we consider how they might achieve similar functional outcomes without them by building on the neurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which stores patterns in the connection weights of an individual neuron. We propose extensions of this approach to increase its biological plausibility as a model of memory and to capture an important advantage of slot-based computation in contemporary language models. For memory, neuroscience research suggests that the weights of overlapping sparse ensembles of neurons, rather than a dedicated individual neuron, are used to store a memory. We introduce the K-winner MHN, extending the approach to ensembles, and find that within a continual learning regime, the ensemble-based MHN exhibits greater retention of older memories, as measured by the graded sensitivity measure d', than a standard (one-neuron) MHN. Next, we consider the powerful use of slot-based memory in contemporary language models. These models use slots to store long sequences of past inputs and their learned encodings, supporting later predictions and allowing error signals to be transported backward in time to adjust weights underlying the learned encodings of these past inputs. Inspired by these models' successes, we show how the MHN can be extended to capture both of these important functional outcomes. Collectively, our modeling approaches constitute steps towards understanding how biologically plausible mechanisms can support computations that have enabled AI systems to capture human-like abilities that no prior models have been able to achieve.",
    "authors": [
      "Shaunak Bhandarkar",
      "James L. McClelland"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "pdf_url": "https://arxiv.org/pdf/2511.04593v1",
    "doi": null,
    "journal_ref": null,
    "comment": "19 main text pages, 7 main text figures; 33 supplementary pages, 13 supplementary figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04539v1",
    "title": "Unified Generative Latent Representation for Functional Brain Graphs",
    "abstract": "Functional brain graphs are often characterized with separate graph-theoretic or spectral descriptors, overlooking how these properties covary and partially overlap across brains and conditions. We anticipate that dense, weighted functional connectivity graphs occupy a low-dimensional latent geometry along which both topological and spectral structures display graded variations. Here, we estimated this unified graph representation and enabled generation of dense functional brain graphs through a graph transformer autoencoder with latent diffusion, with spectral geometry providing an inductive bias to guide learning. This geometry-aware latent representation, although unsupervised, meaningfully separated working-memory states and decoded visual stimuli, with performance further enhanced by incorporating neural dynamics. From the diffusion modeled distribution, we were able to sample biologically plausible and structurally grounded synthetic dense graphs.",
    "authors": [
      "Subati Abulikemu",
      "Tiago Azevedo",
      "Michail Mamalakis",
      "John Suckling"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.04539v1",
    "doi": null,
    "journal_ref": null,
    "comment": "NeurIPS 2025 Workshop on Symmetry and Geometry in Neural Representations",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04455v1",
    "title": "The brain as a blueprint: a survey of brain-inspired approaches to learning in artificial intelligence",
    "abstract": "Inspired by key neuroscience principles, deep learning has driven exponential breakthroughs in developing functional models of perception and other cognitive processes. A key to this success has been the implementation of crucial features found in biological neural networks: neurons as units of information transfer, non-linear activation functions that enable general function approximation, and complex architectures vital for attentional processes. However, standard deep learning models rely on biologically implausible error propagation algorithms and struggle to accumulate knowledge incrementally. While, the precise learning rule governing synaptic plasticity in biological systems remains unknown, recent discoveries in neuroscience could fuel further progress in AI. Here I examine successful implementations of brain-inspired principles in deep learning, current limitations, and promising avenues inspired by recent advances in neuroscience, including error computation, propagation, and integration via synaptic updates in biological neural networks.",
    "authors": [
      "Guillaume Etter"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.04455v1",
    "doi": null,
    "journal_ref": null,
    "comment": "17 pages, 6 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04454v1",
    "title": "Fitting Reinforcement Learning Model to Behavioral Data under Bandits",
    "abstract": "We consider the problem of fitting a reinforcement learning (RL) model to some given behavioral data under a multi-armed bandit environment. These models have received much attention in recent years for characterizing human and animal decision making behavior. We provide a generic mathematical optimization problem formulation for the fitting problem of a wide range of RL models that appear frequently in scientific research applications, followed by a detailed theoretical analysis of its convexity properties. Based on the theoretical results, we introduce a novel solution method for the fitting problem of RL models based on convex relaxation and optimization. Our method is then evaluated in several simulated bandit environments to compare with some benchmark methods that appear in the literature. Numerical results indicate that our method achieves comparable performance to the state-of-the-art, while significantly reducing computation time. We also provide an open-source Python package for our proposed method to empower researchers to apply it in the analysis of their datasets directly, without prior knowledge of convex optimization.",
    "authors": [
      "Hao Zhu",
      "Jasper Hoffmann",
      "Baohe Zhang",
      "Joschka Boedecker"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "cs.CE",
      "cs.LG",
      "math.OC",
      "q-bio.NC"
    ],
    "primary_category": "cs.CE",
    "pdf_url": "https://arxiv.org/pdf/2511.04454v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.05612v1",
    "title": "AI-Enhanced High-Density NIRS Patch for Real-Time Brain Layer Oxygenation Monitoring in Neurological Emergencies",
    "abstract": "Photon scattering has traditionally limited the ability of near-infrared spectroscopy (NIRS) to extract accurate, layer-specific information from the brain. This limitation restricts its clinical utility for precise neurological monitoring. To address this, we introduce an AI-driven, high-density NIRS system optimized to provide real-time, layer-specific oxygenation data from the brain cortex, specifically targeting acute neuro-emergencies. Our system integrates high-density NIRS reflectance data with a neural network trained on MRI-based synthetic datasets. This approach achieves robust cortical oxygenation accuracy across diverse anatomical variations. In simulations, our AI-assisted NIRS demonstrated a strong correlation (R2=0.913) with actual cortical oxygenation, markedly outperforming conventional methods (R2=0.469). Furthermore, biomimetic phantom experiments confirmed its superior anatomical reliability (R2=0.986) compared to standard commercial devices (R2=0.823). In clinical validation with healthy subjects and ischemic stroke patients, the system distinguished between the two groups with an AUC of 0.943. This highlights its potential as an accessible, high-accuracy diagnostic tool for emergency and point-of-care settings. These results underscore the system's capability to advance neuro-monitoring precision through AI, enabling timely, data-driven decisions in critical care environments.",
    "authors": [
      "Minsu Ji",
      "Jihoon Kang",
      "Seongkwon Yu",
      "Jaemyoung Kim",
      "Bumjun Koh",
      "Jimin Lee",
      "Guil Jeong",
      "Jongkwan choi",
      "Chang-Ho Yun",
      "Hyeonmin Bae"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.05612v1",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04292v1",
    "title": "BTTDA: Block-Term Tensor Discriminant Analysis for Brain-Computer Interfacing",
    "abstract": "Brain-computer interfaces (BCIs) allow direct communication between the brain and external devices, frequently using electroencephalography (EEG) to record neural activity. Dimensionality reduction and structured regularization are essential for effectively classifying task-related brain signals, including event-related potentials (ERPs) and motor imagery (MI) rhythms. Current tensor-based approaches, such as Tucker and PARAFAC decompositions, often lack the flexibility needed to fully capture the complexity of EEG data. This study introduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel tensor-based and supervised feature extraction method designed to enhance classification accuracy by providing flexible multilinear dimensionality reduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a novel and interpretable forward model for HODA combined with a deflation scheme to iteratively extract discriminant block terms, improving feature representation for classification. BTTDA and a sum-of-rank-1-terms variant PARAFACDA were evaluated on publicly available ERP (second-order tensors) and MI (third-order tensors) EEG datasets from the MOABB benchmarking framework. Benchmarking revealed that BTTDA and PARAFACDA significantly outperform the traditional HODA method in ERP decoding, resulting in state-of-the art performance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and PARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52% > 61.00%). The block-term structure of BTTDA enables interpretable and more efficient dimensionality reduction without compromising discriminative power. This offers a promising and adaptable approach for feature extraction in BCI and broader neuroimaging applications.",
    "authors": [
      "Arne Van Den Kerchove",
      "Hakim Si-Mohammed",
      "François Cabestaing",
      "Marc M. Van Hulle"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "eess.SP",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "pdf_url": "https://arxiv.org/pdf/2511.04292v1",
    "doi": null,
    "journal_ref": null,
    "comment": "This archive contains 26 pages, 7 figures, 2 tables, 3 appendices and 3 ancillary files (erp_results.csv, mi_results.csv, block_theta_results.csv). Source code is available at https://github.com/arnevdk/bttda",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.05606v1",
    "title": "Exploring Cordial Labeling techniques in Brain Connectivity Network",
    "abstract": "Graph-theoretical labeling provides a rigorous mathematical framework for characterizing the structural and functional organization of complex networks. This paper investigates the application of cordial labeling and signed product cordial labeling to brain connectivity graphs, emphasizing their relevance to small-world network models in neuroscience. The cordial condition is interpreted as a measure of structural balance between excitatory and inhibitory neuronal interactions, while the signed product cordial labeling reflects the coexistence of cooperative and antagonistic neural dynamics.",
    "authors": [
      "S. Soundar Rajan",
      "J. Baskar Babujee"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.05606v1",
    "doi": "1.5281/zenodo.1387210",
    "journal_ref": "Techniques-Sciences-methodes, vol 9, issue 11, (2025), pp-20-31",
    "comment": "12 Pages",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04174v1",
    "title": "Protein aggregation in Huntington's disease",
    "abstract": "The presence of an expanded polyglutamine produces a toxic gain of function in huntingtin. Protein aggregation resulting from this gain of function is likely to be the cause of neuronal death. Two main mechanisms of aggregation have been proposed: hydrogen bonding by polar-zipper formation and covalent bonding by transglutaminase-catalyzed cross-linking. In cell culture models of Huntington's disease, aggregates are mostly stabilized by hydrogen bonds, but covalent bonds are also likely to occur. Nothing is known about the nature of the bonds that stabilize the aggregates in the brain of patients with Huntington's disease. It seems that the nature of the bond stabilizing the aggregates is one of the most important questions, as the answer would condition the therapeutic approach to Huntington's disease.",
    "authors": [
      "Guylaine Hoffner",
      "Philippe Djian"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "q-bio.BM",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.BM",
    "pdf_url": "https://arxiv.org/pdf/2511.04174v1",
    "doi": null,
    "journal_ref": "Biochimie, 2002, 84 (4), pp.273-278",
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.04047v3",
    "title": "Why Consciousness Should Explain Physical Phenomena: Toward a Testable Theory",
    "abstract": "The reductionist approach commonly employed in scientific methods presupposes that both macro and micro phenomena can be explained by micro-level laws alone. This assumption implies intra-level causal closure, rendering all macro phenomena epiphenomenal. However, the integrative nature of consciousness suggests that it is a macro phenomenon. To ensure scientific testability and reject epiphenomenalism, the reductionist assumption of intra-level causal closure must be rejected. This implies that even neural-level behavior cannot be explained by observable neural-level laws alone. Therefore, a new methodology is necessary to acknowledge the causal efficacy of macro-level phenomena. We model the brain as operating under dual laws at different levels. This model includes hypothetical macro-level psychological laws that are not determined solely by micro-level neural laws, as well as the causal effects from macro to micro levels. In this study, we propose a constructive approach that explains both mental and physical phenomena through the interaction between these two sets of laws.",
    "authors": [
      "Yoshiyuki Ohmura",
      "Yasuo Kuniyoshi"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-22",
    "categories": [
      "q-bio.NC",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "pdf_url": "https://arxiv.org/pdf/2511.04047v3",
    "doi": null,
    "journal_ref": null,
    "comment": null,
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.03988v1",
    "title": "Simple 3D Pose Features Support Human and Machine Social Scene Understanding",
    "abstract": "Humans can quickly and effortlessly extract a variety of information about others' social interactions from visual input, ranging from visuospatial cues like whether two people are facing each other to higher-level information. Yet, the computations supporting these abilities remain poorly understood, and social interaction recognition continues to challenge even the most advanced AI vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose information to make social interaction judgments, which is absent in most AI vision models. To test this, we combined state-of-the-art pose and depth estimation algorithms to extract 3D joint positions of people in short video clips depicting everyday human actions and compared their ability to predict human social interaction judgments with current AI vision models. Strikingly, 3D joint positions outperformed most current AI vision models, revealing that key social information is available in explicit body position but not in the learned features of most vision models, including even the layer-wise embeddings of the pose models used to extract joint positions. To uncover the critical pose features humans use to make social judgments, we derived a compact set of 3D social pose features describing only the 3D position and direction of faces in the videos. We found that these minimal descriptors matched the predictive strength of the full set of 3D joints and significantly improved the performance of off-the-shelf AI vision models when combined with their embeddings. Moreover, the degree to which 3D social pose features were represented in each off-the-shelf AI vision model predicted the model's ability to match human social judgments. Together, our findings provide strong evidence that human social scene understanding relies on explicit representations of 3D pose and can be supported by simple, structured visuospatial primitives.",
    "authors": [
      "Wenshuo Qin",
      "Leyla Isik"
    ],
    "published": "2025-11-06",
    "updated": "2025-11-06",
    "categories": [
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "pdf_url": "https://arxiv.org/pdf/2511.03988v1",
    "doi": null,
    "journal_ref": null,
    "comment": "28 pages, 6 figures",
    "source": "arXiv"
  },
  {
    "arxiv_id": "2511.03671v1",
    "title": "Final state sensitivity and fractal basin boundaries from coupled Chialvo neurons",
    "abstract": "We investigate and quantify the basin geometry and extreme final state uncertainty of two identical electrically asymmetrically coupled Chialvo neurons. The system's diverse behaviors are presented, along with the mathematical reasoning behind its chaotic and nonchaotic dynamics as determined by the structure of the coupled equations. The system is found to be multistable with two qualitatively different attractors. Although each neuron is individually nonchaotic, the chaotic basin takes up the vast majority of the coupled system's state space, but the nonchaotic basin stretches to infinity due to chance synchronization. The boundary between the basins is found to be fractal, leading to extreme final state sensitivity. This uncertainty and its potential effect on the synchronization of biological neurons may have significant implications for understanding human behavior and neurological disease.",
    "authors": [
      "Bennett Lamb",
      "Brandon B. Le"
    ],
    "published": "2025-11-05",
    "updated": "2025-11-05",
    "categories": [
      "nlin.CD",
      "math.DS",
      "physics.bio-ph",
      "q-bio.NC"
    ],
    "primary_category": "nlin.CD",
    "pdf_url": "https://arxiv.org/pdf/2511.03671v1",
    "doi": null,
    "journal_ref": null,
    "comment": "15 pages, 9 figures",
    "source": "arXiv"
  }
]