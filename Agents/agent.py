"""
Agents/agent.py
å¯æ‰§è¡Œçš„Agentç±» - æ”¯æŒLLMè°ƒç”¨å’ŒRAGæ£€ç´¢
"""

from typing import Dict, Any, Optional, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import BaseTool
from config.settings import get_settings
from Agents.state import CritiqueResult, REAgentState, get_tool_registry


async def summarize_messages(messages: List, max_summary_length: int = 2000) -> str:
    """
    ä½¿ç”¨ LLM å¯¹æ¶ˆæ¯å†å²è¿›è¡Œæ™ºèƒ½æ€»ç»“ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ä½†å¤§å¹…å‡å°‘ tokens
    
    Args:
        messages: è¦æ€»ç»“çš„æ¶ˆæ¯åˆ—è¡¨
        max_summary_length: æ€»ç»“çš„æœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
    
    Returns:
        æ€»ç»“åçš„æ–‡æœ¬
    """
    if not messages:
        return ""
    
    # æ„å»ºæ¶ˆæ¯å†…å®¹æ‘˜è¦ï¼ˆæå–å…³é”®ä¿¡æ¯ï¼‰
    message_contents = []
    for msg in messages:
        if isinstance(msg, SystemMessage):
            continue  # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯
        elif isinstance(msg, HumanMessage):
            content = msg.content[:500] if len(msg.content) > 500 else msg.content
            message_contents.append(f"User: {content}")
        elif isinstance(msg, AIMessage):
            content = msg.content[:500] if len(msg.content) > 500 else msg.content
            message_contents.append(f"Assistant: {content}")
        elif isinstance(msg, ToolMessage):
            # å·¥å…·æ¶ˆæ¯åªä¿ç•™å·¥å…·åç§°å’Œç®€è¦ç»“æœ
            content = msg.content[:200] if len(msg.content) > 200 else msg.content
            message_contents.append(f"Tool Result: {content}")
    
    if not message_contents:
        return "No significant messages to summarize."
    
    # ä½¿ç”¨ LLM è¿›è¡Œæ€»ç»“
    try:
        settings = get_settings()
        summarizer_llm = ChatOpenAI(
            model=settings.llm_model,
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ï¼Œæ›´èšç„¦çš„æ€»ç»“
            openai_api_key=settings.openai_api_key,
            max_tokens=1000  # é™åˆ¶æ€»ç»“é•¿åº¦
        )
        
        summary_prompt = f"""Please intelligently summarize the following conversation history, preserving all key information and decisions while significantly compressing the content.

Requirements:
1. Preserve all important task information, design decisions, and parameter settings
2. Preserve key conclusions and scores from expert analyses
3. Remove redundant and repetitive information
4. Compress detailed tool execution results, keeping only key information
5. Keep the summary within {max_summary_length} characters

Conversation history:
{chr(10).join(message_contents[:20])}  # Process at most the first 20 messages

Please provide a concise but complete summary:"""

        response = await summarizer_llm.ainvoke([HumanMessage(content=summary_prompt)])
        summary = response.content if response.content else ""
        
        # ç¡®ä¿æ€»ç»“ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
        if len(summary) > max_summary_length:
            summary = summary[:max_summary_length] + "..."
        
        return summary
    except Exception as e:
        # å¦‚æœæ€»ç»“å¤±è´¥ï¼Œè¿”å›ç®€å•çš„æ–‡æœ¬æ‘˜è¦
        print(f"  âš ï¸ æ¶ˆæ¯æ€»ç»“å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•æ‘˜è¦", flush=True)
        return f"å¯¹è¯å†å²æ‘˜è¦ï¼ˆ{len(messages)}æ¡æ¶ˆæ¯ï¼‰: " + "; ".join([msg.content[:100] for msg in messages[:5] if hasattr(msg, 'content')])


class Agent:
    """
    å¯æ‰§è¡Œçš„Agentç±»
    
    åŠŸèƒ½ï¼š
    1. LLMè°ƒç”¨èƒ½åŠ›
    2. RAGçŸ¥è¯†æ£€ç´¢
    3. åˆ†æå®éªŒæ–¹æ¡ˆå¹¶ç”ŸæˆCritiqueResult
    """

    def __init__(
        self,
        title: str,
        expertise: str,
        goal: str,
        role: str,
        model: str,
        rag_interface: Optional[Any] = None
    ) -> None:
        """
        åˆå§‹åŒ–Agent
        
        Args:
            title: Agentæ ‡é¢˜
            expertise: ä¸“ä¸šé¢†åŸŸ
            goal: ç›®æ ‡
            role: è§’è‰²æè¿°
            model: LLMæ¨¡å‹åç§°
            rag_interface: RAGæ¥å£ï¼ˆå¯é€‰ï¼Œå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        """
        self.title = title
        self.expertise = expertise
        self.goal = goal
        self.role = role
        self.model = model
        self._rag_interface = rag_interface
        self._llm = None
        self._llm_with_tools = None
        self._tools = []
        self.settings = get_settings()

    def prompt(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤º"""
        # æ£€æŸ¥æ˜¯å¦æœ‰RAGå·¥å…·å¯ç”¨
        has_rag_tool = any(tool.name == "rag_search" for tool in self._tools)
        
        tool_instructions = ""
        if has_rag_tool:
            tool_instructions = """
            
CRITICAL: You MUST use the `rag_search` tool to retrieve relevant knowledge from the knowledge base BEFORE providing your analysis.
- Call `rag_search` with a detailed query related to your expertise area and the task at hand
- Use the retrieved knowledge to inform your design decisions
- Cite specific knowledge sources in your analysis
- If the initial search doesn't return enough relevant results, refine your query and search again

You also have access to file reading/writing tools (`read_file`, `write_file`) if you need to examine data files or save intermediate results.
"""
        
        return (
            f"You are a {self.title}. "
            f"Your expertise is in {self.expertise}. "
            f"Your goal is to {self.goal}. "
            f"Your role is to {self.role}."
            + tool_instructions
        )

    def message(self) -> dict[str, str]:
        """è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼"""
        return {
            "role": "system",
            "content": self.prompt(),
        }

    def _is_reasoning_model(self, model_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æ¨ç†æ¨¡å‹ï¼ˆéœ€è¦æ›´å¤§çš„ max_tokens é…é¢ï¼‰"""
        model_lower = model_name.lower()
        # æ£€æŸ¥æ˜¯å¦æ˜¯ o1 ç³»åˆ—æˆ–å…¶ä»–æ¨ç†æ¨¡å‹
        # gpt-5.1 å’Œ gpt-5.2 éƒ½æ˜¯æ¨ç†æ¨¡å‹ï¼Œä¼šä½¿ç”¨ reasoning tokens
        reasoning_indicators = ["o1", "reasoning", "gpt-5.1", "gpt-5.2"]
        return any(indicator in model_lower for indicator in reasoning_indicators)
    
    def _get_max_tokens(self, model_name: str) -> int:
        """æ ¹æ®æ¨¡å‹ç±»å‹è·å–åˆé€‚çš„ max_tokens å€¼"""
        if self._is_reasoning_model(model_name):
            # æ¨ç†æ¨¡å‹ï¼šéœ€è¦æ›´å¤§çš„é…é¢ï¼ˆreasoning tokens + content tokensï¼‰
            # o1 ç³»åˆ—é€šå¸¸éœ€è¦ 16000-32000
            # gpt-5.1/gpt-5.2 æ¨ç†æ¨¡å‹ï¼šå¦‚æœä½¿ç”¨äº† 16000 reasoning tokensï¼Œ
            # éœ€è¦è‡³å°‘ 32000-64000 çš„æ€»é…é¢æ¥ä¸ºå†…å®¹ tokens ç•™å‡ºç©ºé—´
            # è®¾ç½®ä¸º 64000 ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ç”Ÿæˆå®Œæ•´å“åº”
            return 64000  # ä¸ºæ¨ç† tokens å’Œå†…å®¹ tokens ç•™å‡ºè¶³å¤Ÿç©ºé—´
        else:
            # éæ¨ç†æ¨¡å‹ï¼šæ ‡å‡†é…é¢
            return 16000  # å¢å¤§æ ‡å‡†é…é¢ï¼Œæ”¯æŒæ›´è¯¦ç»†çš„ä»£ç ç”Ÿæˆ

    @property
    def llm(self) -> ChatOpenAI:
        """å»¶è¿Ÿåˆå§‹åŒ–LLM"""
        if self._llm is None:
            max_tokens = self._get_max_tokens(self.model)
            self._llm = ChatOpenAI(
                model=self.model,
                temperature=self.settings.default_temperature,
                openai_api_key=self.settings.openai_api_key,
                max_tokens=max_tokens  # æ ¹æ®æ¨¡å‹ç±»å‹åŠ¨æ€è®¾ç½®
            )
            if self._is_reasoning_model(self.model):
                print(f"   â„¹ï¸ æ¨ç†æ¨¡å‹æ£€æµ‹åˆ° ({self.model})ï¼Œè®¾ç½® max_tokens={max_tokens} ä»¥æ”¯æŒæ¨ç† tokens", flush=True)
        return self._llm

    def set_tools(self, tools: List[BaseTool]):
        """è®¾ç½®å·¥å…·åˆ—è¡¨"""
        self._tools = tools
        self._llm_with_tools = None  # é‡ç½®ï¼Œä¸‹æ¬¡è®¿é—®æ—¶é‡æ–°ç»‘å®š

    @property
    def llm_with_tools(self) -> ChatOpenAI:
        """è·å–å¸¦å·¥å…·ç»‘å®šçš„LLM"""
        if self._llm_with_tools is None:
            if self._tools:
                self._llm_with_tools = self.llm.bind_tools(self._tools)
            else:
                self._llm_with_tools = self.llm
        return self._llm_with_tools

    def set_rag_interface(self, rag_interface: Any):
        """è®¾ç½®RAGæ¥å£"""
        self._rag_interface = rag_interface

    @property
    def rag_interface(self) -> Optional[Any]:
        """è·å–RAGæ¥å£"""
        return self._rag_interface

    async def search_knowledge(
        self,
        query: str,
        strategy: str = "hybrid",
        top_k: int = 5
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼ˆå¼ºåˆ¶é€šè¿‡RAGå·¥å…·é“¾ï¼‰
        
        ä¼˜å…ˆé€šè¿‡ ToolRegistry ä¸­çš„ `rag_search` å·¥å…·æ‰§è¡Œï¼Œ
        è¿™æ ·å¯ä»¥åœ¨ç»ˆç«¯çœ‹åˆ°å·¥å…·è°ƒç”¨çŠ¶æ€ï¼›å¦‚æœå·¥å…·ä¸å¯ç”¨ï¼Œ
        åˆ™å›é€€åˆ°ç›´æ¥ä½¿ç”¨åº•å±‚ RAG æ¥å£ã€‚
        """
        # ä¼˜å…ˆä½¿ç”¨ RAGSearchToolï¼ˆèµ°å·¥å…·é“¾ï¼‰
        try:
            tool_registry = get_tool_registry()
            rag_tool = tool_registry.get_tool("rag_search")
        except Exception:
            rag_tool = None

        if rag_tool is not None:
            try:
                tool_result = await rag_tool._arun(
                    query=query,
                    agent_role=self.role,
                    top_k=top_k,
                )
                if not tool_result.get("success", False):
                    print(f"âš ï¸ RAGå·¥å…·æ£€ç´¢å¤±è´¥ ({self.title}): {tool_result.get('error')}", flush=True)
                    return {
                        "shared_knowledge": [],
                        "specialized_knowledge": [],
                        "total_results": 0,
                    }

                data = tool_result.get("data", {}) or {}
                results = data.get("results", []) or []

                shared = [
                    {
                        "id": item.get("metadata", {}).get("doc_id", ""),  # çŸ¥è¯†åº“æ¡ç›®ID
                        "content": str(item.get("content", "")),  # å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                        "source": item.get("metadata", {}).get("source", ""),
                        "title": item.get("metadata", {}).get("title", ""),
                        "score": float(item.get("score", 0.0)),
                    }
                    for item in results
                ]

                return {
                    "shared_knowledge": shared,
                    "specialized_knowledge": [],
                    "total_results": int(data.get("total_results", len(shared))),
                }
            except Exception as e:
                print(f"âš ï¸ é€šè¿‡RAGå·¥å…·æ£€ç´¢å¤±è´¥ ({self.title}): {e}", flush=True)
                # ç»§ç»­å›é€€åˆ°åº•å±‚æ¥å£

        # å›é€€ï¼šç›´æ¥ä½¿ç”¨åº•å±‚ RAG æ¥å£ï¼ˆå…¼å®¹æ—§å®ç°ï¼‰
        if not self._rag_interface:
            return {
                "shared_knowledge": [],
                "specialized_knowledge": [],
                "total_results": 0,
            }

        try:
            results = await self._rag_interface.query(
                query=query,
                strategy=strategy,
                top_k=top_k,
            )

            return {
                "shared_knowledge": [
                    {
                        "id": r.document_id,  # çŸ¥è¯†åº“æ¡ç›®ID
                        "content": r.content,  # å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                        "source": getattr(r, "source", ""),
                        "title": r.metadata.get("title", "") if hasattr(r, "metadata") and isinstance(r.metadata, dict) else "",
                        "score": getattr(r, "score", 0.0),
                    }
                    for r in results.shared_results
                ],
                "specialized_knowledge": [
                    {
                        "id": r.document_id,
                        "content": r.content,
                        "source": getattr(r, "source", ""),
                        "title": r.metadata.get("title", "") if hasattr(r, "metadata") and isinstance(r.metadata, dict) else "",
                        "score": getattr(r, "score", 0.0),
                    }
                    for r in getattr(results, "specialized_results", []) or []
                ],
                "total_results": len(results.shared_results)
                + len(getattr(results, "specialized_results", []) or []),
            }
        except Exception as e:
            print(f"âš ï¸ RAGæ£€ç´¢å¤±è´¥ ({self.title}): {e}", flush=True)
            return {
                "shared_knowledge": [],
                "specialized_knowledge": [],
                "total_results": 0,
            }

    async def analyze(
        self,
        task_plan: Dict[str, Any],
        state: Optional[REAgentState] = None
    ) -> CritiqueResult:
        """
        åˆ†æä»»åŠ¡æ–¹æ¡ˆå¹¶ç”ŸæˆCritiqueResult
        
        Args:
            task_plan: ä»»åŠ¡è®¡åˆ’å­—å…¸ï¼ŒåŒ…å«ï¼š
                - title: ä»»åŠ¡æ ‡é¢˜
                - description: ä»»åŠ¡æè¿°/èƒŒæ™¯
                - data_source: æ•°æ®æºä¿¡æ¯
                - methodology: æ–¹æ³•æè¿°
                - model_architecture: æ¨¡å‹æ¶æ„
                - evaluation_metrics: è¯„ä¼°æŒ‡æ ‡
            state: å½“å‰çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            CritiqueResultå¯¹è±¡
        """
        # 0. æ£€æŸ¥å¹¶æ€»ç»“è¿‡é•¿çš„æ¶ˆæ¯å†å²ï¼ˆå¦‚æœä» state ä¼ å…¥ï¼‰
        if state and state.get("messages"):
            state_messages = state.get("messages", [])
            # æ£€æŸ¥æ¶ˆæ¯å†å²é•¿åº¦ï¼ˆç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼‰
            total_chars = sum(len(str(msg.content)) if hasattr(msg, 'content') and msg.content else 0 for msg in state_messages)
            estimated_tokens = total_chars / 4
            
            # å¦‚æœä¼°è®¡è¶…è¿‡ 200000 tokensï¼Œæ€»ç»“æ—§æ¶ˆæ¯
            if estimated_tokens > 200000:
                print(f"  âš ï¸ æ¶ˆæ¯å†å²è¿‡é•¿ï¼Œè¿›è¡Œæ™ºèƒ½æ€»ç»“...", flush=True)
                # ä¿ç•™æœ€è¿‘çš„ 10 æ¡æ¶ˆæ¯ï¼Œæ€»ç»“ä¹‹å‰çš„æ¶ˆæ¯
                recent_messages = state_messages[-10:]
                old_messages = state_messages[:-10]
                
                if old_messages:
                    summary = await summarize_messages(old_messages, max_summary_length=2000)
                    # åˆ›å»ºæ€»ç»“æ¶ˆæ¯
                    summary_message = HumanMessage(
                        content=f"[Previous Conversation Summary]\n{summary}\n\n[Continuing with recent messages...]"
                    )
                    # ç”¨æ€»ç»“æ¶ˆæ¯æ›¿æ¢æ—§æ¶ˆæ¯
                    state["messages"] = [summary_message] + recent_messages
                    print(f"  âœ“ æ¶ˆæ¯å†å²å·²æ€»ç»“ï¼š{len(old_messages)} æ¡æ—§æ¶ˆæ¯ -> 1 æ¡æ€»ç»“æ¶ˆæ¯", flush=True)
        
        # 1. æ„å»ºåˆ†ææŸ¥è¯¢ï¼ˆåŒ…å«å…·ä½“çš„ä»»åŠ¡ä¿¡æ¯å’Œåœºæ™¯ç»†èŠ‚ï¼‰
        # æˆªæ–­è¿‡é•¿çš„å­—æ®µä»¥é¿å…è¾“å…¥è¿‡å¤§
        MAX_FIELD_LENGTH = 2000  # æ¯ä¸ªå­—æ®µæœ€å¤š2000å­—ç¬¦
        
        def truncate_field(text, max_len=MAX_FIELD_LENGTH):
            if not text:
                return ""
            if len(text) <= max_len:
                return text
            return text[:max_len] + f"\n[... Content truncated, original length: {len(text)} characters ...]"
        
        title = truncate_field(task_plan.get("title", ""), 500)
        description = truncate_field(task_plan.get("description", ""), MAX_FIELD_LENGTH)
        data_source = truncate_field(task_plan.get("data_source", ""), MAX_FIELD_LENGTH)
        methodology = truncate_field(task_plan.get("methodology", ""), MAX_FIELD_LENGTH)
        model_arch = truncate_field(task_plan.get("model_architecture", ""), MAX_FIELD_LENGTH)
        eval_metrics = truncate_field(task_plan.get("evaluation_metrics", ""), MAX_FIELD_LENGTH)
        code_instructions = truncate_field(task_plan.get("code_instructions", ""), MAX_FIELD_LENGTH)
        
        # æå–æ•°æ®é›†çš„å…³é”®ä¿¡æ¯ï¼ˆä»data_sourceä¸­ï¼‰
        dataset_details = ""
        if data_source:
            # å°è¯•æå–æ–‡ä»¶è·¯å¾„ã€æ•°æ®ç±»å‹ã€å­—æ®µç­‰ä¿¡æ¯
            if "File path:" in data_source:
                dataset_details = data_source.split("File path:")[1].split(";")[0].strip()
            if "Data type:" in data_source:
                data_type = data_source.split("Data type:")[1].split(";")[0].strip()
                dataset_details += f" {data_type}"
            if "Input features:" in data_source:
                features = data_source.split("Input features:")[1].split(";")[0].strip()
                dataset_details += f" features: {features}"
            if "Target variable:" in data_source:
                target = data_source.split("Target variable:")[1].split(";")[0].strip()
                dataset_details += f" target: {target}"
        
        # æ ¹æ®Agentè§’è‰²æ„å»ºç²¾ç®€ä¸”èšç„¦çš„æŸ¥è¯¢ï¼ˆçªå‡ºè§’è‰²ç‰¹ç‚¹ï¼‰
        if self.role == "data_management":
            query = f"""Data preprocessing and management: dataset type analysis (MPRA/RNA-seq/ChIP-seq/ATAC-seq), 
dataset size-based preprocessing strategies (large datasets: quality control and cleaning, 
small datasets: data augmentation), train/validation/test split, quality control procedures."""
        elif self.role == "methodology":
            query = f"""Training methodology: loss function design, optimization algorithms, regularization strategies, 
prior knowledge integration (motifs, PWMs), data augmentation, training pipeline workflow."""
        elif self.role == "model_architect":
            query = f"""Neural network architecture: dataset size-based complexity control (small datasets: compact architectures, 
large datasets: expressive architectures), innovative architecture design (attention, residual connections, multi-scale), 
parameter count estimation, robustness and generalization."""
        elif self.role == "result_analyst":
            query = f"""Evaluation and analysis: evaluation metrics, statistical testing, validation strategy 
(cross-validation, held-out test, external validation), biological validation methods, result interpretation."""
        else:
            query = f"""Experimental design: {title}"""

        # 2. ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³çŸ¥è¯†
        knowledge = await self.search_knowledge(query, strategy="hybrid", top_k=5)

        # 3. æ„å»ºåˆ†ææç¤º
        knowledge_context = self._format_knowledge_context(knowledge)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰Supervisoræä¾›çš„ä¸“é—¨ä»»åŠ¡prompt
        supervisor_task_prompt = task_plan.get("task_prompt", "")
        
        # æ ¹æ®Agentè§’è‰²æ„å»ºä¸åŒçš„è®¾è®¡æç¤º
        if self.role == "data_management":
            design_focus = "data usage plan"
            design_sections = [
                "1. Dataset characteristic analysis (dataset type: MPRA/RNA-seq/ChIP-seq/ATAC-seq/etc., sequence length distribution, dataset size and sample count, feature dimensions)",
                "2. Data source selection and justification",
                "3. Data preprocessing pipeline tailored to dataset characteristics (e.g., aggressive cleaning for large datasets, augmentation strategies for small datasets)",
                "4. Train/validation/test split strategy considering dataset size",
                "5. Data augmentation methods appropriate for dataset type and size",
                "6. Quality control procedures",
                "7. Bias mitigation strategies"
            ]
        elif self.role == "methodology":
            design_focus = "training methodology"
            design_sections = [
                "1. Loss function design and rationale",
                "2. Optimization algorithm and hyperparameters",
                "3. Regularization strategies",
                "4. Prior knowledge integration (motifs, PWMs, etc.)",
                "5. Data augmentation approaches",
                "6. Training pipeline workflow"
            ]
        elif self.role == "model_architect":
            design_focus = "model architecture"
            design_sections = [
                "1. Dataset size analysis and model complexity strategy (evaluate dataset size to determine appropriate parameter count and architecture complexity)",
                "2. Architecture type selection and rationale (encourage innovative and effective designs: attention mechanisms, residual connections, multi-scale convolutions, etc.)",
                "3. Detailed layer-by-layer design with parameter count justification",
                "4. Parameter count estimation and complexity control (flexibly adjust based on data volume: smaller models for limited data, larger models for abundant data)",
                "5. Long-range dependency modeling mechanisms",
                "6. Robustness considerations (generalization strategies, regularization integration, overfitting prevention)",
                "7. Interpretability features",
                "8. Computational efficiency considerations"
            ]
        elif self.role == "result_analyst":
            design_focus = "result analysis plan"
            design_sections = [
                "1. Evaluation metric suite selection",
                "2. Statistical testing design",
                "3. Validation strategy (cross-validation, held-out test, external validation)",
                "4. Biological validation methods",
                "5. Result interpretation framework",
                "6. Summary and reporting format"
            ]
        else:
            design_focus = "experimental design"
            design_sections = ["1. Design recommendations"]
        
        # ä¸º detailed_design æ˜ç¡®è¦æ±‚ç»“æ„åŒ–è¾“å‡ºï¼Œé¿å…ä¸ºç©º
        detailed_keys = [
            section.split(". ")[1].lower().replace(" ", "_")
            for section in design_sections
        ]
        detailed_keys_str = ", ".join(f'"{k}"' for k in detailed_keys)

        # æ£€æŸ¥æ˜¯å¦æœ‰RAGå·¥å…·ï¼Œå¦‚æœæœ‰åˆ™å¼ºåˆ¶è¦æ±‚ä½¿ç”¨
        has_rag_tool = any(tool.name == "rag_search" for tool in self._tools)
        rag_requirement = ""
        if has_rag_tool:
            # å¦‚æœé¢„æ£€ç´¢çš„çŸ¥è¯†å¾ˆå°‘æˆ–ä¸ºç©ºï¼Œå¼ºåˆ¶è¦æ±‚ä½¿ç”¨å·¥å…·
            total_knowledge = knowledge.get("total_results", 0)
            if total_knowledge < 3:
                rag_requirement = f"""
            
âš ï¸ CRITICAL: Pre-retrieved knowledge is insufficient ({total_knowledge} results). You MUST use the `rag_search` tool to search for relevant knowledge BEFORE providing your analysis.
- Call `rag_search` with query: "{query}" or a more specific query related to your expertise
- Use the retrieved knowledge to inform every aspect of your design
- Reference specific methods, techniques, or findings from the knowledge base in your detailed_design sections
- If the retrieved knowledge is still insufficient, refine your query and search again with different keywords
- DO NOT proceed with analysis without first retrieving sufficient knowledge from the RAG system
"""
            else:
                rag_requirement = f"""
            
âš ï¸ IMPORTANT: While some knowledge has been pre-retrieved, you SHOULD also use the `rag_search` tool to search for additional relevant knowledge if needed.
- You can call `rag_search` with query: "{query}" or refine it with more specific terms
- Use ALL retrieved knowledge (pre-retrieved + tool-retrieved) to inform your design
- Reference specific methods, techniques, or findings from the knowledge base in your detailed_design sections
"""
        
        # è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœSupervisorå·²è¯»å–ï¼‰
        dataset_stats = task_plan.get("dataset_statistics", {})
        dataset_stats_text = ""
        if dataset_stats:
            dataset_stats_text = "\n\nğŸ“Š Dataset Statistics (read by Supervisor):\n"
            for file_path, stats in dataset_stats.items():
                dataset_stats_text += f"File: {file_path}\n"
                dataset_stats_text += f"  - Number of rows (samples): {stats.get('num_rows', 'N/A')}\n"
                dataset_stats_text += f"  - Number of columns (features): {stats.get('num_cols', 'N/A')}\n"
                col_names = stats.get('column_names', [])
                if col_names:
                    # é™åˆ¶åˆ—åæ˜¾ç¤ºï¼šæœ€å¤šæ˜¾ç¤ºå‰20ä¸ªï¼Œé¿å…è¿‡é•¿
                    MAX_COL_NAMES = 20
                    if len(col_names) > MAX_COL_NAMES:
                        col_names_str = ', '.join(col_names[:MAX_COL_NAMES]) + f" ... (and {len(col_names) - MAX_COL_NAMES} more columns)"
                    else:
                        col_names_str = ', '.join(col_names)
                    dataset_stats_text += f"  - Column names ({len(col_names)}): {col_names_str}\n"
            
            # æ·»åŠ æ•°æ®é›†ç‰¹ç‚¹åˆ†ææç¤ºï¼ˆä»…å¯¹data_managementè§’è‰²ï¼‰
            if self.role == "data_management":
                dataset_stats_text += "\nâš ï¸ CRITICAL DATASET CHARACTERISTIC ANALYSIS REQUIRED:\n"
                dataset_stats_text += "You MUST analyze the following dataset characteristics:\n"
                dataset_stats_text += "1. Dataset Type: Identify from column names and task description (MPRA, RNA-seq, ChIP-seq, ATAC-seq, STARR-seq, etc.)\n"
                dataset_stats_text += "2. Sequence Length: Analyze sequence length distribution if sequence columns exist (mean, median, range, outliers)\n"
                dataset_stats_text += "3. Dataset Size: Evaluate number of samples to determine if dataset is small (<1K), medium (1K-10K), or large (>10K)\n"
                dataset_stats_text += "4. Data Volume: Assess feature dimensions and data sparsity\n"
                dataset_stats_text += "5. Preprocessing Strategy Selection:\n"
                dataset_stats_text += "   - Large datasets (>10K samples): Focus on aggressive quality control, cleaning, filtering, outlier removal\n"
                dataset_stats_text += "   - Small datasets (<1K samples): Prioritize data augmentation techniques (sequence augmentation, synthetic data generation)\n"
                dataset_stats_text += "   - Medium datasets (1K-10K): Balance between quality control and augmentation\n"
                dataset_stats_text += "6. Link dataset characteristics to specific preprocessing parameters (quality thresholds, augmentation ratios, filtering criteria)\n"
            elif self.role == "model_architect":
                dataset_stats_text += "\nâš ï¸ CRITICAL MODEL COMPLEXITY CONTROL REQUIRED:\n"
                dataset_stats_text += "You MUST analyze dataset size and flexibly control model parameters and complexity:\n"
                dataset_stats_text += "1. Dataset Size Analysis: Evaluate number of samples to determine appropriate model complexity\n"
                dataset_stats_text += "2. Model Complexity Strategy:\n"
                dataset_stats_text += "   - Small datasets (<1K samples): Design compact architectures with fewer parameters, strong regularization, innovative architectural choices\n"
                dataset_stats_text += "   - Medium datasets (1K-10K samples): Design moderate complexity architectures with balanced parameter counts\n"
                dataset_stats_text += "   - Large datasets (>10K samples): Design more expressive architectures with higher capacity while maintaining efficiency\n"
                dataset_stats_text += "3. Parameter Count Justification: Provide clear rationale linking dataset size to parameter count decisions\n"
                dataset_stats_text += "4. Innovative Architecture Design: Encourage effective architectural choices (attention mechanisms, residual connections, multi-scale features, etc.)\n"
                dataset_stats_text += "5. Robustness: Ensure generalization strategies, overfitting prevention, and regularization integration\n"
        
        # æˆªæ–­ supervisor_task_prompt å¦‚æœè¿‡é•¿
        if supervisor_task_prompt and supervisor_task_prompt.strip():
            supervisor_task_prompt = truncate_field(supervisor_task_prompt, MAX_FIELD_LENGTH)
        
        # å¦‚æœSupervisoræä¾›äº†ä¸“é—¨çš„ä»»åŠ¡promptï¼Œä¼˜å…ˆä½¿ç”¨å®ƒ
        if supervisor_task_prompt and supervisor_task_prompt.strip():
            task_instruction = f"""
Supervisor's Specific Task Assignment for You:
{supervisor_task_prompt}

Task Context:
Title: {title}
Background/Description: {description}
Data Source: {data_source}
Methodology: {methodology or "To be designed"}
Model Architecture: {model_arch or "To be designed"}
Evaluation Metrics: {eval_metrics or "To be designed"}
{dataset_stats_text}
"""
        else:
            # ä½¿ç”¨é€šç”¨çš„ä»»åŠ¡æè¿°
            task_instruction = f"""
Task Information:
Title: {title}
Background/Description: {description}
Data Source: {data_source}
Methodology: {methodology or "To be designed"}
Model Architecture: {model_arch or "To be designed"}
Evaluation Metrics: {eval_metrics or "To be designed"}
{dataset_stats_text}

Your task is to design a comprehensive {design_focus} based on the task information above.
"""
        
        analysis_prompt = f"""You are designing an experimental plan for gene regulatory element design.

âš ï¸ CRITICAL LANGUAGE REQUIREMENT:
- You MUST write ALL responses in English (EN). Do NOT use Chinese, Japanese, or any other language.
- All text in "design_summary", "detailed_design", "strengths", "potential_issues", "recommendations" MUST be in English.
- This is a strict requirement for international publication standards.

{task_instruction}

Relevant Knowledge from Literature (pre-retrieved):
{knowledge_context}
{rag_requirement}

âš ï¸ DETAILED ANALYSIS REQUIREMENTS:
1. You MUST provide EXTENSIVE and DETAILED design plan - focus on comprehensive design specifications, not code implementation
2. For DATA MANAGEMENT role, you MUST FIRST conduct comprehensive dataset characteristic analysis:
   - Identify dataset type (MPRA, RNA-seq, ChIP-seq, ATAC-seq, STARR-seq, etc.) and explain its implications for preprocessing
   - Analyze sequence length distribution (mean, median, range, outliers) and its impact on preprocessing choices
   - Evaluate dataset size (number of samples) and determine if it's small (<1K), medium (1K-10K), or large (>10K)
   - Assess data volume and feature dimensions to guide preprocessing strategy
   - CRITICALLY link dataset characteristics to preprocessing strategy selection:
     * Large datasets (>10K samples): Focus on aggressive quality control, cleaning, filtering, outlier removal
     * Small datasets (<1K samples): Prioritize data augmentation techniques (sequence augmentation, synthetic data generation, etc.)
     * Medium datasets (1K-10K): Balance between quality control and augmentation
   - Provide specific preprocessing parameters based on dataset type and size (e.g., quality thresholds, augmentation ratios, filtering criteria)
3. Each section in "detailed_design" MUST contain:
   - At least 5-7 detailed sentences explaining the design approach and rationale
   - SPECIFIC parameter values, hyperparameter settings, and configuration details (this is CRITICAL)
   - Detailed model architecture specifications (for model architect: layer dimensions, activation functions, dropout rates, batch normalization settings, etc.)
   - Algorithm choices with detailed justification and parameter settings
   - Step-by-step design specifications and workflow
   - References to relevant methods from the knowledge base (if available)
   - Concrete design examples or use cases
4. For MODEL ARCHITECT role, you MUST provide EXTENSIVE parameter design details:
   - Layer-by-layer architecture with exact dimensions (input/output sizes, kernel sizes, stride, padding)
   - All hyperparameters: learning rate, batch size, dropout rates, weight decay, optimizer parameters
   - Activation functions and their parameters (e.g., LeakyReLU negative_slope, ELU alpha)
   - Regularization parameters (L1/L2 coefficients, dropout probabilities, batch norm momentum)
   - Initialization strategies and their parameters (e.g., Xavier/Glorot initialization parameters)
   - Training configuration (epochs, early stopping criteria, learning rate schedule parameters)
   - Model capacity estimation (total parameter count, FLOPs if applicable)
4. "strengths" and "potential_issues" should be BRIEF (1-2 items each, focus on critical points only)
5. "recommendations" MUST be concrete, actionable design improvements (at least 3-5 items) with specific parameter suggestions or configuration details

âš ï¸ STRICT SCORING CRITERIA (You MUST be strict and critical):
- Score 9.0-10.0: Design is EXCELLENT - comprehensive design specifications with detailed parameter values, all requirements met, minimal issues
- Score 8.5-8.9: Design is GOOD but has some gaps - mostly complete with most parameters specified, minor improvements needed
- Score 8.0-8.4: Design is ACCEPTABLE but needs refinement - missing some parameter details, moderate improvements needed
- Score < 8.0: Design needs SIGNIFICANT improvement - major gaps in parameter specifications, substantial design details missing

You MUST return a valid JSON object with ALL of the following top-level fields:
- "score": a float in [0,10] evaluating the feasibility and quality of your design (BE STRICT - only give 8.5+ if design is truly comprehensive with detailed parameters)
- "design_summary": a comprehensive summary (at least 5-7 sentences) of your design approach
- "detailed_design": an object containing detailed design specifications with parameter values (THIS IS THE MOST IMPORTANT PART)
- "strengths": a brief list of 1-2 key strengths (keep it concise)
- "potential_issues": a brief list of 1-2 critical potential issues (keep it concise)
- "recommendations": a list of at least 3-5 concrete, actionable design recommendations with specific parameter suggestions or configuration details
- "confidence": a float in [0,1] representing your confidence

IMPORTANT: Only give a score >= 8.5 if:
1. All design sections include detailed parameter specifications and values
2. All required design sections are fully detailed with comprehensive specifications
3. Design plan is comprehensive and actionable with clear parameter settings
4. For model architect: architecture specifications include exact dimensions, hyperparameters, and all configuration details
5. Design addresses all aspects of the task requirements with specific parameter values

If any of these are missing or incomplete, score should be < 8.5.

The "detailed_design" field MUST be a JSON object with ALL of these keys (do NOT leave them empty or omit them):
- {detailed_keys_str}

For each key in "detailed_design", write 5-7 DETAILED sentences describing your design for that aspect. Include:
- Technical rationale and justification
- SPECIFIC parameter values, hyperparameter settings, and configuration details (this is CRITICAL)
- Detailed design specifications (for model architect: exact layer dimensions, activation parameters, regularization settings, etc.)
- Step-by-step design workflow and configuration
- References to relevant knowledge from the literature (if available)
- Design examples or use cases with parameter values

Return ONLY the JSON object, no extra text.

Focus on your area of expertise: {self.expertise}
Your goal: {self.goal}
"""

        # 4. è°ƒç”¨LLMè¿›è¡Œåˆ†æï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        try:
            messages = [
                SystemMessage(content=self.prompt()),
                HumanMessage(content=analysis_prompt)
            ]
            
            # ä½¿ç”¨æ”¯æŒå·¥å…·è°ƒç”¨çš„LLMï¼Œä½¿Agentåœ¨éœ€è¦æ—¶å¯ä»¥è°ƒç”¨RAGã€æ–‡ä»¶è¯»å†™ç­‰å·¥å…·
            response = await self.llm_with_tools.ainvoke(messages)
            
            # å¤„ç†å·¥å…·è°ƒç”¨ï¼šå¦‚æœLLMè¿”å›å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·å¹¶ç»§ç»­å¯¹è¯
            max_tool_iterations = 3  # æœ€å¤šå…è®¸3è½®å·¥å…·è°ƒç”¨
            tool_iteration = 0
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬çš„LangChainï¼‰
            has_tool_calls = False
            if hasattr(response, "tool_calls") and response.tool_calls:
                has_tool_calls = True
            elif hasattr(response, "additional_kwargs") and response.additional_kwargs.get("tool_calls"):
                has_tool_calls = True
            
            while tool_iteration < max_tool_iterations and has_tool_calls:
                tool_iteration += 1
                print(f"  ğŸ”§ {self.title} æ­£åœ¨ä½¿ç”¨å·¥å…· (ç¬¬ {tool_iteration} è½®)...", flush=True)
                
                # æ£€æŸ¥æ¶ˆæ¯é•¿åº¦ï¼Œå¦‚æœè¿‡é•¿åˆ™æ€»ç»“
                total_chars = sum(len(str(msg.content)) if hasattr(msg, 'content') and msg.content else 0 for msg in messages)
                estimated_tokens = total_chars / 4
                if estimated_tokens > 200000:
                    print(f"  âš ï¸ æ¶ˆæ¯å†å²è¿‡é•¿ï¼Œè¿›è¡Œæ™ºèƒ½æ€»ç»“...", flush=True)
                    # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ã€æœ€è¿‘çš„å“åº”å’Œæœ€è¿‘çš„å·¥å…·ç»“æœ
                    system_msg = messages[0] if messages and isinstance(messages[0], SystemMessage) else None
                    recent_messages = messages[-5:] if len(messages) > 5 else messages[1:]  # ä¿ç•™æœ€è¿‘5æ¡ï¼ˆæ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰
                    old_messages = messages[1:-5] if len(messages) > 6 else []
                    
                    if old_messages:
                        summary = await summarize_messages(old_messages, max_summary_length=1500)
                        summary_msg = HumanMessage(
                            content=f"[Previous Tool Call History Summary]\n{summary}\n\n[Continuing with recent messages...]"
                        )
                        # é‡å»ºæ¶ˆæ¯åˆ—è¡¨
                        if system_msg:
                            messages = [system_msg, summary_msg] + recent_messages
                        else:
                            messages = [summary_msg] + recent_messages
                        print(f"  âœ“ æ¶ˆæ¯å†å²å·²æ€»ç»“ï¼š{len(old_messages)} æ¡æ—§æ¶ˆæ¯ -> 1 æ¡æ€»ç»“æ¶ˆæ¯", flush=True)
                
                # æ·»åŠ LLMå“åº”åˆ°æ¶ˆæ¯å†å²
                messages.append(response)
                
                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                tool_results = []
                tool_calls_list = []
                if hasattr(response, "tool_calls") and response.tool_calls:
                    tool_calls_list = response.tool_calls
                elif hasattr(response, "additional_kwargs") and response.additional_kwargs.get("tool_calls"):
                    tool_calls_list = response.additional_kwargs["tool_calls"]
                
                for tool_call in tool_calls_list:
                    # å¤„ç†ä¸åŒæ ¼å¼çš„å·¥å…·è°ƒç”¨
                    if isinstance(tool_call, dict):
                        tool_name = tool_call.get("name", "") or tool_call.get("function", {}).get("name", "")
                        tool_args = tool_call.get("args", {}) or tool_call.get("function", {}).get("arguments", {})
                        tool_call_id = tool_call.get("id", "") or tool_call.get("function", {}).get("id", "")
                        # å¦‚æœargsæ˜¯å­—ç¬¦ä¸²ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œè§£æå®ƒ
                        if isinstance(tool_args, str):
                            import json
                            try:
                                tool_args = json.loads(tool_args)
                            except:
                                tool_args = {}
                    else:
                        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•è·å–å±æ€§
                        tool_name = getattr(tool_call, "name", "") or (getattr(tool_call, "function", None) and getattr(tool_call.function, "name", ""))
                        tool_args = getattr(tool_call, "args", {}) or (getattr(tool_call, "function", None) and getattr(tool_call.function, "arguments", {}))
                        tool_call_id = getattr(tool_call, "id", "")
                        if isinstance(tool_args, str):
                            import json
                            try:
                                tool_args = json.loads(tool_args)
                            except:
                                tool_args = {}
                    
                    # ç¡®ä¿ tool_call_id ä¸ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™ç”Ÿæˆä¸€ä¸ª
                    if not tool_call_id:
                        import uuid
                        tool_call_id = f"call_{uuid.uuid4().hex[:12]}"
                        print(f"    âš ï¸ Tool call missing ID, generated: {tool_call_id}", flush=True)
                    
                    # å¦‚æœ tool_name ä¸ºç©ºï¼Œä»ç„¶éœ€è¦åˆ›å»º ToolMessage ä»¥é¿å…é”™è¯¯
                    if not tool_name:
                        tool_results.append({
                            "tool_call_id": tool_call_id,
                            "name": "unknown",
                            "content": f"Tool call has no name. Original tool_call: {str(tool_call)[:200]}"
                        })
                        continue
                    
                    # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                    tool = next((t for t in self._tools if t.name == tool_name), None)
                    if tool:
                        try:
                            # æ‰§è¡Œå·¥å…·ï¼ˆæ”¯æŒå¼‚æ­¥ï¼‰
                            if hasattr(tool, "_arun"):
                                result = await tool._arun(**tool_args)
                            else:
                                result = tool._run(**tool_args)
                            
                            # æ ¼å¼åŒ–å·¥å…·ç»“æœ
                            if isinstance(result, dict) and result.get("success"):
                                tool_results.append({
                                    "tool_call_id": tool_call_id,
                                    "name": tool_name,
                                    "content": f"Tool '{tool_name}' executed successfully. Result: {result.get('data', {})}"
                                })
                                # å¦‚æœæ˜¯RAGå·¥å…·ï¼Œæ›´æ–°knowledge_context
                                if tool_name == "rag_search" and isinstance(result.get("data"), dict):
                                    rag_results = result.get("data", {})
                                    # åˆå¹¶åˆ°ç°æœ‰knowledgeä¸­
                                    existing_shared = knowledge.get("shared_knowledge", [])
                                    new_shared = rag_results.get("results", [])
                                    # å»é‡å¹¶åˆå¹¶
                                    all_sources = {item.get("metadata", {}).get("source", "") for item in existing_shared}
                                    for item in new_shared:
                                        item_source = item.get("metadata", {}).get("source", "")
                                        if item_source not in all_sources:
                                            existing_shared.append({
                                                "content": str(item.get("content", ""))[:500],
                                                "source": item_source,
                                                "score": float(item.get("score", 0.0)),
                                            })
                                            all_sources.add(item_source)
                                    knowledge["shared_knowledge"] = existing_shared[:10]  # æœ€å¤šä¿ç•™10æ¡
                                    knowledge["total_results"] = len(existing_shared)
                                    knowledge_context = self._format_knowledge_context(knowledge)
                            else:
                                tool_results.append({
                                    "tool_call_id": tool_call_id,
                                    "name": tool_name,
                                    "content": f"Tool '{tool_name}' returned: {result}"
                                })
                        except Exception as e:
                            print(f"    âš ï¸ å·¥å…· '{tool_name}' æ‰§è¡Œå¤±è´¥: {e}", flush=True)
                            tool_results.append({
                                "tool_call_id": tool_call_id,
                                "name": tool_name,
                                "content": f"Tool '{tool_name}' execution failed: {str(e)}"
                            })
                    else:
                        tool_results.append({
                            "tool_call_id": tool_call_id,
                            "name": tool_name,
                            "content": f"Tool '{tool_name}' not found"
                        })
                
                # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²ï¼ˆLangChainæ ¼å¼ï¼‰
                # ç¡®ä¿æ¯ä¸ª tool_call éƒ½æœ‰å¯¹åº”çš„ ToolMessage
                processed_tool_call_ids = set()
                for tool_result in tool_results:
                    tool_call_id = tool_result.get("tool_call_id", "")
                    if tool_call_id:
                        messages.append(ToolMessage(
                            content=tool_result["content"],
                            tool_call_id=tool_call_id
                        ))
                        processed_tool_call_ids.add(tool_call_id)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„ tool_call_idï¼ˆä» response ä¸­è·å–æ‰€æœ‰ tool_call_idsï¼‰
                all_tool_call_ids = set()
                for tool_call in tool_calls_list:
                    if isinstance(tool_call, dict):
                        call_id = tool_call.get("id", "") or tool_call.get("function", {}).get("id", "")
                    else:
                        call_id = getattr(tool_call, "id", "")
                    if call_id:
                        all_tool_call_ids.add(call_id)
                
                # ä¸ºä»»ä½•é—æ¼çš„ tool_call_id åˆ›å»ºç©ºçš„ ToolMessage
                missing_ids = all_tool_call_ids - processed_tool_call_ids
                if missing_ids:
                    print(f"    âš ï¸ å‘ç°é—æ¼çš„ tool_call_ids: {missing_ids}ï¼Œåˆ›å»ºç©ºå“åº”", flush=True)
                    for missing_id in missing_ids:
                        messages.append(ToolMessage(
                            content="Tool execution was skipped or failed to generate response.",
                            tool_call_id=missing_id
                    ))
                
                # å¦‚æœknowledge_contextå·²æ›´æ–°ï¼Œæ›´æ–°prompt
                if knowledge_context != self._format_knowledge_context(knowledge):
                    # é‡æ–°æ„å»ºpromptï¼ˆç®€åŒ–ç‰ˆï¼Œåªæ·»åŠ æ›´æ–°çš„knowledgeï¼‰
                    update_message = HumanMessage(
                        content=f"Updated knowledge context:\n{knowledge_context}\n\nPlease continue your analysis based on this updated knowledge."
                    )
                    messages.append(update_message)
                
                # ç»§ç»­è°ƒç”¨LLM
                response = await self.llm_with_tools.ainvoke(messages)
                
                # æ›´æ–°has_tool_callsæ ‡å¿—
                has_tool_calls = False
                if hasattr(response, "tool_calls") and response.tool_calls:
                    has_tool_calls = True
                elif hasattr(response, "additional_kwargs") and response.additional_kwargs.get("tool_calls"):
                    has_tool_calls = True
            
            # è·å–æœ€ç»ˆçš„åˆ†ææ–‡æœ¬
            analysis_text = response.content
            if not analysis_text and (hasattr(response, "tool_calls") and response.tool_calls or 
                                      (hasattr(response, "additional_kwargs") and response.additional_kwargs.get("tool_calls"))):
                # å¦‚æœåªæœ‰å·¥å…·è°ƒç”¨æ²¡æœ‰æ–‡æœ¬ï¼Œæç¤ºLLMç”Ÿæˆåˆ†æ
                messages.append(response)
                messages.append(HumanMessage(content="Please provide your analysis based on the tool results above. Return the JSON object as required."))
                response = await self.llm_with_tools.ainvoke(messages)
                analysis_text = response.content

            # 5. è§£æLLMå“åº”
            critique_data = self._parse_analysis_response(analysis_text)

            # 6. æ„å»ºCritiqueResultï¼ˆåŒ…å«è®¾è®¡è¯¦æƒ…å’Œæ£€ç´¢åˆ°çš„çŸ¥è¯†æ¡ç›®ï¼‰
            # æå–æ£€ç´¢åˆ°çš„çŸ¥è¯†æ¡ç›®ï¼ˆid + å†…å®¹ï¼‰ï¼Œç”¨äºå¯è§£é‡Šæ€§
            retrieved_knowledge_items = []
            shared_knowledge = knowledge.get("shared_knowledge", [])
            specialized_knowledge = knowledge.get("specialized_knowledge", [])
            
            for item in shared_knowledge + specialized_knowledge:
                retrieved_knowledge_items.append({
                    "id": item.get("id", ""),
                    "title": item.get("title", ""),
                    "content": item.get("content", ""),  # å®Œæ•´å†…å®¹
                    "source": item.get("source", ""),
                    "relevance_score": item.get("score", 0.0)
                })
            
            return CritiqueResult(
                agent_role=self.role,
                score=critique_data.get("score", 5.0),
                strengths=critique_data.get("strengths", []),
                weaknesses=critique_data.get("potential_issues", critique_data.get("weaknesses", [])),
                recommendations=critique_data.get("recommendations", []),
                confidence=critique_data.get("confidence", 0.5),
                metadata={
                    "query": query,
                    "knowledge_results": knowledge.get("total_results", 0),
                    "retrieved_knowledge": retrieved_knowledge_items,  # æ£€ç´¢åˆ°çš„çŸ¥è¯†æ¡ç›®ï¼ˆid + å†…å®¹ï¼‰
                    "model": self.model,
                    "design_summary": critique_data.get("design_summary", ""),
                    "detailed_design": critique_data.get("detailed_design", {})
                }
            )

        except Exception as e:
            print(f"âš ï¸ Agentåˆ†æå¤±è´¥ ({self.title}): {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return CritiqueResult(
                agent_role=self.role,
                score=0.0,
                strengths=[],
                weaknesses=[f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"],
                recommendations=["è¯·æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼"],
                confidence=0.0,
                metadata={"error": str(e)}
            )

    def _format_knowledge_context(self, knowledge: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–çŸ¥è¯†ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        # é™åˆ¶æ¯æ¡çŸ¥è¯†å†…å®¹çš„é•¿åº¦ï¼Œé¿å…è¿‡é•¿
        MAX_CONTENT_LENGTH = 3000  # æ¯æ¡çŸ¥è¯†æœ€å¤š3000å­—ç¬¦

        shared = knowledge.get("shared_knowledge", [])
        if shared:
            context_parts.append("Shared Knowledge (from RAG retrieval):")
            for i, item in enumerate(shared[:5], 1):  # æœ€å¤š5æ¡
                content = item.get('content', '')
                # æˆªæ–­è¿‡é•¿çš„å†…å®¹
                if len(content) > MAX_CONTENT_LENGTH:
                    content = content[:MAX_CONTENT_LENGTH] + f"\n[... Content truncated, original length: {len(content)} characters ...]"
                source = item.get('source', 'Unknown')
                score = item.get('score', 0.0)
                context_parts.append(f"{i}. [{source}] (relevance score: {score:.3f})\n   {content}")

        specialized = knowledge.get("specialized_knowledge", [])
        if specialized:
            context_parts.append("\nSpecialized Knowledge:")
            for i, item in enumerate(specialized[:5], 1):  # æœ€å¤š5æ¡
                content = item.get('content', '')
                # æˆªæ–­è¿‡é•¿çš„å†…å®¹
                if len(content) > MAX_CONTENT_LENGTH:
                    content = content[:MAX_CONTENT_LENGTH] + f"\n[... Content truncated, original length: {len(content)} characters ...]"
                source = item.get('source', 'Unknown')
                score = item.get('score', 0.0)
                context_parts.append(f"{i}. [{source}] (relevance score: {score:.3f})\n   {content}")

        if not context_parts:
            return "âš ï¸ No relevant knowledge found in the knowledge base. You MUST use the rag_search tool to retrieve knowledge before proceeding."

        return "\n".join(context_parts)

    def _parse_analysis_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æLLMçš„åˆ†æå“åº”"""
        import json
        import re

        # å°è¯•æå–JSON
        try:
            # æŸ¥æ‰¾JSONä»£ç å—
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))

            # æŸ¥æ‰¾æ™®é€šJSONå¯¹è±¡
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))

        except json.JSONDecodeError:
            pass

        # é™çº§ï¼šä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
        result = {
            "score": 5.0,
            "strengths": [],
            "weaknesses": [],
            "recommendations": [],
            "confidence": 0.5,
            "design_summary": "",
            "detailed_design": {}
        }

        # å°è¯•æå–åˆ†æ•°
        score_match = re.search(r'score["\']?\s*[:=]\s*(\d+\.?\d*)', response_text, re.IGNORECASE)
        if score_match:
            try:
                result["score"] = float(score_match.group(1))
            except:
                pass

        # æå–åˆ—è¡¨é¡¹
        for key in ["strengths", "weaknesses", "recommendations"]:
            pattern = rf'{key}["\']?\s*[:=]\s*\[(.*?)\]'
            match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)
            if match:
                items = re.findall(r'"([^"]+)"', match.group(1))
                result[key] = items

        # å°è¯•æå–design_summary
        summary_match = re.search(r'"design_summary"\s*:\s*"([^"]+)"', response_text, re.DOTALL | re.IGNORECASE)
        if summary_match:
            result["design_summary"] = summary_match.group(1)
        
        # å°è¯•æå–detailed_designï¼ˆè¿™æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œæ¯”è¾ƒå¤æ‚ï¼‰
        # å…ˆå°è¯•æ‰¾åˆ°detailed_designçš„å¼€å§‹å’Œç»“æŸ
        detailed_match = re.search(r'"detailed_design"\s*:\s*(\{.*?\})', response_text, re.DOTALL | re.IGNORECASE)
        if detailed_match:
            try:
                # å°è¯•è§£ædetailed_designå¯¹è±¡
                detailed_str = detailed_match.group(1)
                result["detailed_design"] = json.loads(detailed_str)
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œè‡³å°‘ä¿ç•™åŸå§‹æ–‡æœ¬
                result["detailed_design"] = {"raw_text": detailed_match.group(1)}

        return result

    def __hash__(self) -> int:
        return hash(self.title)

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, Agent):
            return False

        return (
            self.title == other.title
            and self.expertise == other.expertise
            and self.goal == other.goal
            and self.role == other.role
            and self.model == other.model
        )

    def __str__(self) -> str:
        return self.title

    def __repr__(self) -> str:
        return self.title
