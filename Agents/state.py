"""
Agents/state.py
å®šä¹‰Agentç³»ç»Ÿçš„çŠ¶æ€å’Œæ•°æ®ç»“æ„
"""

from typing import Dict, Any, List, Optional, TypedDict, Literal
from dataclasses import dataclass, field
from langchain_core.messages import BaseMessage


# ==================== Agentè§’è‰²æšä¸¾ ====================

class AgentRole:
    """Agentè§’è‰²å®šä¹‰"""
    DATA_MANAGEMENT = "data_management"
    METHODOLOGY = "methodology"
    MODEL_ARCHITECT = "model_architect"
    RESULT_ANALYST = "result_analyst"
    
    ALL_ROLES = [DATA_MANAGEMENT, METHODOLOGY, MODEL_ARCHITECT, RESULT_ANALYST]


# ==================== çŠ¶æ€å®šä¹‰ ====================

class REAgentState(TypedDict, total=False):
    """RE-Agentç³»ç»Ÿçš„çŠ¶æ€"""
    messages: List[BaseMessage]
    
    # ä»»åŠ¡ä¿¡æ¯ï¼ˆç”±ç”¨æˆ·æä¾›ï¼‰
    task_description: Optional[str]  # ä»»åŠ¡æè¿°
    background: Optional[str]  # èƒŒæ™¯è¦æ±‚
    dataset_info: Optional[str]  # æ•°æ®é›†ä¿¡æ¯
    methodology: Optional[str]  # æ–¹æ³•æè¿°ï¼ˆå¯é€‰ï¼‰
    model_architecture: Optional[str]  # æ¨¡å‹æ¶æ„ï¼ˆå¯é€‰ï¼‰
    evaluation_metrics: Optional[str]  # è¯„ä¼°æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰
    additional_info: Optional[Dict[str, Any]]  # å…¶ä»–é™„åŠ ä¿¡æ¯
    agent_task_plans: Optional[Dict[str, Dict[str, Any]]]  # ç”±SupervisoræŒ‰è§’è‰²åˆ†é…çš„ä»»åŠ¡è®¡åˆ’
    dataset_statistics: Optional[Dict[str, Dict[str, Any]]]  # æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ–‡ä»¶è·¯å¾„ -> {è¡Œæ•°, åˆ—æ•°, åˆ—å}ï¼‰
    
    # å·¥ä½œæµæ§åˆ¶
    next_action: Literal["request_info", "analyze", "discuss", "iterate", "report", "end"]
    
    # ä¸“å®¶åˆ†æç»“æœ
    data_critique: Optional[Dict[str, Any]]
    methodology_critique: Optional[Dict[str, Any]]
    model_critique: Optional[Dict[str, Any]]
    results_critique: Optional[Dict[str, Any]]
    
    # è¿­ä»£æ§åˆ¶
    iteration_count: int
    max_iterations: int
    
    # æœ€ç»ˆæŠ¥å‘Š
    final_report: Optional[Dict[str, Any]]


# ==================== åˆ†æç»“æœæ¨¡å‹ ====================

@dataclass
class CritiqueResult:
    """ä¸“å®¶åˆ†æç»“æœ"""
    agent_role: str
    score: float  # 0-10åˆ†
    strengths: List[str]
    weaknesses: List[str]
    recommendations: List[str]
    confidence: float  # 0-1
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class OptimizationReport:
    """ä¼˜åŒ–æŠ¥å‘Š"""
    title: str
    summary: str
    critiques: Dict[str, CritiqueResult]
    overall_score: float
    priority_recommendations: List[str]
    metadata: Dict[str, Any] = field(default_factory=dict)


# ==================== å·¥å…·æ³¨å†Œè¡¨ ====================
# ==================== å·¥å…·åŸºç±» ====================

from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field, PrivateAttr


ToolResult = Dict[str, Any]


class BioAgentToolInput(BaseModel):
    """Bio-Agentå·¥å…·çš„é€šç”¨è¾“å…¥æ¨¡å‹"""
    pass


class BioAgentTool(BaseTool):
    """
    Bio-Agentå·¥å…·åŸºç±»
    
    æ‰€æœ‰å·¥å…·éƒ½åº”ç»§æ‰¿æ­¤ç±»
    """
    
    def _run(self, *args, **kwargs) -> ToolResult:
        """åŒæ­¥æ‰§è¡Œï¼ˆå¿…é¡»å®ç°ï¼‰"""
        raise NotImplementedError("å·¥å…·å¿…é¡»å®ç°_runæ–¹æ³•")
    
    async def _arun(self, *args, **kwargs) -> ToolResult:
        """å¼‚æ­¥æ‰§è¡Œï¼ˆå¯é€‰ï¼‰"""
        return self._run(*args, **kwargs)
    
    def format_success(self, data: Any, metadata: Dict[str, Any] = None) -> ToolResult:
        """æ ¼å¼åŒ–æˆåŠŸç»“æœ"""
        # æ‰“å°å·¥å…·è°ƒç”¨çŠ¶æ€ï¼Œä¾¿äºåœ¨ç»ˆç«¯è§‚å¯Ÿå·¥å…·ä½¿ç”¨æƒ…å†µ
        try:
            tool_name = getattr(self, "name", self.__class__.__name__)
            print(f"ğŸ› ï¸ Tool '{tool_name}' SUCCESS", flush=True)
        except Exception:
            # æ—¥å¿—å¤±è´¥ä¸å½±å“æ­£å¸¸è¿”å›
            pass

        return {
            "status": "success",
            "success": True,
            "data": data,
            "error": None,
            "metadata": metadata or {}
        }
    
    def format_error(self, error: str, metadata: Dict[str, Any] = None) -> ToolResult:
        """æ ¼å¼åŒ–é”™è¯¯ç»“æœ"""
        # æ‰“å°å·¥å…·è°ƒç”¨å¤±è´¥çŠ¶æ€
        try:
            tool_name = getattr(self, "name", self.__class__.__name__)
            print(f"âŒ Tool '{tool_name}' ERROR: {error}", flush=True)
        except Exception:
            pass

        return {
            "status": "error",
            "success": False,
            "data": None,
            "error": error,
            "metadata": metadata or {}
        }


# ==================== å·¥å…·1ï¼šRAGæ£€ç´¢å·¥å…· ====================

from RAG.rag import HybridRAGSystem, AgentRAGInterface


class RAGSearchInput(BioAgentToolInput):
    """RAGæ£€ç´¢å·¥å…·è¾“å…¥"""
    query: str = Field(description="æ£€ç´¢æŸ¥è¯¢æ–‡æœ¬")
    agent_role: str = Field(
        default="data_management",
        description="æ™ºèƒ½ä½“è§’è‰²ï¼ˆdata_management/methodology/model_architect/result_analystï¼‰ï¼Œç”¨äºä¸Šä¸‹æ–‡ç†è§£"
    )
    top_k: int = Field(default=5, description="è¿”å›ç»“æœæ•°é‡")


class RAGSearchTool(BioAgentTool):
    """RAGçŸ¥è¯†æ£€ç´¢å·¥å…· - ä»å…±äº«çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡çŒ®å’Œä¸“ä¸šçŸ¥è¯†"""
    
    name: str = "rag_search"
    description: str = """
    ä»æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢åŸºå› è°ƒæ§å…ƒä»¶è®¾è®¡ç›¸å…³çš„æ–‡çŒ®å’Œä¸“ä¸šçŸ¥è¯†ã€‚
    çŸ¥è¯†åº“åŒ…å«ï¼šPubMedæ–‡çŒ®ã€arXivé¢„å°æœ¬ã€bioRxivé¢„å°æœ¬ã€PMCå¼€æ”¾è·å–æ–‡ç« ã€GitHubä»£ç åº“ç­‰ã€‚
    å¯ä»¥æœç´¢ï¼šæ•°æ®ç®¡ç†ã€è®­ç»ƒæ–¹æ³•ã€æ¨¡å‹æ¶æ„ã€è¯„ä¼°æŒ‡æ ‡ç­‰ä¸“ä¸šçŸ¥è¯†ã€‚
    """
    args_schema: type[BaseModel] = RAGSearchInput

    # ä½¿ç”¨PrivateAttrå­˜å‚¨åº•å±‚RAGç³»ç»Ÿï¼Œé¿å…pydanticå­—æ®µæ ¡éªŒé”™è¯¯
    _rag_system: HybridRAGSystem = PrivateAttr()

    def __init__(self, rag_system: Optional[HybridRAGSystem] = None, **data: Any):
        super().__init__(**data)
        self._rag_system = rag_system or HybridRAGSystem()
    
    async def _arun(
        self,
        query: str,
        agent_role: str = "data_management",
        top_k: int = 5
    ) -> ToolResult:
        """æ‰§è¡ŒRAGæ£€ç´¢"""
        try:
            # åˆ›å»ºAgentæ¥å£
            rag_interface = AgentRAGInterface(self._rag_system, agent_role)
            
            # æ‰§è¡Œæ£€ç´¢ï¼ˆç°åœ¨åªæœ‰å…±äº«åº“ï¼‰
            results = await rag_interface.query(
                query=query,
                strategy="hybrid",  # ä¿ç•™å‚æ•°ä»¥å…¼å®¹ï¼Œä½†å®é™…åªä½¿ç”¨å…±äº«åº“
                top_k=top_k
            )
            
            # ç»Ÿè®¡æ€»ç»“æœæ•°ï¼ˆç°åœ¨åªæœ‰shared_resultsï¼‰
            total_results = len(results.shared_results)
            
            # æ ¼å¼åŒ–è¿”å›
            formatted_results = {
                "query": query,
                "results": [
                    {
                        "content": r.content,
                        "score": round(r.score, 4),
                        "metadata": {
                            "doc_id": r.metadata.get("doc_id", ""),
                            "title": r.metadata.get("title", ""),
                            "source": r.metadata.get("source", ""),
                            "authors": r.metadata.get("authors", ""),
                            "journal": r.metadata.get("journal", ""),
                            "date": r.metadata.get("date", ""),
                            "doi": r.metadata.get("doi", "")
                        }
                    }
                    for r in results.shared_results
                ],
                "total_results": total_results,
                "retrieval_time_ms": round(results.retrieval_time_ms, 2)
            }
            
            return self.format_success(
                data=formatted_results,
                metadata={
                    "agent_role": agent_role,
                    "top_k": top_k
                }
            )
        
        except Exception as e:
            return self.format_error(
                error=f"RAGæ£€ç´¢å¤±è´¥: {str(e)}",
                metadata={"query": query, "agent_role": agent_role}
            )


# ==================== å·¥å…·2ï¼šæ–‡ä»¶è¯»å†™å·¥å…· ====================

import json
from pathlib import Path


class FileReadInput(BioAgentToolInput):
    """æ–‡ä»¶è¯»å–å·¥å…·è¾“å…¥"""
    file_path: str = Field(description="è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼‰")
    encoding: str = Field(default="utf-8", description="æ–‡ä»¶ç¼–ç ")


class FileReadTool(BioAgentTool):
    """æ–‡ä»¶è¯»å–å·¥å…· - è¯»å–æ–‡æœ¬æ–‡ä»¶æˆ–JSONæ–‡ä»¶"""
    
    name: str = "read_file"
    description: str = """
    è¯»å–æ–‡ä»¶å†…å®¹ã€‚æ”¯æŒæ–‡æœ¬æ–‡ä»¶ï¼ˆ.txt, .mdç­‰ï¼‰å’ŒJSONæ–‡ä»¶ï¼ˆ.jsonï¼‰ã€‚
    è¿”å›æ–‡ä»¶å†…å®¹ï¼Œå¦‚æœæ˜¯JSONæ–‡ä»¶åˆ™è‡ªåŠ¨è§£æä¸ºå­—å…¸ã€‚
    """
    args_schema: type[BaseModel] = FileReadInput
    
    async def _arun(
        self,
        file_path: str,
        encoding: str = "utf-8"
    ) -> ToolResult:
        """è¯»å–æ–‡ä»¶"""
        try:
            path = Path(file_path)
            project_root = Path(__file__).parent.parent  # Agents/state.py -> RE-Agent/
            
            # é¦–å…ˆå°è¯•ä» task_description.json è¯»å–æ•°æ®é›†è·¯å¾„
            task_desc_path = project_root / "task" / "task_description.json"
            dataset_path_from_json = None
            if task_desc_path.exists():
                try:
                    with open(task_desc_path, 'r', encoding='utf-8') as f:
                        task_desc = json.load(f)
                    dataset_path_from_json = task_desc.get("task_dataset", {}).get("file_path", "")
                    if dataset_path_from_json:
                        # å¤„ç†ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„
                        if Path(dataset_path_from_json).is_absolute():
                            dataset_full_path = Path(dataset_path_from_json)
                        else:
                            dataset_full_path = project_root / dataset_path_from_json
                        
                        # å¦‚æœæŒ‡å®šçš„æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼Œä½†æ•°æ®é›†è·¯å¾„å­˜åœ¨ï¼Œè‡ªåŠ¨ä½¿ç”¨æ•°æ®é›†è·¯å¾„
                        if (not path.exists() or not path.is_file()) and dataset_full_path.exists() and dataset_full_path.is_file():
                            print(f"  â„¹ï¸ æ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä½¿ç”¨ä»»åŠ¡æè¿°æ–‡ä»¶ä¸­çš„æ•°æ®é›†è·¯å¾„: {dataset_path_from_json}", flush=True)
                            path = dataset_full_path
                except Exception as e:
                    # å¦‚æœè¯»å– task_description.json å¤±è´¥ï¼Œç»§ç»­åŸæœ‰é€»è¾‘
                    pass
            
            # å¦‚æœæ–‡ä»¶ä»ç„¶ä¸å­˜åœ¨ï¼Œå°è¯•æ™ºèƒ½æŸ¥æ‰¾
            if not path.exists() or not path.is_file():
                # å¦‚æœè·¯å¾„æ˜¯ç›¸å¯¹è·¯å¾„ï¼ˆä¸åŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼‰ï¼Œå°è¯•åœ¨é¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾
                if not any(sep in file_path for sep in ['/', '\\']):
                    # å°è¯•ç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•
                    candidate = project_root / file_path
                    if candidate.exists() and candidate.is_file():
                        path = candidate
                    else:
                        # å°è¯•åœ¨ task/data/ ç›®å½•ä¸‹é€’å½’æŸ¥æ‰¾
                        task_data_dir = project_root / "task" / "data"
                        if task_data_dir.exists():
                            found_files = list(task_data_dir.rglob(file_path))
                            if found_files:
                                path = found_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
                            else:
                                error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}ã€‚å·²å°è¯•åœ¨é¡¹ç›®æ ¹ç›®å½•å’Œ task/data/ ç›®å½•ä¸‹æŸ¥æ‰¾ï¼Œæœªæ‰¾åˆ°ã€‚"
                                if dataset_path_from_json:
                                    error_msg += f" æç¤ºï¼šä»»åŠ¡æè¿°æ–‡ä»¶ä¸­æŒ‡å®šçš„æ•°æ®é›†è·¯å¾„ä¸º: {dataset_path_from_json}"
                                else:
                                    error_msg += " æç¤ºï¼šè¯·å…ˆä½¿ç”¨ read_file è¯»å– task/task_description.json è·å–æ­£ç¡®çš„æ•°æ®é›†æ–‡ä»¶è·¯å¾„ã€‚"
                                
                                return self.format_error(
                                    error=error_msg,
                                    metadata={"file_path": file_path, "searched_locations": [str(project_root), str(task_data_dir)]}
                                )
                else:
                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ä½†åŒ…å«åˆ†éš”ç¬¦ï¼Œå°è¯•ä»é¡¹ç›®æ ¹ç›®å½•è§£æ
                    if not path.is_absolute():
                        candidate = project_root / file_path
                        if candidate.exists() and candidate.is_file():
                            path = candidate
                        else:
                            return self.format_error(
                                error=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}",
                                metadata={"file_path": file_path, "tried_path": str(candidate)}
                            )
                    else:
                        return self.format_error(
                            error=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}",
                            metadata={"file_path": file_path}
                        )
            
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            if not path.is_file():
                return self.format_error(
                    error=f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {file_path}",
                    metadata={"file_path": file_path, "resolved_path": str(path)}
                )
            
            # è¯»å–æ–‡ä»¶ï¼ˆåªè¯»å–å‰å‡ è¡Œå’Œç»Ÿè®¡ä¿¡æ¯ï¼Œé¿å…è¿‡å¤§ï¼‰
            MAX_PREVIEW_LINES = 10  # æœ€å¤šæ˜¾ç¤ºå‰10è¡Œ
            
            with open(path, 'r', encoding=encoding) as f:
                # å…ˆè¯»å–æ‰€æœ‰è¡Œä»¥è·å–ç»Ÿè®¡ä¿¡æ¯
                all_lines = f.readlines()
                total_lines = len(all_lines)
                total_size = sum(len(line.encode(encoding)) for line in all_lines)
                
                # åªä¿ç•™å‰å‡ è¡Œä½œä¸ºé¢„è§ˆ
                preview_lines = all_lines[:MAX_PREVIEW_LINES]
                preview_content = ''.join(preview_lines)
            
            # å¦‚æœæ˜¯JSONæ–‡ä»¶ï¼Œå°è¯•è§£æ
            if path.suffix.lower() == '.json':
                try:
                    # å¯¹äºJSONæ–‡ä»¶ï¼Œå°è¯•è§£æå®Œæ•´å†…å®¹ä»¥è·å–ç»“æ„ä¿¡æ¯
                    full_content = ''.join(all_lines)
                    data = json.loads(full_content)
                    
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œåªè¿”å›é”®å’Œéƒ¨åˆ†å€¼é¢„è§ˆ
                    if isinstance(data, dict):
                        # åªè¿”å›å‰å‡ ä¸ªé”®å€¼å¯¹ä½œä¸ºé¢„è§ˆ
                        preview_data = dict(list(data.items())[:5])
                        if len(data) > 5:
                            preview_data["_note"] = f"... (and {len(data) - 5} more keys, total: {len(data)} keys)"
                    elif isinstance(data, list):
                        # åªè¿”å›å‰å‡ ä¸ªå…ƒç´ ä½œä¸ºé¢„è§ˆ
                        preview_data = data[:5]
                        if len(data) > 5:
                            preview_data.append(f"... (and {len(data) - 5} more items, total: {len(data)} items)")
                    else:
                        preview_data = data
                    
                    return self.format_success(
                        data={
                            "file_path": str(path),
                            "file_type": "json",
                            "content": preview_data,
                            "preview_only": True,
                            "total_keys" if isinstance(data, dict) else "total_items": len(data) if isinstance(data, (dict, list)) else 1,
                            "size_bytes": total_size,
                            "line_count": total_lines
                        },
                        metadata={"encoding": encoding}
                    )
                except json.JSONDecodeError as e:
                    return self.format_error(
                        error=f"JSONè§£æå¤±è´¥: {str(e)}",
                        metadata={"file_path": file_path}
                    )
            
            # åˆ¤æ–­æ–‡ä»¶ç±»å‹
            file_type = "csv" if path.suffix.lower() == '.csv' else "text"
            
            # æ„å»ºé¢„è§ˆå†…å®¹è¯´æ˜
            preview_note = ""
            if total_lines > MAX_PREVIEW_LINES:
                preview_note = f"\n\n[Note: Showing first {MAX_PREVIEW_LINES} lines only. Total lines: {total_lines}]"
            
            return self.format_success(
                data={
                    "file_path": str(path),
                    "file_type": file_type,
                    "content": preview_content + preview_note,  # åªè¿”å›å‰å‡ è¡Œé¢„è§ˆ
                    "preview_only": True,
                    "total_lines": total_lines,
                    "size_bytes": total_size,
                    "line_count": total_lines
                    },
                    metadata={"encoding": encoding}
                )
        
        except Exception as e:
            return self.format_error(
                error=f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}",
                metadata={"file_path": file_path}
            )


class FileWriteInput(BioAgentToolInput):
    """æ–‡ä»¶å†™å…¥å·¥å…·è¾“å…¥"""
    file_path: str = Field(description="è¦å†™å…¥çš„æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼‰")
    content: str = Field(description="è¦å†™å…¥çš„å†…å®¹ï¼ˆæ–‡æœ¬æˆ–JSONå­—ç¬¦ä¸²ï¼‰")
    encoding: str = Field(default="utf-8", description="æ–‡ä»¶ç¼–ç ")
    create_dirs: bool = Field(default=True, description="å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œæ˜¯å¦åˆ›å»º")


class FileWriteTool(BioAgentTool):
    """æ–‡ä»¶å†™å…¥å·¥å…· - å†™å…¥æ–‡æœ¬æ–‡ä»¶æˆ–JSONæ–‡ä»¶"""
    
    name: str = "write_file"
    description: str = """
    å†™å…¥æ–‡ä»¶å†…å®¹ã€‚æ”¯æŒæ–‡æœ¬æ–‡ä»¶å’ŒJSONæ–‡ä»¶ã€‚
    å¦‚æœcontentæ˜¯JSONå­—ç¬¦ä¸²ï¼Œä¼šè‡ªåŠ¨æ ¼å¼åŒ–ä¿å­˜ã€‚
    å¦‚æœç›®å½•ä¸å­˜åœ¨ä¸”create_dirs=Trueï¼Œä¼šè‡ªåŠ¨åˆ›å»ºç›®å½•ã€‚
    """
    args_schema: type[BaseModel] = FileWriteInput
    
    async def _arun(
        self,
        file_path: str,
        content: str,
        encoding: str = "utf-8",
        create_dirs: bool = True
    ) -> ToolResult:
        """å†™å…¥æ–‡ä»¶"""
        try:
            path = Path(file_path)
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if create_dirs:
                path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¦‚æœæ˜¯JSONæ–‡ä»¶ï¼Œå°è¯•æ ¼å¼åŒ–
            if path.suffix.lower() == '.json':
                try:
                    # å°è¯•è§£æJSONä»¥éªŒè¯æ ¼å¼
                    data = json.loads(content)
                    # æ ¼å¼åŒ–å†™å…¥
                    with open(path, 'w', encoding=encoding) as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                except json.JSONDecodeError as e:
                    return self.format_error(
                        error=f"JSONæ ¼å¼æ— æ•ˆ: {str(e)}",
                        metadata={"file_path": file_path}
                    )
            else:
                # æ™®é€šæ–‡æœ¬æ–‡ä»¶
                with open(path, 'w', encoding=encoding) as f:
                    f.write(content)
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_size = path.stat().st_size
            
            return self.format_success(
                data={
                    "file_path": str(path),
                    "file_size_bytes": file_size,
                    "message": "æ–‡ä»¶å†™å…¥æˆåŠŸ"
                },
                metadata={"encoding": encoding, "create_dirs": create_dirs}
            )
        
        except Exception as e:
            return self.format_error(
                error=f"å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}",
                metadata={"file_path": file_path}
            )


# ==================== å·¥å…·æ³¨å†Œè¡¨ ====================

class ToolRegistry:
    """å·¥å…·æ³¨å†Œè¡¨ - ç®¡ç†æ‰€æœ‰å¯ç”¨å·¥å…·"""
    
    def __init__(self):
        self.tools: Dict[str, BioAgentTool] = {}
        self._register_default_tools()
    
    def _register_default_tools(self):
        """æ³¨å†Œé»˜è®¤å·¥å…·"""
        # RAGæ£€ç´¢å·¥å…·
        try:
            self.register_tool("rag_search", RAGSearchTool())
        except Exception as e:
            print(f"âš ï¸ æ³¨å†ŒRAGå·¥å…·å¤±è´¥: {e}")
        
        # æ–‡ä»¶è¯»å–å·¥å…·
        try:
            self.register_tool("read_file", FileReadTool())
        except Exception as e:
            print(f"âš ï¸ æ³¨å†Œæ–‡ä»¶è¯»å–å·¥å…·å¤±è´¥: {e}")
        
        # æ–‡ä»¶å†™å…¥å·¥å…·
        try:
            self.register_tool("write_file", FileWriteTool())
        except Exception as e:
            print(f"âš ï¸ æ³¨å†Œæ–‡ä»¶å†™å…¥å·¥å…·å¤±è´¥: {e}")
    
    def register_tool(self, name: str, tool: BioAgentTool):
        """æ³¨å†Œå·¥å…·"""
        self.tools[name] = tool
    
    def get_tool(self, name: str) -> Optional[BioAgentTool]:
        """è·å–å·¥å…·"""
        return self.tools.get(name)
    
    def get_all_tools(self) -> List[BioAgentTool]:
        """è·å–æ‰€æœ‰å·¥å…·åˆ—è¡¨ï¼ˆç”¨äºLangChainï¼‰"""
        return list(self.tools.values())


# å…¨å±€å·¥å…·æ³¨å†Œè¡¨å®ä¾‹
_tool_registry: Optional[ToolRegistry] = None


def get_tool_registry() -> ToolRegistry:
    """è·å–å·¥å…·æ³¨å†Œè¡¨å•ä¾‹"""
    global _tool_registry
    if _tool_registry is None:
        _tool_registry = ToolRegistry()
    return _tool_registry


# ==================== å¯¼å‡º ====================

__all__ = [
    "AgentRole",
    "REAgentState",
    "CritiqueResult",
    "OptimizationReport",
    "BioAgentTool",
    "BioAgentToolInput",
    "ToolResult",
    "RAGSearchTool",
    "RAGSearchInput",
    "FileReadTool",
    "FileReadInput",
    "FileWriteTool",
    "FileWriteInput",
    "ToolRegistry",
    "get_tool_registry"
]
