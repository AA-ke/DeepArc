"""
coding_multi.py
åˆ†æ®µå¤šè½®ä»£ç ç”Ÿæˆ - ä¸¥æ ¼æŒ‰ç…§å®éªŒæŠ¥å‘Šç”Ÿæˆç”Ÿäº§çº§ä»£ç 
"""

import asyncio
import json
import re
from pathlib import Path
from langchain_core.messages import SystemMessage, HumanMessage

from Agents.prompt import get_agent_by_role
from config.settings import get_settings


async def generate_code_from_report(report_path: str | None = None, output_dir: str = "code_generated_multi"):
    """
    æ ¹æ®å®éªŒæ–¹æ¡ˆæŠ¥å‘Šåˆ†æ®µç”Ÿæˆå®Œæ•´ä»£ç 
    
    Args:
        report_path: å®éªŒæ–¹æ¡ˆæŠ¥å‘ŠJSONæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨ outputs/final_report.jsonï¼‰
        output_dir: è¾“å‡ºç›®å½•
    """
    print("="*80)
    print("ğŸš€ Multi-Stage Code Generator - åˆ†æ®µä»£ç ç”Ÿæˆ")
    print("="*80)
    
    # 1. è¯»å–æŠ¥å‘Šæ–‡ä»¶ï¼ˆé»˜è®¤ä½¿ç”¨ outputs/final_report.jsonï¼‰
    if report_path is None:
        report_path = "outputs/final_report.json"
    
    print(f"\nğŸ“– è¯»å–å®éªŒæ–¹æ¡ˆæŠ¥å‘Š: {report_path}")
    report_path_obj = Path(report_path)
    if not report_path_obj.exists():
        raise FileNotFoundError(f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_path}")
    
    with open(report_path_obj, "r", encoding="utf-8") as f:
        full_report = json.load(f)
    
    # åªæå– expert_analyses ä¹‹å‰çš„å†…å®¹
    report = {}
    for key in ["title", "summary", "priority_recommendations", "task_information", "experimental_design"]:
        if key in full_report:
            report[key] = full_report[key]
    
    print("âœ“ æŠ¥å‘Šæ–‡ä»¶è¯»å–æˆåŠŸï¼ˆä»…ä½¿ç”¨ expert_analyses ä¹‹å‰çš„å†…å®¹ï¼‰")
    
    # 2. æå–ä»»åŠ¡ä¿¡æ¯å’Œå®éªŒæ–¹æ¡ˆ
    task_info = report.get("task_information", {})
    exp_design = report.get("experimental_design", {})
    priority_recs = report.get("priority_recommendations", [])
    
    task_description = task_info.get("description", "")
    background = task_info.get("background", "")
    dataset_info = task_info.get("dataset_info", "")
    
    # 3. åˆå§‹åŒ– Code Generator Agent
    print("\nğŸ”§ åˆå§‹åŒ– Code Generator Agent...")
    code_agent = get_agent_by_role("code_generator")
    print("âœ“ Code Generator Agent åˆå§‹åŒ–å®Œæˆ")
    
    # 4. å‡†å¤‡è¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # å­˜å‚¨å·²ç”Ÿæˆçš„ä»£ç ç‰‡æ®µ
    generated_code_parts = {}
    
    # ==================== ç¬¬ä¸€æ­¥ï¼šé¡¹ç›®ç»“æ„ä¸é…ç½® ====================
    print("\n" + "="*80)
    print("ğŸ“¦ Stage 1: Project Structure & Configuration")
    print("="*80)
    
    stage1_prompt = f"""You are generating PRODUCTION-GRADE code for a bioinformatics deep learning project. This is NOT a tutorial or demonstration - this is production code that will be used in real research.

âš ï¸ CRITICAL REQUIREMENTS:
- Generate PRODUCTION-GRADE code with ROBUST ERROR HANDLING
- STRICTLY FOLLOW the report specifications - DO NOT SIMPLIFY
- DO NOT SIMPLIFY any implementation details
- Include comprehensive error handling, logging, and validation
- All code must be production-ready and maintainable
- **MAKE DECISIVE CHOICES**: If the report provides multiple options or vague suggestions, you MUST make a clear decision and choose what you believe is the BEST solution. DO NOT leave choices ambiguous or use placeholder values. DO NOT be lazy - make specific, well-reasoned choices based on the context and best practices.

## Task Description
**Title**: {task_description}

**Background**: {background}

**Dataset Information**: {dataset_info}

## Experimental Design Report

### Data Usage Plan
{json.dumps(exp_design.get("1_data_usage_plan", {}), ensure_ascii=False, indent=2)}

### Method Design
{json.dumps(exp_design.get("2_method_design", {}), ensure_ascii=False, indent=2)}

### Model Design
{json.dumps(exp_design.get("3_model_design", {}), ensure_ascii=False, indent=2)}

### Result Summary
{json.dumps(exp_design.get("4_result_summary", {}), ensure_ascii=False, indent=2)}

## Priority Recommendations
{chr(10).join(f"- {rec}" for rec in priority_recs)}

## Stage 1 Task: Project Structure & Configuration

Generate ONLY the following files for Stage 1:

1. **config.py**: Complete configuration file with ALL hyperparameters from the experimental design
   - STRICTLY FOLLOW all parameter values specified in the report
   - Include ALL hyperparameters: learning rates, batch sizes, optimizer settings, regularization parameters, etc.
   - Add ROBUST ERROR HANDLING for configuration validation
   - Include type hints and comprehensive documentation
   - DO NOT SIMPLIFY - include all configuration details from the report

2. **requirements.txt**: Complete dependency list with version specifications
   - Include all necessary packages: PyTorch, NumPy, Pandas, scikit-learn, etc.
   - Specify version constraints based on compatibility requirements

3. **PROJECT_STRUCTURE.md**: Detailed project structure documentation
   - Explain the overall architecture
   - Document the purpose of each module
   - Include usage guidelines

4. **README.md**: Comprehensive project documentation
   - Project overview and purpose
   - Installation instructions
   - Usage guidelines
   - Configuration explanation

âš ï¸ REMEMBER:
- This is PRODUCTION-GRADE code, NOT a tutorial
- STRICTLY FOLLOW the report specifications - DO NOT SIMPLIFY
- Include ROBUST ERROR HANDLING throughout
- All code must be production-ready

Output format: Provide a STRICT, VALID JSON object with the following structure:

âš ï¸ CRITICAL JSON FORMAT REQUIREMENTS:
- You MUST return valid, parseable JSON that strictly conforms to JSON specification
- ALL string values (especially in the "code" field) MUST have control characters properly escaped:
  * Newlines: use \\n (not actual newline characters)
  * Tabs: use \\t (not actual tab characters)
  * Carriage returns: use \\r (not actual \\r characters)
  * Other control characters: use \\uXXXX Unicode escape sequences
- DO NOT include unescaped control characters in string values - they will cause JSON parsing to fail
- The "code" field contains Python code as a STRING - escape all special characters properly
- Use double quotes for all strings (not single quotes)
- Ensure all brackets, braces, and quotes are properly matched and escaped

Example of properly escaped code string:
"code": "def hello():\\n    print(\\\"Hello\\\")\\n    return True"

```json
{{
    "files": [
        {{
            "path": "config.py",
            "code": "...complete production code with ALL control characters properly escaped..."
        }},
        {{
            "path": "requirements.txt",
            "code": "..."
        }},
        {{
            "path": "PROJECT_STRUCTURE.md",
            "code": "..."
        }},
        {{
            "path": "README.md",
            "code": "..."
        }}
    ],
    "stage": 1,
    "description": "Brief description of what was generated"
}}
```

IMPORTANT: The JSON you return MUST be parseable by standard JSON parsers. Test your output mentally - if the "code" field contains Python code with newlines, they MUST be escaped as \\n, not actual newline characters.
"""
    
    stage1_code = await _generate_stage_code(code_agent, stage1_prompt, "Stage 1")
    generated_code_parts[1] = stage1_code
    
    # ä¿å­˜ Stage 1 ä»£ç 
    await _save_stage_files(output_path, stage1_code, 1)
    
    # ==================== ç¬¬äºŒæ­¥ï¼šæ•°æ®ç®¡é“ ====================
    print("\n" + "="*80)
    print("ğŸ“Š Stage 2: Data Pipeline")
    print("="*80)
    
    stage2_prompt = f"""You are generating PRODUCTION-GRADE code for a bioinformatics deep learning project. This is NOT a tutorial - this is production code.

âš ï¸ CRITICAL REQUIREMENTS:
- Generate PRODUCTION-GRADE code with ROBUST ERROR HANDLING
- STRICTLY FOLLOW the report specifications - DO NOT SIMPLIFY
- DO NOT SIMPLIFY any data preprocessing steps
- Include comprehensive error handling, data validation, and logging
- **MAKE DECISIVE CHOICES**: If the report provides multiple options or vague suggestions, you MUST make a clear decision and choose what you believe is the BEST solution. DO NOT leave choices ambiguous or use placeholder values. DO NOT be lazy - make specific, well-reasoned choices based on the context and best practices.

## Task Description
**Title**: {task_description}

**Background**: {background}

**Dataset Information**: {dataset_info}

## Experimental Design Report

### Data Usage Plan (CRITICAL - STRICTLY FOLLOW THIS)
{json.dumps(exp_design.get("1_data_usage_plan", {}), ensure_ascii=False, indent=2)}

### Method Design (for data augmentation details)
{json.dumps(exp_design.get("2_method_design", {}), ensure_ascii=False, indent=2)}

## Priority Recommendations
{chr(10).join(f"- {rec}" for rec in priority_recs)}

## Stage 2 Task: Data Pipeline

Generate ONLY the data pipeline code for Stage 2:

1. **dataset.py**: Complete data loading and preprocessing module
   - STRICTLY FOLLOW all data preprocessing specifications from the Data Usage Plan
   - Implement ALL preprocessing steps exactly as specified in the report
   - Include ROBUST ERROR HANDLING for data validation
   - Implement data loading, preprocessing, augmentation, and splitting
   - DO NOT SIMPLIFY - implement all data transformations exactly as specified
   - Include comprehensive logging and error handling
   - Add data quality checks and validation

2. **utils.py** (data-related utilities): Utility functions for data processing
   - One-hot encoding functions (if specified)
   - Data normalization functions
   - Data augmentation functions (if specified)
   - Data validation utilities
   - All utility functions with ROBUST ERROR HANDLING

âš ï¸ REMEMBER:
- This is PRODUCTION-GRADE code - STRICTLY FOLLOW the report specifications
- DO NOT SIMPLIFY any preprocessing steps
- Include ROBUST ERROR HANDLING for all data operations
- All data transformations must match the report exactly

Output format: Provide a STRICT, VALID JSON object:

âš ï¸ CRITICAL JSON FORMAT REQUIREMENTS:
- You MUST return valid, parseable JSON that strictly conforms to JSON specification
- ALL string values (especially in the "code" field) MUST have control characters properly escaped:
  * Newlines: use \\n (not actual newline characters)
  * Tabs: use \\t (not actual tab characters)
  * Carriage returns: use \\r (not actual \\r characters)
  * Other control characters: use \\uXXXX Unicode escape sequences
- DO NOT include unescaped control characters in string values - they will cause JSON parsing to fail
- The "code" field contains Python code as a STRING - escape all special characters properly
- Use double quotes for all strings (not single quotes)
- Ensure all brackets, braces, and quotes are properly matched and escaped

```json
{{
    "files": [
        {{
            "path": "dataset.py",
            "code": "...complete production code with ALL control characters properly escaped..."
        }},
        {{
            "path": "utils.py",
            "code": "...complete production code with ALL control characters properly escaped..."
        }}
    ],
    "stage": 2,
    "description": "Brief description"
}}
```

IMPORTANT: The JSON you return MUST be parseable by standard JSON parsers. All control characters in code strings MUST be escaped.
"""
    
    stage2_code = await _generate_stage_code(code_agent, stage2_prompt, "Stage 2")
    generated_code_parts[2] = stage2_code
    
    # ä¿å­˜ Stage 2 ä»£ç 
    await _save_stage_files(output_path, stage2_code, 2)
    
    # ==================== ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹æ¶æ„ ====================
    print("\n" + "="*80)
    print("ğŸ—ï¸ Stage 3: Model Architecture")
    print("="*80)
    
    stage3_prompt = f"""You are generating PRODUCTION-GRADE code for a bioinformatics deep learning project. This is NOT a tutorial - this is production code.

âš ï¸ CRITICAL REQUIREMENTS:
- Generate PRODUCTION-GRADE code with ROBUST ERROR HANDLING
- STRICTLY FOLLOW the report specifications - DO NOT SIMPLIFY
- DO NOT SIMPLIFY any model architecture details
- Implement EXACT layer dimensions, kernel sizes, activation functions as specified
- **MAKE DECISIVE CHOICES**: If the report provides multiple options or vague suggestions, you MUST make a clear decision and choose what you believe is the BEST solution. DO NOT leave choices ambiguous or use placeholder values. DO NOT be lazy - make specific, well-reasoned choices based on the context and best practices.

## Task Description
**Title**: {task_description}

**Background**: {background}

**Dataset Information**: {dataset_info}

## Experimental Design Report

### Model Design (CRITICAL - STRICTLY FOLLOW THIS)
{json.dumps(exp_design.get("3_model_design", {}), ensure_ascii=False, indent=2)}

### Method Design (for regularization and optimization details)
{json.dumps(exp_design.get("2_method_design", {}), ensure_ascii=False, indent=2)}

## Priority Recommendations
{chr(10).join(f"- {rec}" for rec in priority_recs)}

## Stage 3 Task: Model Architecture

Generate ONLY the model architecture code for Stage 3:

1. **model.py**: Complete model architecture implementation
   - STRICTLY FOLLOW all architecture specifications from the Model Design section
   - Implement EXACT layer dimensions, kernel sizes, strides, padding as specified
   - Use EXACT activation functions, dropout rates, normalization layers as specified
   - Include ALL architectural components: attention mechanisms, residual connections, etc.
   - DO NOT SIMPLIFY - implement the architecture exactly as specified in the report
   - Include ROBUST ERROR HANDLING for model initialization and forward pass
   - Add comprehensive model validation and parameter checking
   - Include proper weight initialization as specified

âš ï¸ REMEMBER:
- This is PRODUCTION-GRADE code - STRICTLY FOLLOW the report specifications
- DO NOT SIMPLIFY any architecture details
- All layer dimensions and hyperparameters must match the report EXACTLY
- Include ROBUST ERROR HANDLING throughout

Output format: Provide a STRICT, VALID JSON object:

âš ï¸ CRITICAL JSON FORMAT REQUIREMENTS:
- You MUST return valid, parseable JSON that strictly conforms to JSON specification
- ALL string values (especially in the "code" field) MUST have control characters properly escaped:
  * Newlines: use \\n (not actual newline characters)
  * Tabs: use \\t (not actual tab characters)
  * Carriage returns: use \\r (not actual \\r characters)
  * Other control characters: use \\uXXXX Unicode escape sequences
- DO NOT include unescaped control characters in string values - they will cause JSON parsing to fail
- The "code" field contains Python code as a STRING - escape all special characters properly
- Use double quotes for all strings (not single quotes)
- Ensure all brackets, braces, and quotes are properly matched and escaped

```json
{{
    "files": [
        {{
            "path": "model.py",
            "code": "...complete production code with ALL control characters properly escaped..."
        }}
    ],
    "stage": 3,
    "description": "Brief description"
}}
```

IMPORTANT: The JSON you return MUST be parseable by standard JSON parsers. All control characters in code strings MUST be escaped.
"""
    
    stage3_code = await _generate_stage_code(code_agent, stage3_prompt, "Stage 3")
    generated_code_parts[3] = stage3_code
    
    # ä¿å­˜ Stage 3 ä»£ç 
    await _save_stage_files(output_path, stage3_code, 3)
    
    # ==================== ç¬¬å››æ­¥ï¼šè®­ç»ƒå¾ªç¯ ====================
    print("\n" + "="*80)
    print("ğŸ”„ Stage 4: Training Loop")
    print("="*80)
    
    stage4_prompt = f"""You are generating PRODUCTION-GRADE code for a bioinformatics deep learning project. This is NOT a tutorial - this is production code.

âš ï¸ CRITICAL REQUIREMENTS:
- Generate PRODUCTION-GRADE code with ROBUST ERROR HANDLING
- STRICTLY FOLLOW the report specifications - DO NOT SIMPLIFY
- DO NOT SIMPLIFY any training logic
- Implement EXACT loss functions, optimizers, schedulers as specified
- **MAKE DECISIVE CHOICES**: If the report provides multiple options or vague suggestions, you MUST make a clear decision and choose what you believe is the BEST solution. DO NOT leave choices ambiguous or use placeholder values. DO NOT be lazy - make specific, well-reasoned choices based on the context and best practices.

## Task Description
**Title**: {task_description}

**Background**: {background}

**Dataset Information**: {dataset_info}

## Experimental Design Report

### Method Design (CRITICAL - STRICTLY FOLLOW THIS)
{json.dumps(exp_design.get("2_method_design", {}), ensure_ascii=False, indent=2)}

### Model Design (for model-specific training details)
{json.dumps(exp_design.get("3_model_design", {}), ensure_ascii=False, indent=2)}

### Result Summary (for evaluation metrics)
{json.dumps(exp_design.get("4_result_summary", {}), ensure_ascii=False, indent=2)}

## Priority Recommendations
{chr(10).join(f"- {rec}" for rec in priority_recs)}

## Stage 4 Task: Training Loop

Generate ONLY the training code for Stage 4:

1. **train.py**: Complete training script
   - STRICTLY FOLLOW all training specifications from the Method Design section
   - Implement EXACT loss functions, optimizers, learning rate schedules as specified
   - Include ALL training features: early stopping, checkpointing, logging, etc.
   - DO NOT SIMPLIFY - implement all training logic exactly as specified
   - Include ROBUST ERROR HANDLING for training loop, data loading, model saving
   - Add comprehensive logging and progress tracking
   - Implement proper checkpoint management and resume functionality
   - Include gradient clipping, mixed precision training if specified

âš ï¸ REMEMBER:
- This is PRODUCTION-GRADE code - STRICTLY FOLLOW the report specifications
- DO NOT SIMPLIFY any training logic
- All hyperparameters and training procedures must match the report EXACTLY
- Include ROBUST ERROR HANDLING throughout

Output format: Provide a STRICT, VALID JSON object:

âš ï¸ CRITICAL JSON FORMAT REQUIREMENTS:
- You MUST return valid, parseable JSON that strictly conforms to JSON specification
- ALL string values (especially in the "code" field) MUST have control characters properly escaped:
  * Newlines: use \\n (not actual newline characters)
  * Tabs: use \\t (not actual tab characters)
  * Carriage returns: use \\r (not actual \\r characters)
  * Other control characters: use \\uXXXX Unicode escape sequences
- DO NOT include unescaped control characters in string values - they will cause JSON parsing to fail
- The "code" field contains Python code as a STRING - escape all special characters properly
- Use double quotes for all strings (not single quotes)
- Ensure all brackets, braces, and quotes are properly matched and escaped

```json
{{
    "files": [
        {{
            "path": "train.py",
            "code": "...complete production code with ALL control characters properly escaped..."
        }}
    ],
    "stage": 4,
    "description": "Brief description"
}}
```

IMPORTANT: The JSON you return MUST be parseable by standard JSON parsers. All control characters in code strings MUST be escaped.
"""
    
    stage4_code = await _generate_stage_code(code_agent, stage4_prompt, "Stage 4")
    generated_code_parts[4] = stage4_code
    
    # ä¿å­˜ Stage 4 ä»£ç 
    await _save_stage_files(output_path, stage4_code, 4)
    
    # ==================== ç¬¬äº”æ­¥ï¼šè¡¥å……ä»£ç å¹¶æ£€æŸ¥æ¥å£ ====================
    print("\n" + "="*80)
    print("ğŸ” Stage 5: Additional Code & Interface Validation")
    print("="*80)
    
    # è¯»å–å·²ç”Ÿæˆçš„æ‰€æœ‰ä»£ç æ–‡ä»¶ï¼ˆè¯»å–æ›´å¤šå†…å®¹ä»¥ä¾¿å…¨é¢å®¡æ ¸ï¼Œä½†é™åˆ¶æ€»é•¿åº¦ï¼‰
    existing_files = {}
    MAX_FILE_PREVIEW = 3000  # æ¯ä¸ªæ–‡ä»¶æœ€å¤šé¢„è§ˆ 3000 å­—ç¬¦ï¼Œå¹³è¡¡å®¡æ ¸éœ€æ±‚å’Œ token é™åˆ¶
    TOTAL_PREVIEW_LIMIT = 15000  # æ‰€æœ‰æ–‡ä»¶é¢„è§ˆæ€»é•¿åº¦é™åˆ¶
    total_preview_chars = 0
    
    for stage_num in [1, 2, 3, 4]:
        stage_dir = output_path / f"stage_{stage_num}"
        if stage_dir.exists():
            for file_path in sorted(stage_dir.glob("*.py")):  # æ’åºä»¥ä¿è¯ä¸€è‡´æ€§
                if total_preview_chars >= TOTAL_PREVIEW_LIMIT:
                    print(f"   âš ï¸ è¾¾åˆ°æ€»é¢„è§ˆé•¿åº¦é™åˆ¶ ({TOTAL_PREVIEW_LIMIT} å­—ç¬¦)ï¼Œè·³è¿‡å‰©ä½™æ–‡ä»¶")
                    break
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        full_content = f.read()
                        # è®¡ç®—å¯ç”¨çš„é¢„è§ˆé•¿åº¦
                        remaining_limit = TOTAL_PREVIEW_LIMIT - total_preview_chars
                        preview_length = min(MAX_FILE_PREVIEW, len(full_content), remaining_limit)
                        
                        if len(full_content) > preview_length:
                            # ä¼˜å…ˆæ˜¾ç¤ºæ–‡ä»¶å¼€å¤´ï¼ˆåŒ…å«å¯¼å…¥å’Œä¸»è¦å‡½æ•°å®šä¹‰ï¼‰
                            preview_content = full_content[:preview_length]
                            existing_files[file_path.name] = preview_content + f"\n\n[... File truncated, total length: {len(full_content)} characters. Focus on function signatures, imports, class definitions, and key logic from the beginning ...]"
                        else:
                            existing_files[file_path.name] = full_content
                        
                        total_preview_chars += len(existing_files[file_path.name])
                except Exception as e:
                    print(f"   âš ï¸ Failed to read {file_path.name}: {e}")
    
    stage5_prompt = f"""You are generating PRODUCTION-GRADE code for a bioinformatics deep learning project. This is NOT a tutorial - this is production code.

âš ï¸ CRITICAL REQUIREMENTS:
- Generate PRODUCTION-GRADE code with ROBUST ERROR HANDLING
- STRICTLY FOLLOW the report specifications - DO NOT SIMPLIFY
- DO NOT SIMPLIFY any implementation
- Check and fix ALL interface compatibility issues
- **MAKE DECISIVE CHOICES**: If the report provides multiple options or vague suggestions, you MUST make a clear decision and choose what you believe is the BEST solution. DO NOT leave choices ambiguous or use placeholder values. DO NOT be lazy - make specific, well-reasoned choices based on the context and best practices.
- **COMPREHENSIVE FILE REVIEW**: You MUST thoroughly read, understand, and analyze ALL existing code files before generating new code or making fixes. Avoid ALL conflicts, inconsistencies, and interface mismatches.

## Task Description
**Title**: {task_description}

**Background**: {background}

**Dataset Information**: {dataset_info}

## Experimental Design Report

### Result Summary (CRITICAL - STRICTLY FOLLOW THIS)
{json.dumps(exp_design.get("4_result_summary", {}), ensure_ascii=False, indent=2)}

### Method Design (for evaluation details)
{json.dumps(exp_design.get("2_method_design", {}), ensure_ascii=False, indent=2)}

## Priority Recommendations
{chr(10).join(f"- {rec}" for rec in priority_recs)}

## Existing Generated Code

âš ï¸ **CRITICAL: You MUST thoroughly read, understand, and analyze ALL of the following files before proceeding.**

The following files have already been generated in previous stages. You MUST:
1. Read and understand the COMPLETE structure of each file
2. Identify ALL function signatures, imports, and dependencies
3. Map out the data flow between files
4. Identify ALL potential conflicts and inconsistencies
5. Ensure your new code and fixes are fully compatible with ALL existing code

{json.dumps({k: v for k, v in existing_files.items()}, ensure_ascii=False, indent=2)}

## Stage 5 Task: Additional Code & Interface Validation

**CRITICAL: You MUST thoroughly read and review ALL existing code files before generating new code or making fixes.**

Generate the remaining code and fix ALL interface issues:

1. **Comprehensive File Review (MANDATORY FIRST STEP)**:
   - **READ and UNDERSTAND** ALL existing code files completely (dataset.py, model.py, train.py, config.py, utils.py)
   - **ANALYZE** each file's structure, function signatures, imports, and dependencies
   - **IDENTIFY** all potential conflicts, inconsistencies, and interface mismatches
   - **MAP OUT** the data flow between files (dataset â†’ model â†’ train â†’ evaluate)
   - **VERIFY** all imports, function calls, and variable names are consistent across files
   - **CHECK** for naming conflicts, duplicate definitions, or missing dependencies
   - DO NOT proceed with code generation until you have fully understood ALL existing code

2. **evaluate.py**: Complete evaluation module
   - STRICTLY FOLLOW all evaluation specifications from the Result Summary section
   - Implement ALL evaluation metrics and statistical tests as specified
   - Include ROBUST ERROR HANDLING for evaluation
   - **ENSURE COMPLETE COMPATIBILITY**: The evaluate.py must work seamlessly with ALL existing files
   - Verify that evaluation inputs match train.py outputs exactly
   - Verify that evaluation can load models and datasets correctly
   - DO NOT SIMPLIFY - implement all evaluation logic exactly as specified

3. **Interface Fixes**: Review and fix ALL interface compatibility issues
   - **THOROUGHLY CHECK** that dataset.py output matches model.py input requirements (data shapes, types, formats)
   - **THOROUGHLY CHECK** that model.py output matches train.py requirements (forward pass output format, device handling)
   - **THOROUGHLY CHECK** that train.py output matches evaluate.py requirements (model checkpoints, predictions format)
   - **RESOLVE ALL CONFLICTS**: Fix ANY interface mismatches, naming conflicts, or inconsistencies in the existing code
   - **VERIFY CONSISTENCY**: Ensure all function signatures are compatible across files
   - **VALIDATE IMPORTS**: Check that all imports are correct and all dependencies are satisfied
   - **CHECK CONFIG USAGE**: Verify that config.py parameters are used consistently across all files
   - Add proper type hints and validation
   - Update any files that have conflicts or inconsistencies

4. **Additional Utilities**: Any remaining utility functions
   - Visualization functions
   - Additional helper functions
   - All with ROBUST ERROR HANDLING
   - **ENSURE NO CONFLICTS**: Verify that utility functions don't conflict with existing code

âš ï¸ REMEMBER:
- This is PRODUCTION-GRADE code - STRICTLY FOLLOW the report specifications
- DO NOT SIMPLIFY any implementation
- Check and fix ALL interface compatibility issues
- Include ROBUST ERROR HANDLING throughout

Output format: Provide a STRICT, VALID JSON object with updated files:

âš ï¸ CRITICAL JSON FORMAT REQUIREMENTS:
- You MUST return valid, parseable JSON that strictly conforms to JSON specification
- ALL string values (especially in the "code" field) MUST have control characters properly escaped:
  * Newlines: use \\n (not actual newline characters)
  * Tabs: use \\t (not actual tab characters)
  * Carriage returns: use \\r (not actual \\r characters)
  * Other control characters: use \\uXXXX Unicode escape sequences
- DO NOT include unescaped control characters in string values - they will cause JSON parsing to fail
- The "code" field contains Python code as a STRING - escape all special characters properly
- Use double quotes for all strings (not single quotes)
- Ensure all brackets, braces, and quotes are properly matched and escaped

```json
{{
    "files": [
        {{
            "path": "evaluate.py",
            "code": "...complete production code with ALL control characters properly escaped..."
        }},
        {{
            "path": "dataset.py",
            "code": "...updated code with interface fixes, ALL control characters properly escaped..."
        }},
        {{
            "path": "model.py",
            "code": "...updated code with interface fixes, ALL control characters properly escaped..."
        }},
        {{
            "path": "train.py",
            "code": "...updated code with interface fixes, ALL control characters properly escaped..."
        }}
    ],
    "stage": 5,
    "description": "Brief description of fixes and additions",
    "interface_fixes": ["List of interface issues fixed"]
}}
```

IMPORTANT: The JSON you return MUST be parseable by standard JSON parsers. All control characters in code strings MUST be escaped.
"""
    
    stage5_code = await _generate_stage_code(code_agent, stage5_prompt, "Stage 5")
    generated_code_parts[5] = stage5_code
    
    # ä¿å­˜ Stage 5 ä»£ç ï¼ˆåŒ…æ‹¬æ›´æ–°çš„æ–‡ä»¶ï¼‰
    await _save_stage_files(output_path, stage5_code, 5)
    
    # ==================== åˆå¹¶æ‰€æœ‰ä»£ç åˆ°æœ€ç»ˆç›®å½• ====================
    print("\n" + "="*80)
    print("ğŸ“¦ Merging All Stages")
    print("="*80)
    
    await _merge_all_stages(output_path, generated_code_parts)
    
    # ==================== åˆ é™¤å‰äº”è½®çš„åˆ†åˆ«æ–‡ä»¶å¤¹ ====================
    print("\n" + "="*80)
    print("ğŸ—‘ï¸ Cleaning Up Stage Directories")
    print("="*80)
    
    for stage_num in [1, 2, 3, 4, 5]:
        stage_dir = output_path / f"stage_{stage_num}"
        if stage_dir.exists():
            import shutil
            try:
                shutil.rmtree(stage_dir)
                print(f"   âœ“ Deleted: stage_{stage_num}/")
            except Exception as e:
                print(f"   âš ï¸ Failed to delete stage_{stage_num}/: {e}")
    
    # ==================== å®Œæˆ ====================
    print("\n" + "="*80)
    print("âœ… Multi-Stage Code Generation Complete!")
    print("="*80)
    print(f"ğŸ“ Output directory: {output_path.resolve()}")
    
    # åˆ—å‡ºæœ€ç»ˆç”Ÿæˆçš„æ–‡ä»¶
    final_files = list((output_path / "final").glob("*")) if (output_path / "final").exists() else []
    if final_files:
        print(f"\nğŸ“„ Final generated files ({len(final_files)}):")
        for f in sorted(final_files):
            if f.is_file():
                size = f.stat().st_size
                size_str = f"{size:,} bytes" if size < 1024 else f"{size/1024:.1f} KB"
                print(f"   âœ“ {f.name:<40} ({size_str})")


async def _generate_stage_code(code_agent, prompt: str, stage_name: str) -> dict:
    """ç”Ÿæˆå•ä¸ªé˜¶æ®µçš„ä»£ç """
    print(f"\nğŸ’» Generating {stage_name} code...")
    print("   (This may take several minutes, please wait...)")
    
    try:
        settings = get_settings()
        code_model = settings.code_model
        
        # ä½¿ç”¨æ ‡å‡†çš„ chat API
        # æ³¨æ„ï¼šä»£ç ç”Ÿæˆä»»åŠ¡åº”è¯¥ç›´æ¥è¿”å›ä»£ç å†…å®¹ï¼Œä¸åº”è¯¥ä½¿ç”¨å·¥å…·è°ƒç”¨
        # ä½¿ç”¨ llm è€Œä¸æ˜¯ llm_with_tools æ¥é¿å…å·¥å…·è°ƒç”¨
        messages = [
            SystemMessage(content=code_agent.prompt()),
            HumanMessage(content=prompt)
        ]
        
        try:
            # ä»£ç ç”Ÿæˆç›´æ¥ä½¿ç”¨ llmï¼Œä¸ä½¿ç”¨å·¥å…·ç»‘å®š
            # ä»£ç ç”Ÿæˆä»»åŠ¡åº”è¯¥ç›´æ¥è¿”å›ä»£ç å†…å®¹ï¼Œä¸åº”è¯¥æœ‰å·¥å…·è°ƒç”¨
            response = await code_agent.llm.ainvoke(messages)
            code_content = response.content if hasattr(response, 'content') and response.content else ""
            
            # æ£€æŸ¥å“åº”å…ƒæ•°æ®ï¼Œåˆ¤æ–­æ˜¯å¦å› ä¸ºé•¿åº¦é™åˆ¶è¢«æˆªæ–­
            finish_reason = None
            reasoning_tokens = 0
            if hasattr(response, 'response_metadata'):
                metadata = response.response_metadata
                finish_reason = metadata.get('finish_reason')
                token_usage = metadata.get('tokeen_usage', {}) or metadata.get('token_usage', {})
                if isinstance(token_usage, dict):
                    completion_details = token_usage.get('completion_tokens_details', {})
                    if isinstance(completion_details, dict):
                        reasoning_tokens = completion_details.get('reasoning_tokens', 0)
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥å“åº”å¯¹è±¡ç»“æ„
            if not code_content or not code_content.strip():
                print(f"   âš ï¸ Empty or whitespace-only response detected. Response type: {type(response)}")
                if hasattr(response, 'content'):
                    print(f"   âš ï¸ response.content type: {type(response.content)}, length: {len(str(response.content))}")
                if finish_reason == 'length':
                    print(f"   âš ï¸ Response was truncated due to length limit (finish_reason: length)")
                    if reasoning_tokens > 0:
                        print(f"   âš ï¸ Model used {reasoning_tokens} reasoning tokens, but content was empty")
                        print(f"   ğŸ’¡ Suggestion: The prompt may be too long or max_tokens too small.")
                        print(f"   ğŸ’¡ Consider: Reducing prompt size or increasing max_tokens limit.")
                if hasattr(response, '__dict__'):
                    print(f"   âš ï¸ Response dict keys: {list(response.__dict__.keys())}")
                # å°è¯•è·å–æ›´å¤šè°ƒè¯•ä¿¡æ¯
                if hasattr(response, 'additional_kwargs'):
                    print(f"   âš ï¸ additional_kwargs keys: {list(response.additional_kwargs.keys()) if response.additional_kwargs else 'None'}")
                    # æ£€æŸ¥æ˜¯å¦æœ‰ refusal
                    if response.additional_kwargs and 'refusal' in response.additional_kwargs:
                        refusal_content = response.additional_kwargs.get('refusal', '')
                        print(f"   âš ï¸ Model refusal detected: {refusal_content[:500] if refusal_content else 'No refusal message'}")
                        print(f"   ğŸ’¡ Suggestion: The prompt may be too long, contain problematic content, or request something the model refuses to do.")
        except Exception as e:
            if "chat model" in str(e).lower() or "not supported" in str(e).lower():
                print(f"   âš ï¸ Model {code_model} doesn't support chat API, falling back...")
                from Agents.prompt import DEFAULT_MODEL
                code_agent.model = DEFAULT_MODEL
                code_agent._llm = None
                code_agent._llm_with_tools = None
                
                response = await code_agent.llm.ainvoke(messages)
                code_content = response.content if response.content else ""
                
                if not code_content:
                    print(f"   âš ï¸ Empty response after fallback. Response type: {type(response)}")
                    if hasattr(response, '__dict__'):
                        print(f"   âš ï¸ Response dict: {response.__dict__}")
                
                print(f"   âœ“ Switched to model: {DEFAULT_MODEL}")
            else:
                raise
        
        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
        if not code_content or not code_content.strip():
            # è·å– finish_reason å’Œ token ä¿¡æ¯ç”¨äºé”™è¯¯æç¤º
            finish_reason = None
            reasoning_tokens = 0
            total_tokens = 0
            if hasattr(response, 'response_metadata'):
                metadata = response.response_metadata
                finish_reason = metadata.get('finish_reason')
                token_usage = metadata.get('tokeen_usage', {}) or metadata.get('token_usage', {})
                if isinstance(token_usage, dict):
                    total_tokens = token_usage.get('total_tokens', 0)
                    completion_details = token_usage.get('completion_tokens_details', {})
                    if isinstance(completion_details, dict):
                        reasoning_tokens = completion_details.get('reasoning_tokens', 0)
            
            error_msg = f"   âŒ Empty response from API. Model: {code_model}"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ refusal
            if hasattr(response, 'additional_kwargs') and response.additional_kwargs:
                if 'refusal' in response.additional_kwargs:
                    refusal_content = response.additional_kwargs.get('refusal', '')
                    error_msg += f"\n   âš ï¸ Model refusal detected: {str(refusal_content)[:200]}"
                    error_msg += f"\n   ğŸ’¡ Suggestion: The prompt may be too long or contain problematic content. Try reducing the prompt size."
            
            if finish_reason == 'length':
                error_msg += f"\n   âš ï¸ Response was truncated due to length limit (finish_reason: length)"
                if reasoning_tokens > 0:
                    error_msg += f"\n   âš ï¸ Model used {reasoning_tokens} reasoning tokens but content was empty"
                error_msg += f"\n   ğŸ’¡ Suggestion: Reduce prompt size or increase max_tokens limit"
            
            print(error_msg)
            
            # ä¿å­˜è°ƒè¯•ä¿¡æ¯
            debug_file = Path("code_generated") / f"debug_{stage_name.lower().replace(' ', '_')}_empty_response.txt"
            debug_file.parent.mkdir(parents=True, exist_ok=True)
            with open(debug_file, "w", encoding="utf-8") as f:
                f.write(f"Stage: {stage_name}\n")
                f.write(f"Model: {code_model}\n")
                f.write("="*80 + "\n")
                f.write("Empty response received from API.\n")
                f.write(f"Response length: {len(code_content)}\n")
                if finish_reason:
                    f.write(f"Finish reason: {finish_reason}\n")
                if reasoning_tokens > 0:
                    f.write(f"Reasoning tokens: {reasoning_tokens}\n")
                if total_tokens > 0:
                    f.write(f"Total tokens: {total_tokens}\n")
                f.write("\nResponse metadata:\n")
                if hasattr(response, 'response_metadata'):
                    import json
                    f.write(json.dumps(response.response_metadata, indent=2, ensure_ascii=False))
            
            error_detail = f"Empty response from API for {stage_name}"
            if finish_reason == 'length':
                error_detail += " (truncated due to length limit)"
            error_detail += f". Check {debug_file} for details."
            raise ValueError(error_detail)
        
        # è§£æ JSON å“åº”
        print(f"   ğŸ“ Response length: {len(code_content)} characters")
        code_data = _parse_json_response(code_content, stage_name)
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œä¿å­˜åŸå§‹å“åº”ç”¨äºè°ƒè¯•
        if not code_data.get("files"):
            debug_file = Path("code_generated") / f"debug_{stage_name.lower().replace(' ', '_')}_response.txt"
            debug_file.parent.mkdir(parents=True, exist_ok=True)
            with open(debug_file, "w", encoding="utf-8") as f:
                f.write(f"Stage: {stage_name}\n")
                f.write("="*80 + "\n")
                f.write(code_content)
            print(f"   âš ï¸ JSON parsing failed, saved raw response to: {debug_file}")
            print(f"   ğŸ“„ First 500 chars of response:\n{code_content[:500]}")
        
        return code_data
        
    except Exception as e:
        print(f"\nâŒ {stage_name} code generation failed: {e}")
        import traceback
        traceback.print_exc()
        raise


def _fix_json_control_chars(json_str: str) -> str:
    """ä¿®å¤ JSON å­—ç¬¦ä¸²ä¸­çš„æœªè½¬ä¹‰æ§åˆ¶å­—ç¬¦
    
    åœ¨ JSON å­—ç¬¦ä¸²å€¼ä¸­ï¼Œæ§åˆ¶å­—ç¬¦ï¼ˆASCII 0-31ï¼‰å¿…é¡»è¢«è½¬ä¹‰ã€‚
    æ­¤å‡½æ•°ä¼šè¯†åˆ«å­—ç¬¦ä¸²å€¼å†…çš„æœªè½¬ä¹‰æ§åˆ¶å­—ç¬¦å¹¶æ­£ç¡®è½¬ä¹‰å®ƒä»¬ã€‚
    """
    result = []
    in_string = False
    escape_next = False
    i = 0
    
    while i < len(json_str):
        char = json_str[i]
        
        # å¤„ç†è½¬ä¹‰åºåˆ—
        if escape_next:
            result.append(char)
            escape_next = False
            i += 1
            continue
        
        # å¤„ç†åæ–œæ è½¬ä¹‰
        if char == '\\':
            result.append(char)
            escape_next = True
            i += 1
            continue
        
        # å¤„ç†å­—ç¬¦ä¸²è¾¹ç•Œ
        if char == '"':
            in_string = not in_string
            result.append(char)
            i += 1
            continue
        
        # åœ¨å­—ç¬¦ä¸²å†…éƒ¨å¤„ç†æ§åˆ¶å­—ç¬¦
        if in_string:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ§åˆ¶å­—ç¬¦ï¼ˆASCII 0-31ï¼‰
            if ord(char) < 32:
                # å¸¸è§çš„æ§åˆ¶å­—ç¬¦ä½¿ç”¨æ ‡å‡†è½¬ä¹‰
                if char == '\n':
                    result.append('\\n')
                elif char == '\r':
                    result.append('\\r')
                elif char == '\t':
                    result.append('\\t')
                elif char == '\b':
                    result.append('\\b')
                elif char == '\f':
                    result.append('\\f')
                else:
                    # å…¶ä»–æ§åˆ¶å­—ç¬¦ä½¿ç”¨ Unicode è½¬ä¹‰
                    result.append(f'\\u{ord(char):04x}')
            else:
                result.append(char)
        else:
            # åœ¨å­—ç¬¦ä¸²å¤–éƒ¨ï¼Œç›´æ¥æ·»åŠ 
            result.append(char)
        
        i += 1
    
    return ''.join(result)


def _parse_json_response(content: str, stage_name: str = "") -> dict:
    """è§£æ LLM è¿”å›çš„ JSON å“åº”"""
    import json
    import re
    
    if not content or not content.strip():
        print(f"   âš ï¸ Empty response content")
        return {"files": [], "stage": 0, "description": "Empty response"}
    
    # æ–¹æ³•1: å°è¯•æå– JSON ä»£ç å—ï¼ˆæ”¯æŒå¤šè¡Œï¼‰
    json_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
    if json_match:
        try:
            json_str = json_match.group(1)
            code_data = json.loads(json_str)
            print(f"   âœ“ Successfully parsed JSON from code block")
            return code_data
        except json.JSONDecodeError as e:
            print(f"   âš ï¸ JSON code block parsing failed: {e}")
            # å°è¯•ä¿®å¤æ§åˆ¶å­—ç¬¦
            try:
                json_str_fixed = _fix_json_control_chars(json_str)
                code_data = json.loads(json_str_fixed)
                print(f"   âœ“ Successfully parsed JSON after fixing control characters")
                return code_data
            except Exception as e2:
                print(f"   âš ï¸ Control character fix failed: {e2}")
                pass
    
    # æ–¹æ³•2: æŸ¥æ‰¾åŒ…å« "files" çš„ JSON å¯¹è±¡ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼‰
    # ä½¿ç”¨å¹³è¡¡æ‹¬å·åŒ¹é…
    try:
        start_idx = content.find('{')
        if start_idx == -1:
            print(f"   âš ï¸ No JSON object found (no opening brace)")
            return {"files": [], "stage": 0, "description": "No JSON object found"}
        
        # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ‹¬å·
        brace_count = 0
        end_idx = start_idx
        for i in range(start_idx, len(content)):
            if content[i] == '{':
                brace_count += 1
            elif content[i] == '}':
                brace_count -= 1
                if brace_count == 0:
                    end_idx = i
                    break
        
        if brace_count == 0 and end_idx > start_idx:
            json_str = content[start_idx:end_idx+1]
            try:
                code_data = json.loads(json_str)
                print(f"   âœ“ Successfully parsed JSON using balanced brace matching")
                return code_data
            except json.JSONDecodeError as e:
                print(f"   âš ï¸ Balanced brace JSON parsing failed: {e}")
                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                try:
                    # å…ˆå°è¯•ä¿®å¤æ§åˆ¶å­—ç¬¦
                    json_str_fixed = _fix_json_control_chars(json_str)
                    code_data = json.loads(json_str_fixed)
                    print(f"   âœ“ Successfully parsed JSON after fixing control characters")
                    return code_data
                except Exception as e2:
                    try:
                        # ç§»é™¤å¯èƒ½çš„æ³¨é‡Š
                        json_str_clean = re.sub(r'//.*?$', '', json_str, flags=re.MULTILINE)
                        json_str_clean = re.sub(r'/\*.*?\*/', '', json_str_clean, flags=re.DOTALL)
                        json_str_clean = _fix_json_control_chars(json_str_clean)
                        code_data = json.loads(json_str_clean)
                        print(f"   âœ“ Successfully parsed JSON after removing comments and fixing control characters")
                        return code_data
                    except:
                        pass
    except Exception as e:
        print(f"   âš ï¸ Balanced brace matching failed: {e}")
    
    # æ–¹æ³•3: å°è¯•ä½¿ç”¨ json5ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        import json5  # type: ignore
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª }
        start_idx = content.find('{')
        end_idx = content.rfind('}')
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_str = content[start_idx:end_idx+1]
            code_data = json5.loads(json_str)
            print(f"   âœ“ Successfully parsed JSON using json5")
            return code_data
    except (ImportError, Exception) as e:
        pass
    
    # æ–¹æ³•4: å°è¯•æå–æ‰€æœ‰å¯èƒ½çš„ JSON å¯¹è±¡
    json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
    for json_obj in json_objects:
        if '"files"' in json_obj or '"path"' in json_obj:
            try:
                code_data = json.loads(json_obj)
                if "files" in code_data:
                    print(f"   âœ“ Successfully parsed JSON from pattern matching")
                    return code_data
            except:
                continue
    
    # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›ç©ºç»“æ„å¹¶æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    print(f"   âŒ All JSON parsing methods failed")
    print(f"   ğŸ“„ Response preview (first 1000 chars):\n{content[:1000]}")
    return {"files": [], "stage": 0, "description": "Failed to parse response"}


async def _save_stage_files(output_path: Path, code_data: dict, stage_num: int):
    """ä¿å­˜å•ä¸ªé˜¶æ®µçš„ä»£ç æ–‡ä»¶"""
    stage_dir = output_path / f"stage_{stage_num}"
    stage_dir.mkdir(parents=True, exist_ok=True)
    
    files = code_data.get("files", [])
    if not files:
        print(f"   âš ï¸ No files found in {code_data.get('stage', stage_num)} response")
        return
    
    print(f"   ğŸ“ Saving {len(files)} files to stage_{stage_num}/")
    for file_info in files:
        if not isinstance(file_info, dict):
            continue
        
        file_path_str = (file_info.get("path") or 
                        file_info.get("file_path") or 
                        file_info.get("filename") or 
                        file_info.get("name") or "")
        
        if not file_path_str:
            continue
        
        file_path = stage_dir / file_path_str
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        code = (file_info.get("code") or 
               file_info.get("content") or 
               file_info.get("source") or 
               file_info.get("source_code") or "")
        
        if code:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(code)
            print(f"   âœ“ Saved: {file_path.name} ({len(code)} chars)")
        else:
            print(f"   âš ï¸ Skipped empty file: {file_path_str}")


async def _merge_all_stages(output_path: Path, generated_parts: dict):
    """åˆå¹¶æ‰€æœ‰é˜¶æ®µçš„ä»£ç åˆ°æœ€ç»ˆç›®å½•"""
    final_dir = output_path / "final"
    final_dir.mkdir(parents=True, exist_ok=True)
    
    print("\nğŸ“¦ Merging all stages into final directory...")
    
    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶ï¼ˆStage 5 çš„æ›´æ–°ç‰ˆæœ¬ä¼˜å…ˆï¼‰
    all_files = {}
    
    # å…ˆæ”¶é›† Stage 1-4 çš„æ–‡ä»¶
    for stage_num in [1, 2, 3, 4]:
        stage_data = generated_parts.get(stage_num, {})
        files = stage_data.get("files", [])
        for file_info in files:
            if not isinstance(file_info, dict):
                continue
            file_path = file_info.get("path") or file_info.get("file_path") or file_info.get("filename") or file_info.get("name") or ""
            if file_path:
                code = file_info.get("code") or file_info.get("content") or file_info.get("source") or file_info.get("source_code") or ""
                if code:
                    all_files[file_path] = code
    
    # Stage 5 çš„æ–‡ä»¶ä¼šè¦†ç›–ä¹‹å‰çš„ç‰ˆæœ¬ï¼ˆå¦‚æœæœ‰æ¥å£ä¿®å¤ï¼‰
    stage5_data = generated_parts.get(5, {})
    files = stage5_data.get("files", [])
    for file_info in files:
        if not isinstance(file_info, dict):
            continue
        file_path = file_info.get("path") or file_info.get("file_path") or file_info.get("filename") or file_info.get("name") or ""
        if file_path:
            code = file_info.get("code") or file_info.get("content") or file_info.get("source") or file_info.get("source_code") or ""
            if code:
                all_files[file_path] = code  # è¦†ç›–ä¹‹å‰çš„ç‰ˆæœ¬
    
    # ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°æœ€ç»ˆç›®å½•
    for file_path_str, code in all_files.items():
        file_path = final_dir / file_path_str
        file_path.parent.mkdir(parents=True, exist_ok=True)
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(code)
    
    print(f"   âœ“ Merged {len(all_files)} files to final/")
    
    # å¦‚æœæœ‰æ¥å£ä¿®å¤ä¿¡æ¯ï¼Œæ˜¾ç¤ºå‡ºæ¥
    if stage5_data.get("interface_fixes"):
        print("\nğŸ”§ Interface Fixes Applied:")
        for fix in stage5_data["interface_fixes"]:
            print(f"   - {fix}")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # é»˜è®¤ä½¿ç”¨ outputs/final_report.jsonï¼ˆåœ¨å‡½æ•°å†…éƒ¨å¤„ç†ï¼‰
    report_path = None
    if len(sys.argv) > 1:
        report_path = sys.argv[1]
    
    output_dir = "code_generated_multi_legnet"
    if len(sys.argv) > 2:
        output_dir = sys.argv[2]
    
    asyncio.run(generate_code_from_report(report_path, output_dir))


if __name__ == "__main__":
    main()
