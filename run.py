import asyncio
import json
from pathlib import Path

from langchain_core.messages import BaseMessage

from Agents.workflow import create_workflow_graph, create_initial_state
from RAG.rag import HybridRAGSystem


def _serialize_messages(messages: list[BaseMessage]) -> list[dict]:
    """å°†å¯¹è¯ä¸è®¨è®ºè¿‡ç¨‹åºåˆ—åŒ–ä¸ºå¯ä¿å­˜çš„ç»“æ„"""
    serialized: list[dict] = []
    for m in messages or []:
        try:
            role = getattr(m, "type", m.__class__.__name__)
            content = getattr(m, "content", "")
            serialized.append(
                {
                    "role": role,
                    "content": content,
                }
            )
        except Exception as e:
            serialized.append(
                {
                    "role": "unknown",
                    "content": f"[Serialization error: {e}]",
                }
            )
    return serialized


def _format_report_to_txt(report: dict) -> str:
    """å°†æŠ¥å‘Šå­—å…¸æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„TXTæ–‡æœ¬"""
    lines = []
    
    # æ ‡é¢˜
    lines.append("=" * 80)
    lines.append(report.get("title", "Experimental Design Report"))
    lines.append("=" * 80)
    lines.append("")
    
    # æ‘˜è¦
    summary = report.get("summary", "")
    if summary:
        lines.append("SUMMARY")
        lines.append("-" * 80)
        lines.append(summary)
        lines.append("")
    
    # æ€»ä½“è¯„åˆ†
    overall_score = report.get("overall_score", 0)
    lines.append(f"Overall Feasibility Score: {overall_score:.1f}/10")
    lines.append("")
    
    # ä»»åŠ¡ä¿¡æ¯
    task_info = report.get("task_information", {})
    if task_info:
        lines.append("TASK INFORMATION")
        lines.append("-" * 80)
        lines.append(f"Description: {task_info.get('description', 'N/A')}")
        lines.append("")
        if task_info.get("background"):
            lines.append("Background:")
            lines.append(task_info["background"])
            lines.append("")
        if task_info.get("dataset_info"):
            lines.append("Dataset Information:")
            lines.append(task_info["dataset_info"])
            lines.append("")
    
    # å®éªŒè®¾è®¡æ–¹æ¡ˆ
    exp_design = report.get("experimental_design", {})
    if exp_design:
        lines.append("=" * 80)
        lines.append("EXPERIMENTAL DESIGN IMPLEMENTATION PLAN")
        lines.append("=" * 80)
        lines.append("")
        
        # 1. æ•°æ®ä½¿ç”¨è®¡åˆ’
        data_plan = exp_design.get("1_data_usage_plan", {})
        if data_plan:
            lines.append("1. DATA USAGE PLAN")
            lines.append("-" * 80)
            for key, value in data_plan.items():
                if isinstance(value, str) and value.strip():
                    lines.append(f"\n{key.replace('_', ' ').title()}:")
                    lines.append(value)
                    lines.append("")
            lines.append("")
        
        # 2. æ–¹æ³•è®¾è®¡
        method_design = exp_design.get("2_method_design", {})
        if method_design:
            lines.append("2. METHOD DESIGN")
            lines.append("-" * 80)
            for key, value in method_design.items():
                if isinstance(value, str) and value.strip():
                    lines.append(f"\n{key.replace('_', ' ').title()}:")
                    lines.append(value)
                    lines.append("")
            lines.append("")
        
        # 3. æ¨¡å‹è®¾è®¡
        model_design = exp_design.get("3_model_design", {})
        if model_design:
            lines.append("3. MODEL DESIGN")
            lines.append("-" * 80)
            for key, value in model_design.items():
                if isinstance(value, str) and value.strip():
                    lines.append(f"\n{key.replace('_', ' ').title()}:")
                    lines.append(value)
                    lines.append("")
            lines.append("")
        
        # 4. ç»“æœæ€»ç»“
        result_summary = exp_design.get("4_result_summary", {})
        if result_summary:
            lines.append("4. RESULT SUMMARY")
            lines.append("-" * 80)
            for key, value in result_summary.items():
                if isinstance(value, str) and value.strip():
                    lines.append(f"\n{key.replace('_', ' ').title()}:")
                    lines.append(value)
                    lines.append("")
            lines.append("")
    
    # ä¸“å®¶åˆ†æï¼ˆé‡ç‚¹å±•ç¤ºå®æ–½æ–¹æ¡ˆï¼‰
    expert_analyses = report.get("expert_analyses", {})
    if expert_analyses:
        lines.append("=" * 80)
        lines.append("EXPERT IMPLEMENTATION PLANS")
        lines.append("=" * 80)
        lines.append("")
        
        role_names = {
            "data_management": "Data Management Expert",
            "methodology": "Methodology Expert",
            "model_architect": "Model Architect",
            "result_analyst": "Result Analyst"
        }
        
        for role, analysis in expert_analyses.items():
            role_name = role_names.get(role, role)
            score = analysis.get("score", 0)
            lines.append(f"{role_name.upper()} (Score: {score:.1f}/10)")
            lines.append("-" * 80)
            
            # è®¾è®¡æ‘˜è¦
            design_summary = analysis.get("design_summary", "")
            if design_summary:
                lines.append("\nDesign Summary:")
                lines.append(design_summary)
                lines.append("")
            
            # å®æ–½æ–¹æ¡ˆï¼ˆé‡ç‚¹ï¼‰- å®Œæ•´æ˜¾ç¤ºï¼Œä¸è¿›è¡Œä»»ä½•æ¦‚æ‹¬
            impl_plan = analysis.get("implementation_plan", {})
            full_metadata = analysis.get("full_metadata", {})
            
            # å¦‚æœ implementation_plan ä¸ºç©ºï¼Œå°è¯•ä» full_metadata ä¸­è·å–
            if (not impl_plan or (isinstance(impl_plan, dict) and len(impl_plan) == 0)) and full_metadata:
                impl_plan = full_metadata.get("detailed_design", {})
            
            if impl_plan and isinstance(impl_plan, dict) and len(impl_plan) > 0:
                lines.append("\nImplementation Plan (Complete, No Summarization):")
                lines.append("")
                for key, value in impl_plan.items():
                    if value:  # åªè¦valueä¸ä¸ºç©ºå°±æ˜¾ç¤º
                        lines.append(f"{key.replace('_', ' ').title()}:")
                        lines.append("-" * 60)
                        # å®Œæ•´æ˜¾ç¤ºå†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                        if isinstance(value, str):
                            # ä¿æŒä»£ç å—çš„åŸå§‹æ ¼å¼
                            lines.append(value)
                        elif isinstance(value, dict):
                            # å¦‚æœæ˜¯åµŒå¥—å­—å…¸ï¼Œä½¿ç”¨JSONæ ¼å¼å®Œæ•´æ˜¾ç¤º
                            import json
                            lines.append(json.dumps(value, ensure_ascii=False, indent=2))
                        elif isinstance(value, list):
                            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå®Œæ•´æ˜¾ç¤º
                            for item in value:
                                lines.append(f"  - {item}")
                        else:
                            lines.append(str(value))
                        lines.append("")
                        lines.append("")
            else:
                lines.append("\nâš ï¸ Implementation Plan: (Not available or empty)")
                lines.append("   This may indicate that the agent did not generate detailed_design.")
                if full_metadata:
                    lines.append(f"   Available metadata keys: {list(full_metadata.keys())}")
                lines.append("")
            
            # å»ºè®®
            recommendations = analysis.get("recommendations", [])
            if recommendations:
                lines.append("Recommendations:")
                for i, rec in enumerate(recommendations, 1):
                    lines.append(f"  {i}. {rec}")
                lines.append("")
            
            # æ£€ç´¢åˆ°çš„çŸ¥è¯†æ¡ç›®ï¼ˆç”¨äºå¯è§£é‡Šæ€§ï¼‰
            retrieved_knowledge = full_metadata.get("retrieved_knowledge", []) if full_metadata else analysis.get("full_metadata", {}).get("retrieved_knowledge", [])
            if not retrieved_knowledge:
                # å°è¯•ä»implementation_plançš„metadataä¸­è·å–
                impl_meta = analysis.get("implementation_plan", {})
                if isinstance(impl_meta, dict):
                    retrieved_knowledge = impl_meta.get("retrieved_knowledge", [])
            
            if retrieved_knowledge:
                lines.append("Retrieved Knowledge Base Items (for Explainability):")
                lines.append("-" * 60)
                for i, kb_item in enumerate(retrieved_knowledge, 1):
                    kb_id = kb_item.get("id", "N/A")
                    kb_title = kb_item.get("title", "")
                    kb_content = kb_item.get("content", "")
                    kb_source = kb_item.get("source", "")
                    kb_score = kb_item.get("relevance_score", 0.0)
                    
                    lines.append(f"\n[{i}] Knowledge ID: {kb_id}")
                    if kb_title:
                        lines.append(f"    Title: {kb_title}")
                    if kb_source:
                        lines.append(f"    Source: {kb_source}")
                    lines.append(f"    Relevance Score: {kb_score:.4f}")
                    lines.append(f"    Content:")
                    # æ˜¾ç¤ºå†…å®¹ï¼ˆå¦‚æœå¤ªé•¿ï¼Œé€‚å½“æˆªæ–­ä½†ä¿ç•™å¤§éƒ¨åˆ†ï¼‰
                    if len(kb_content) > 1000:
                        lines.append(f"    {kb_content[:1000]}...")
                        lines.append(f"    ... (truncated, total length: {len(kb_content)} chars)")
                    else:
                        lines.append(f"    {kb_content}")
                    lines.append("")
            
            lines.append("")
    
    # ä¼˜å…ˆå»ºè®®
    priority_recs = report.get("priority_recommendations", [])
    if priority_recs:
        lines.append("=" * 80)
        lines.append("PRIORITY RECOMMENDATIONS")
        lines.append("=" * 80)
        lines.append("")
        for i, rec in enumerate(priority_recs, 1):
            lines.append(f"{i}. {rec}")
        lines.append("")
    
    return "\n".join(lines)


def _format_conversation_to_txt(messages: list[dict]) -> str:
    """å°†å¯¹è¯æ—¥å¿—æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„TXTæ–‡æœ¬"""
    lines = []
    
    lines.append("=" * 80)
    lines.append("CONVERSATION & DISCUSSION LOG")
    lines.append("=" * 80)
    lines.append("")
    
    role_display = {
        "system": "SYSTEM",
        "human": "USER",
        "ai": "ASSISTANT",
        "tool": "TOOL"
    }
    
    for i, msg in enumerate(messages, 1):
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        
        display_role = role_display.get(role.lower(), role.upper())
        
        lines.append(f"[Message {i}] {display_role}")
        lines.append("-" * 80)
        
        # æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
        lines.append(content)
        
        lines.append("")
        lines.append("")
    
    return "\n".join(lines)


def main() -> None:
    rag = HybridRAGSystem()
    
    # æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å·²æœ‰æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åŠ è½½çŸ¥è¯†åº“ï¼ˆåŒ…æ‹¬æ ¸å¿ƒè®ºæ–‡ï¼‰
    collection = rag.collections.get("shared_knowledge_base")
    if collection and collection.count() == 0:
        print("\n" + "="*60)
        print("ğŸ“š å‘é‡æ•°æ®åº“ä¸ºç©ºï¼Œæ­£åœ¨åŠ è½½çŸ¥è¯†åº“ï¼ˆåŒ…æ‹¬æ ¸å¿ƒè®ºæ–‡Methodséƒ¨åˆ†ï¼‰...")
        print("="*60)
        rag.load_knowledge_base(load_core_papers=True)
        print("="*60 + "\n")
    elif collection and collection.count() > 0:
        print(f"\nâœ“ å‘é‡æ•°æ®åº“å·²æœ‰ {collection.count()} ä¸ªæ–‡æ¡£ï¼Œè·³è¿‡åŠ è½½")
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å•ç‹¬åŠ è½½æ ¸å¿ƒè®ºæ–‡ï¼ˆå¦‚æœä¹‹å‰æ²¡æœ‰åŠ è½½è¿‡ï¼‰
        # é€šè¿‡æ£€æŸ¥æ˜¯å¦æœ‰ doc_type="core_paper_methods" çš„æ–‡æ¡£æ¥åˆ¤æ–­
        try:
            sample_results = collection.peek(limit=100)
            has_core_papers = any(
                meta.get("doc_type") == "core_paper_methods" 
                for meta in (sample_results.get("metadatas", []) or [])
            )
            if not has_core_papers:
                print("âš ï¸ æ£€æµ‹åˆ°å‘é‡åº“ä¸­æ²¡æœ‰æ ¸å¿ƒè®ºæ–‡Methodséƒ¨åˆ†ï¼Œæ­£åœ¨åŠ è½½...")
                rag.load_core_papers()
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥æ ¸å¿ƒè®ºæ–‡æ—¶å‡ºé”™: {e}ï¼Œå°è¯•åŠ è½½æ ¸å¿ƒè®ºæ–‡...")
            rag.load_core_papers()
    else:
        print("âš ï¸ æ— æ³•è®¿é—®å‘é‡æ•°æ®åº“é›†åˆï¼Œå°è¯•åŠ è½½çŸ¥è¯†åº“...")
        rag.load_knowledge_base(load_core_papers=True)
    
    app = create_workflow_graph(rag_system=rag)

    state = create_initial_state(rag_system=rag)
    # ä½¿ç”¨å¼‚æ­¥æ¥å£è¿è¡ŒåŒ…å«å¼‚æ­¥èŠ‚ç‚¹çš„LangGraphåº”ç”¨ï¼Œå¹¶é€‚å½“æé«˜é€’å½’ä¸Šé™ï¼Œé˜²æ­¢æ—©æœŸè¿­ä»£è§¦å‘é€’å½’é™åˆ¶
    result = asyncio.run(app.ainvoke(state, config={"recursion_limit": 40}))

    print("âœ“ Workflow finished")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("outputs")
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1) ä¿å­˜æœ€ç»ˆæŠ¥å‘Šï¼ˆJSONå’ŒTXTæ ¼å¼ï¼‰
    final_report = result.get("final_report")
    if final_report:
        title = final_report.get("title", "")
        print("âœ“ Final report title:", title)

        # ä¿å­˜JSONæ ¼å¼
        report_json_path = output_dir / "final_report.json"
        with report_json_path.open("w", encoding="utf-8") as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2)
        print(f"âœ“ Final report (JSON) saved to: {report_json_path.resolve()}")

        # ä¿å­˜TXTæ ¼å¼ï¼ˆæ˜“è¯»ï¼‰
        report_txt_path = output_dir / "final_report.txt"
        report_txt_content = _format_report_to_txt(final_report)
        with report_txt_path.open("w", encoding="utf-8") as f:
            f.write(report_txt_content)
        print(f"âœ“ Final report (TXT) saved to: {report_txt_path.resolve()}")

    # 2) ä¿å­˜å®Œæ•´å¯¹è¯ä¸è®¨è®ºè¿‡ç¨‹ï¼ˆä¼šè®®è®°å½•ï¼ŒJSONå’ŒTXTæ ¼å¼ï¼‰
    messages = result.get("messages", [])
    serialized_msgs = _serialize_messages(messages)
    
    # ä¿å­˜JSONæ ¼å¼
    convo_json_path = output_dir / "conversation_log.json"
    with convo_json_path.open("w", encoding="utf-8") as f:
        json.dump(serialized_msgs, f, ensure_ascii=False, indent=2)
    print(f"âœ“ Conversation log (JSON) saved to: {convo_json_path.resolve()}")
    
    # ä¿å­˜TXTæ ¼å¼ï¼ˆæ˜“è¯»ï¼‰
    convo_txt_path = output_dir / "conversation_log.txt"
    convo_txt_content = _format_conversation_to_txt(serialized_msgs)
    with convo_txt_path.open("w", encoding="utf-8") as f:
        f.write(convo_txt_content)
    print(f"âœ“ Conversation log (TXT) saved to: {convo_txt_path.resolve()}")


if __name__ == "__main__":
    main()